{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-27 23:03:49,908] Making new env: CartPole-v0\n",
      "[2017-11-27 23:03:49,933] Clearing 4 monitor files from previous run (because force=True was provided)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env = wrappers.Monitor(env, 'cartpole', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "  def __init__(self, input_size, output_size):\n",
    "    super(Policy, self).__init__() # this statement is always needed\n",
    "    \n",
    "    self.fc1 = nn.Linear(input_size, 10) # matrix multiplication\n",
    "    self.fc2 = nn.Linear(10, output_size) # matrix multiplication\n",
    "    \n",
    "    # == parameters initialization ==\n",
    "    nn.init.xavier_normal(self.fc1.weight)\n",
    "    nn.init.xavier_normal(self.fc2.weight)\n",
    "    \n",
    "    nn.init.normal(self.fc1.bias)\n",
    "    nn.init.normal(self.fc2.bias)\n",
    "    # =============================== \n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ValueFunction(nn.Module):\n",
    "  def __init__(self, input_size):\n",
    "    super(ValueFunction, self).__init__()\n",
    "    \n",
    "    self.fc1 = nn.Linear(input_size, 10)\n",
    "    self.fc2 = nn.Linear(10, 1) # a single value\n",
    "    \n",
    "    # == parameters initialization ==\n",
    "    nn.init.xavier_normal(self.fc1.weight)\n",
    "    nn.init.xavier_normal(self.fc2.weight)\n",
    "    \n",
    "    nn.init.normal(self.fc1.bias)\n",
    "    nn.init.normal(self.fc2.bias)\n",
    "    # ===============================\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "  def __init__(self, input_size, output_size):\n",
    "    super(ActorCritic, self).__init__()\n",
    "    self.actor = Policy(input_size, output_size)\n",
    "    self.critic = ValueFunction(input_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.critic(x), self.actor(x) # value, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size = 4, output_size = 2\n"
     ]
    }
   ],
   "source": [
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.n\n",
    "print('input_size = {0}, output_size = {1}'.format(input_size, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamma = 0.99 # the parameter for discounting future rewards\n",
    "lbda = 0.9 # the parameter for GAE (generalized advantage estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ActorCritic(input_size, output_size)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-27 23:04:08,315] Starting new video recorder writing to /Users/fchua/Documents/torch_projects/pytorch_tutorials/pytorch-deep-rl/cartpole/openaigym.video.0.68446.video000000.mp4\n",
      "/Users/fchua/Applications/miniconda/lib/python3.5/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n",
      "[2017-11-27 23:04:09,408] Starting new video recorder writing to /Users/fchua/Documents/torch_projects/pytorch_tutorials/pytorch-deep-rl/cartpole/openaigym.video.0.68446.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: episode_rewards = 11.0, policy_loss = 44.216556549072266, value_loss = 650.34375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fchua/Applications/miniconda/lib/python3.5/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n",
      "[2017-11-27 23:04:10,053] Starting new video recorder writing to /Users/fchua/Documents/torch_projects/pytorch_tutorials/pytorch-deep-rl/cartpole/openaigym.video.0.68446.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: episode_rewards = 28.0, policy_loss = 298.5724182128906, value_loss = 7316.267578125\n",
      "2: episode_rewards = 21.0, policy_loss = 164.59884643554688, value_loss = 3428.46826171875\n",
      "3: episode_rewards = 13.0, policy_loss = 62.25950241088867, value_loss = 991.8350219726562\n",
      "4: episode_rewards = 12.0, policy_loss = 54.986114501953125, value_loss = 808.2779541015625\n",
      "5: episode_rewards = 12.0, policy_loss = 68.74180603027344, value_loss = 777.2911987304688\n",
      "6: episode_rewards = 11.0, policy_loss = 60.19776153564453, value_loss = 621.7948608398438\n",
      "7: episode_rewards = 16.0, policy_loss = 98.62602996826172, value_loss = 1687.5443115234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fchua/Applications/miniconda/lib/python3.5/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8: episode_rewards = 11.0, policy_loss = 40.42898178100586, value_loss = 642.636474609375\n",
      "9: episode_rewards = 21.0, policy_loss = 166.7332000732422, value_loss = 3406.75439453125\n",
      "10: episode_rewards = 15.0, policy_loss = 81.10751342773438, value_loss = 1416.95361328125\n",
      "11: episode_rewards = 15.0, policy_loss = 86.94470977783203, value_loss = 1418.1427001953125\n",
      "12: episode_rewards = 15.0, policy_loss = 85.4642105102539, value_loss = 1420.504638671875\n",
      "13: episode_rewards = 15.0, policy_loss = 91.18727111816406, value_loss = 1425.382568359375\n",
      "14: episode_rewards = 12.0, policy_loss = 55.28855895996094, value_loss = 799.579833984375\n",
      "15: episode_rewards = 25.0, policy_loss = 244.47914123535156, value_loss = 5360.80419921875\n",
      "16: episode_rewards = 18.0, policy_loss = 126.79525756835938, value_loss = 2277.943115234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-27 23:04:10,673] Starting new video recorder writing to /Users/fchua/Documents/torch_projects/pytorch_tutorials/pytorch-deep-rl/cartpole/openaigym.video.0.68446.video000027.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17: episode_rewards = 38.0, policy_loss = 494.18475341796875, value_loss = 16106.47265625\n",
      "18: episode_rewards = 10.0, policy_loss = 37.61907958984375, value_loss = 503.0838317871094\n",
      "19: episode_rewards = 11.0, policy_loss = 45.965843200683594, value_loss = 640.5760498046875\n",
      "20: episode_rewards = 16.0, policy_loss = 89.91012573242188, value_loss = 1665.63818359375\n",
      "21: episode_rewards = 18.0, policy_loss = 119.37548065185547, value_loss = 2261.0693359375\n",
      "22: episode_rewards = 12.0, policy_loss = 53.292686462402344, value_loss = 793.2205810546875\n",
      "23: episode_rewards = 15.0, policy_loss = 96.06649780273438, value_loss = 1393.4212646484375\n",
      "24: episode_rewards = 11.0, policy_loss = 57.003074645996094, value_loss = 622.34619140625\n",
      "25: episode_rewards = 14.0, policy_loss = 80.45267486572266, value_loss = 1177.7318115234375\n",
      "26: episode_rewards = 32.0, policy_loss = 351.70574951171875, value_loss = 10222.328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fchua/Applications/miniconda/lib/python3.5/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27: episode_rewards = 15.0, policy_loss = 86.24864196777344, value_loss = 1404.958984375\n",
      "28: episode_rewards = 15.0, policy_loss = 88.44280242919922, value_loss = 1400.9266357421875\n",
      "29: episode_rewards = 18.0, policy_loss = 130.00564575195312, value_loss = 2266.146728515625\n",
      "30: episode_rewards = 19.0, policy_loss = 138.5735321044922, value_loss = 2602.57470703125\n",
      "31: episode_rewards = 13.0, policy_loss = 63.26320266723633, value_loss = 967.2552490234375\n",
      "32: episode_rewards = 9.0, policy_loss = 30.730144500732422, value_loss = 380.0207214355469\n",
      "33: episode_rewards = 25.0, policy_loss = 237.62451171875, value_loss = 5322.65673828125\n",
      "34: episode_rewards = 13.0, policy_loss = 61.89451217651367, value_loss = 960.7030029296875\n",
      "35: episode_rewards = 21.0, policy_loss = 163.598876953125, value_loss = 3370.518310546875\n",
      "36: episode_rewards = 13.0, policy_loss = 68.72775268554688, value_loss = 967.4465942382812\n",
      "37: episode_rewards = 16.0, policy_loss = 97.26411437988281, value_loss = 1653.8050537109375\n",
      "38: episode_rewards = 10.0, policy_loss = 49.421470642089844, value_loss = 479.4997863769531\n",
      "39: episode_rewards = 14.0, policy_loss = 87.22653198242188, value_loss = 1153.006591796875\n",
      "40: episode_rewards = 27.0, policy_loss = 259.2460632324219, value_loss = 6520.08837890625\n",
      "41: episode_rewards = 15.0, policy_loss = 89.062255859375, value_loss = 1399.2698974609375\n",
      "42: episode_rewards = 46.0, policy_loss = 689.7239379882812, value_loss = 26302.740234375\n",
      "43: episode_rewards = 28.0, policy_loss = 284.0631408691406, value_loss = 7199.474609375\n",
      "44: episode_rewards = 12.0, policy_loss = 51.8453483581543, value_loss = 775.928466796875\n",
      "45: episode_rewards = 14.0, policy_loss = 79.14663696289062, value_loss = 1160.690673828125\n",
      "46: episode_rewards = 66.0, policy_loss = 1358.7740478515625, value_loss = 65959.7109375\n",
      "47: episode_rewards = 10.0, policy_loss = 48.240936279296875, value_loss = 479.76739501953125\n",
      "48: episode_rewards = 14.0, policy_loss = 74.25456237792969, value_loss = 1150.96875\n",
      "49: episode_rewards = 35.0, policy_loss = 419.3493957519531, value_loss = 12898.3564453125\n",
      "50: episode_rewards = 20.0, policy_loss = 160.178466796875, value_loss = 2935.677490234375\n",
      "51: episode_rewards = 36.0, policy_loss = 441.8115234375, value_loss = 13853.6435546875\n",
      "52: episode_rewards = 14.0, policy_loss = 83.53958129882812, value_loss = 1142.098388671875\n",
      "53: episode_rewards = 25.0, policy_loss = 226.90017700195312, value_loss = 5312.9072265625\n",
      "54: episode_rewards = 11.0, policy_loss = 44.97888946533203, value_loss = 608.3734130859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-27 23:04:11,828] Starting new video recorder writing to /Users/fchua/Documents/torch_projects/pytorch_tutorials/pytorch-deep-rl/cartpole/openaigym.video.0.68446.video000064.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55: episode_rewards = 25.0, policy_loss = 222.7940673828125, value_loss = 5293.73193359375\n",
      "56: episode_rewards = 12.0, policy_loss = 56.217525482177734, value_loss = 765.1885375976562\n",
      "57: episode_rewards = 14.0, policy_loss = 83.7933349609375, value_loss = 1143.230224609375\n",
      "58: episode_rewards = 23.0, policy_loss = 193.3460235595703, value_loss = 4242.73046875\n",
      "59: episode_rewards = 11.0, policy_loss = 52.25811004638672, value_loss = 609.2244873046875\n",
      "60: episode_rewards = 30.0, policy_loss = 317.876220703125, value_loss = 8565.314453125\n",
      "61: episode_rewards = 10.0, policy_loss = 41.42536544799805, value_loss = 481.3644714355469\n",
      "62: episode_rewards = 17.0, policy_loss = 112.01714324951172, value_loss = 1907.4481201171875\n",
      "63: episode_rewards = 11.0, policy_loss = 49.32096862792969, value_loss = 607.84326171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fchua/Applications/miniconda/lib/python3.5/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64: episode_rewards = 13.0, policy_loss = 72.66355895996094, value_loss = 941.2955322265625\n",
      "65: episode_rewards = 25.0, policy_loss = 224.84681701660156, value_loss = 5274.5849609375\n",
      "66: episode_rewards = 22.0, policy_loss = 182.44842529296875, value_loss = 3757.931640625\n",
      "67: episode_rewards = 48.0, policy_loss = 738.0908203125, value_loss = 29244.296875\n",
      "68: episode_rewards = 18.0, policy_loss = 123.21417236328125, value_loss = 2211.73193359375\n",
      "69: episode_rewards = 13.0, policy_loss = 65.96382141113281, value_loss = 932.6232299804688\n",
      "70: episode_rewards = 23.0, policy_loss = 196.18856811523438, value_loss = 4208.85693359375\n",
      "71: episode_rewards = 13.0, policy_loss = 67.49333190917969, value_loss = 937.54052734375\n",
      "72: episode_rewards = 9.0, policy_loss = 37.31221008300781, value_loss = 361.53778076171875\n",
      "73: episode_rewards = 16.0, policy_loss = 98.19729614257812, value_loss = 1610.3502197265625\n",
      "74: episode_rewards = 29.0, policy_loss = 293.452880859375, value_loss = 7803.53857421875\n",
      "75: episode_rewards = 50.0, policy_loss = 790.027587890625, value_loss = 32432.25390625\n",
      "76: episode_rewards = 13.0, policy_loss = 71.76036071777344, value_loss = 932.5326538085938\n",
      "77: episode_rewards = 46.0, policy_loss = 678.3416137695312, value_loss = 26126.431640625\n",
      "78: episode_rewards = 24.0, policy_loss = 208.10826110839844, value_loss = 4738.330078125\n",
      "79: episode_rewards = 20.0, policy_loss = 148.7138671875, value_loss = 2896.904296875\n",
      "80: episode_rewards = 55.0, policy_loss = 934.6878662109375, value_loss = 41368.00390625\n",
      "81: episode_rewards = 12.0, policy_loss = 60.65480041503906, value_loss = 753.2420043945312\n",
      "82: episode_rewards = 23.0, policy_loss = 197.15989685058594, value_loss = 4206.35302734375\n",
      "83: episode_rewards = 18.0, policy_loss = 126.02944946289062, value_loss = 2193.562744140625\n",
      "84: episode_rewards = 21.0, policy_loss = 166.3317413330078, value_loss = 3303.10107421875\n",
      "85: episode_rewards = 38.0, policy_loss = 478.6993713378906, value_loss = 15861.2451171875\n",
      "86: episode_rewards = 16.0, policy_loss = 101.597412109375, value_loss = 1600.476806640625\n",
      "87: episode_rewards = 15.0, policy_loss = 90.7271728515625, value_loss = 1355.229248046875\n",
      "88: episode_rewards = 17.0, policy_loss = 111.2029800415039, value_loss = 1878.880615234375\n",
      "89: episode_rewards = 14.0, policy_loss = 78.5779037475586, value_loss = 1116.828857421875\n",
      "90: episode_rewards = 31.0, policy_loss = 333.1084289550781, value_loss = 9277.7724609375\n",
      "91: episode_rewards = 12.0, policy_loss = 58.92277908325195, value_loss = 746.810302734375\n",
      "92: episode_rewards = 42.0, policy_loss = 575.54638671875, value_loss = 20636.134765625\n",
      "93: episode_rewards = 25.0, policy_loss = 223.57803344726562, value_loss = 5195.09619140625\n",
      "94: episode_rewards = 18.0, policy_loss = 123.34766387939453, value_loss = 2191.0498046875\n",
      "95: episode_rewards = 47.0, policy_loss = 703.314697265625, value_loss = 27572.458984375\n",
      "96: episode_rewards = 35.0, policy_loss = 415.2046203613281, value_loss = 12761.078125\n",
      "97: episode_rewards = 20.0, policy_loss = 152.85519409179688, value_loss = 2889.59033203125\n",
      "98: episode_rewards = 24.0, policy_loss = 207.9452667236328, value_loss = 4682.04638671875\n",
      "99: episode_rewards = 13.0, policy_loss = 69.06233978271484, value_loss = 913.0662231445312\n",
      "100: episode_rewards = 25.0, policy_loss = 220.576416015625, value_loss = 5222.681640625\n",
      "101: episode_rewards = 15.0, policy_loss = 86.9568862915039, value_loss = 1340.9677734375\n",
      "102: episode_rewards = 48.0, policy_loss = 727.2210693359375, value_loss = 29031.7578125\n",
      "103: episode_rewards = 23.0, policy_loss = 192.9209442138672, value_loss = 4182.70263671875\n",
      "104: episode_rewards = 16.0, policy_loss = 100.21551513671875, value_loss = 1593.1868896484375\n",
      "105: episode_rewards = 14.0, policy_loss = 78.42098236083984, value_loss = 1102.205810546875\n",
      "106: episode_rewards = 17.0, policy_loss = 109.11918640136719, value_loss = 1862.722900390625\n",
      "107: episode_rewards = 46.0, policy_loss = 672.46240234375, value_loss = 25951.51953125\n",
      "108: episode_rewards = 20.0, policy_loss = 150.98854064941406, value_loss = 2866.7919921875\n",
      "109: episode_rewards = 9.0, policy_loss = 35.10340118408203, value_loss = 349.40582275390625\n",
      "110: episode_rewards = 20.0, policy_loss = 148.87466430664062, value_loss = 2868.330810546875\n",
      "111: episode_rewards = 20.0, policy_loss = 146.88796997070312, value_loss = 2866.6884765625\n",
      "112: episode_rewards = 17.0, policy_loss = 109.7396011352539, value_loss = 1862.3841552734375\n",
      "113: episode_rewards = 21.0, policy_loss = 161.19314575195312, value_loss = 3267.48681640625\n",
      "114: episode_rewards = 13.0, policy_loss = 69.85005187988281, value_loss = 906.0396728515625\n",
      "115: episode_rewards = 43.0, policy_loss = 592.8109741210938, value_loss = 21778.322265625\n",
      "116: episode_rewards = 42.0, policy_loss = 569.6244506835938, value_loss = 20564.234375\n",
      "117: episode_rewards = 10.0, policy_loss = 41.28511047363281, value_loss = 456.76885986328125\n",
      "118: episode_rewards = 22.0, policy_loss = 176.3852996826172, value_loss = 3695.810546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-27 23:04:14,031] Starting new video recorder writing to /Users/fchua/Documents/torch_projects/pytorch_tutorials/pytorch-deep-rl/cartpole/openaigym.video.0.68446.video000125.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119: episode_rewards = 52.0, policy_loss = 833.5734252929688, value_loss = 35538.734375\n",
      "120: episode_rewards = 45.0, policy_loss = 640.811767578125, value_loss = 24440.0546875\n",
      "121: episode_rewards = 14.0, policy_loss = 77.96585845947266, value_loss = 1100.3280029296875\n",
      "122: episode_rewards = 19.0, policy_loss = 137.51622009277344, value_loss = 2469.81005859375\n",
      "123: episode_rewards = 17.0, policy_loss = 109.92646789550781, value_loss = 1853.939453125\n",
      "124: episode_rewards = 21.0, policy_loss = 162.13111877441406, value_loss = 3260.1484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fchua/Applications/miniconda/lib/python3.5/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125: episode_rewards = 16.0, policy_loss = 98.751953125, value_loss = 1572.20458984375\n",
      "126: episode_rewards = 16.0, policy_loss = 98.66185760498047, value_loss = 1576.4686279296875\n",
      "127: episode_rewards = 28.0, policy_loss = 270.43048095703125, value_loss = 7019.64892578125\n",
      "128: episode_rewards = 14.0, policy_loss = 76.87844848632812, value_loss = 1107.720458984375\n",
      "129: episode_rewards = 14.0, policy_loss = 75.80248260498047, value_loss = 1101.1683349609375\n",
      "130: episode_rewards = 19.0, policy_loss = 132.5284881591797, value_loss = 2488.318359375\n",
      "131: episode_rewards = 19.0, policy_loss = 135.30047607421875, value_loss = 2482.94091796875\n",
      "132: episode_rewards = 29.0, policy_loss = 289.4839782714844, value_loss = 7664.759765625\n",
      "133: episode_rewards = 17.0, policy_loss = 112.15398406982422, value_loss = 1839.5714111328125\n",
      "134: episode_rewards = 15.0, policy_loss = 88.90082550048828, value_loss = 1311.5439453125\n",
      "135: episode_rewards = 15.0, policy_loss = 91.98249816894531, value_loss = 1308.361572265625\n",
      "136: episode_rewards = 39.0, policy_loss = 504.6811218261719, value_loss = 16772.8671875\n",
      "137: episode_rewards = 12.0, policy_loss = 56.89423370361328, value_loss = 726.1151733398438\n",
      "138: episode_rewards = 27.0, policy_loss = 253.3197479248047, value_loss = 6354.1689453125\n",
      "139: episode_rewards = 13.0, policy_loss = 69.63116455078125, value_loss = 894.024658203125\n",
      "140: episode_rewards = 16.0, policy_loss = 100.81321716308594, value_loss = 1546.7607421875\n",
      "141: episode_rewards = 54.0, policy_loss = 886.8890380859375, value_loss = 39091.8828125\n",
      "142: episode_rewards = 12.0, policy_loss = 59.63967514038086, value_loss = 716.775390625\n",
      "143: episode_rewards = 25.0, policy_loss = 220.56150817871094, value_loss = 5128.791015625\n",
      "144: episode_rewards = 23.0, policy_loss = 192.46621704101562, value_loss = 4108.38037109375\n",
      "145: episode_rewards = 56.0, policy_loss = 947.9351196289062, value_loss = 42928.34375\n",
      "146: episode_rewards = 18.0, policy_loss = 120.49602508544922, value_loss = 2144.23046875\n",
      "147: episode_rewards = 15.0, policy_loss = 88.0864028930664, value_loss = 1300.433837890625\n",
      "148: episode_rewards = 44.0, policy_loss = 611.1702880859375, value_loss = 23000.69140625\n",
      "149: episode_rewards = 22.0, policy_loss = 175.2037811279297, value_loss = 3662.27392578125\n",
      "150: episode_rewards = 26.0, policy_loss = 233.8651580810547, value_loss = 5716.07177734375\n",
      "151: episode_rewards = 29.0, policy_loss = 287.72314453125, value_loss = 7632.72021484375\n",
      "152: episode_rewards = 24.0, policy_loss = 203.36474609375, value_loss = 4612.6513671875\n",
      "153: episode_rewards = 16.0, policy_loss = 98.13490295410156, value_loss = 1563.7080078125\n",
      "154: episode_rewards = 40.0, policy_loss = 509.8550109863281, value_loss = 17854.2578125\n",
      "155: episode_rewards = 12.0, policy_loss = 58.165836334228516, value_loss = 707.1134033203125\n",
      "156: episode_rewards = 14.0, policy_loss = 76.63409423828125, value_loss = 1088.4029541015625\n",
      "157: episode_rewards = 30.0, policy_loss = 305.0902404785156, value_loss = 8342.7451171875\n",
      "158: episode_rewards = 43.0, policy_loss = 586.06201171875, value_loss = 21641.458984375\n",
      "159: episode_rewards = 16.0, policy_loss = 98.10245513916016, value_loss = 1516.5953369140625\n",
      "160: episode_rewards = 20.0, policy_loss = 145.02149963378906, value_loss = 2824.21484375\n",
      "161: episode_rewards = 60.0, policy_loss = 1065.0406494140625, value_loss = 50808.296875\n",
      "162: episode_rewards = 28.0, policy_loss = 268.91162109375, value_loss = 6939.42578125\n",
      "163: episode_rewards = 22.0, policy_loss = 172.66102600097656, value_loss = 3637.99072265625\n",
      "164: episode_rewards = 41.0, policy_loss = 536.1416625976562, value_loss = 18907.9609375\n",
      "165: episode_rewards = 31.0, policy_loss = 321.09014892578125, value_loss = 9075.576171875\n",
      "166: episode_rewards = 33.0, policy_loss = 361.8316345214844, value_loss = 10738.259765625\n",
      "167: episode_rewards = 11.0, policy_loss = 51.311363220214844, value_loss = 560.376220703125\n",
      "168: episode_rewards = 21.0, policy_loss = 157.37429809570312, value_loss = 3194.8291015625\n",
      "169: episode_rewards = 39.0, policy_loss = 485.94061279296875, value_loss = 16680.072265625\n",
      "170: episode_rewards = 14.0, policy_loss = 78.40731048583984, value_loss = 1061.9212646484375\n",
      "171: episode_rewards = 12.0, policy_loss = 58.66282272338867, value_loss = 707.87646484375\n",
      "172: episode_rewards = 17.0, policy_loss = 107.1329574584961, value_loss = 1774.4620361328125\n",
      "173: episode_rewards = 13.0, policy_loss = 68.44684600830078, value_loss = 849.5714721679688\n",
      "174: episode_rewards = 31.0, policy_loss = 321.91766357421875, value_loss = 9047.36328125\n",
      "175: episode_rewards = 45.0, policy_loss = 630.791015625, value_loss = 24269.056640625\n",
      "176: episode_rewards = 22.0, policy_loss = 169.7502899169922, value_loss = 3612.85546875\n",
      "177: episode_rewards = 20.0, policy_loss = 144.7125701904297, value_loss = 2780.983154296875\n",
      "178: episode_rewards = 31.0, policy_loss = 324.1138000488281, value_loss = 9076.373046875\n",
      "179: episode_rewards = 43.0, policy_loss = 579.577392578125, value_loss = 21432.63671875\n",
      "180: episode_rewards = 18.0, policy_loss = 118.27885437011719, value_loss = 2090.50732421875\n",
      "181: episode_rewards = 23.0, policy_loss = 186.78176879882812, value_loss = 4064.361572265625\n",
      "182: episode_rewards = 12.0, policy_loss = 59.18080139160156, value_loss = 707.7180786132812\n",
      "183: episode_rewards = 15.0, policy_loss = 85.61825561523438, value_loss = 1285.070556640625\n",
      "184: episode_rewards = 45.0, policy_loss = 627.2589721679688, value_loss = 24173.068359375\n",
      "185: episode_rewards = 11.0, policy_loss = 51.7918586730957, value_loss = 539.518310546875\n",
      "186: episode_rewards = 23.0, policy_loss = 185.92645263671875, value_loss = 4067.464599609375\n",
      "187: episode_rewards = 10.0, policy_loss = 42.48015213012695, value_loss = 436.167724609375\n",
      "188: episode_rewards = 22.0, policy_loss = 168.81509399414062, value_loss = 3573.793212890625\n",
      "189: episode_rewards = 52.0, policy_loss = 810.6780395507812, value_loss = 35190.3046875\n",
      "190: episode_rewards = 62.0, policy_loss = 1108.251708984375, value_loss = 54977.2890625\n",
      "191: episode_rewards = 41.0, policy_loss = 533.1460571289062, value_loss = 18860.236328125\n",
      "192: episode_rewards = 52.0, policy_loss = 813.3466186523438, value_loss = 34994.46484375\n",
      "193: episode_rewards = 17.0, policy_loss = 107.26837158203125, value_loss = 1777.70458984375\n",
      "194: episode_rewards = 24.0, policy_loss = 198.83905029296875, value_loss = 4548.01953125\n",
      "195: episode_rewards = 35.0, policy_loss = 392.3153991699219, value_loss = 12443.0537109375\n",
      "196: episode_rewards = 11.0, policy_loss = 51.400657653808594, value_loss = 536.7491455078125\n",
      "197: episode_rewards = 26.0, policy_loss = 232.1091766357422, value_loss = 5627.85400390625\n",
      "198: episode_rewards = 16.0, policy_loss = 95.73715209960938, value_loss = 1494.0986328125\n",
      "199: episode_rewards = 33.0, policy_loss = 356.34930419921875, value_loss = 10600.037109375\n",
      "200: episode_rewards = 17.0, policy_loss = 108.21944427490234, value_loss = 1783.5714111328125\n",
      "201: episode_rewards = 37.0, policy_loss = 441.697509765625, value_loss = 14383.609375\n",
      "202: episode_rewards = 32.0, policy_loss = 333.3311462402344, value_loss = 9803.607421875\n",
      "203: episode_rewards = 35.0, policy_loss = 393.3686218261719, value_loss = 12390.041015625\n",
      "204: episode_rewards = 26.0, policy_loss = 230.63868713378906, value_loss = 5587.330078125\n",
      "205: episode_rewards = 25.0, policy_loss = 211.74972534179688, value_loss = 5042.31689453125\n",
      "206: episode_rewards = 24.0, policy_loss = 199.69708251953125, value_loss = 4487.85546875\n",
      "207: episode_rewards = 26.0, policy_loss = 228.92002868652344, value_loss = 5555.330078125\n",
      "208: episode_rewards = 61.0, policy_loss = 1069.919921875, value_loss = 52810.44140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-27 23:04:17,073] Starting new video recorder writing to /Users/fchua/Documents/torch_projects/pytorch_tutorials/pytorch-deep-rl/cartpole/openaigym.video.0.68446.video000216.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209: episode_rewards = 17.0, policy_loss = 106.08619689941406, value_loss = 1770.837646484375\n",
      "210: episode_rewards = 18.0, policy_loss = 120.36920928955078, value_loss = 2039.8350830078125\n",
      "211: episode_rewards = 12.0, policy_loss = 63.849666595458984, value_loss = 659.4358520507812\n",
      "212: episode_rewards = 18.0, policy_loss = 116.78791809082031, value_loss = 2034.849365234375\n",
      "213: episode_rewards = 11.0, policy_loss = 49.28379440307617, value_loss = 538.8980712890625\n",
      "214: episode_rewards = 26.0, policy_loss = 231.0035400390625, value_loss = 5574.16796875\n",
      "215: episode_rewards = 21.0, policy_loss = 155.11587524414062, value_loss = 3137.178955078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fchua/Applications/miniconda/lib/python3.5/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216: episode_rewards = 40.0, policy_loss = 497.62939453125, value_loss = 17593.796875\n",
      "217: episode_rewards = 57.0, policy_loss = 945.3668212890625, value_loss = 44217.14453125\n",
      "218: episode_rewards = 21.0, policy_loss = 154.9577178955078, value_loss = 3108.844970703125\n",
      "219: episode_rewards = 26.0, policy_loss = 228.23179626464844, value_loss = 5556.5048828125\n",
      "220: episode_rewards = 16.0, policy_loss = 95.03447723388672, value_loss = 1495.0439453125\n",
      "221: episode_rewards = 26.0, policy_loss = 228.67918395996094, value_loss = 5509.52392578125\n",
      "222: episode_rewards = 21.0, policy_loss = 153.35743713378906, value_loss = 3129.417724609375\n",
      "223: episode_rewards = 20.0, policy_loss = 139.11251831054688, value_loss = 2734.933837890625\n",
      "224: episode_rewards = 17.0, policy_loss = 104.7176513671875, value_loss = 1751.6944580078125\n",
      "225: episode_rewards = 31.0, policy_loss = 313.08160400390625, value_loss = 8868.1142578125\n",
      "226: episode_rewards = 10.0, policy_loss = 41.415096282958984, value_loss = 404.2605285644531\n",
      "227: episode_rewards = 25.0, policy_loss = 211.51388549804688, value_loss = 4996.09375\n",
      "228: episode_rewards = 42.0, policy_loss = 543.0543212890625, value_loss = 19916.59375\n",
      "229: episode_rewards = 21.0, policy_loss = 155.18984985351562, value_loss = 3099.00341796875\n",
      "230: episode_rewards = 113.0, policy_loss = 3105.134765625, value_loss = 232988.28125\n",
      "231: episode_rewards = 77.0, policy_loss = 1604.9906005859375, value_loss = 93525.2109375\n",
      "232: episode_rewards = 23.0, policy_loss = 180.9061279296875, value_loss = 3979.931640625\n",
      "233: episode_rewards = 37.0, policy_loss = 427.0965881347656, value_loss = 14253.564453125\n",
      "234: episode_rewards = 40.0, policy_loss = 496.10711669921875, value_loss = 17471.537109375\n",
      "235: episode_rewards = 17.0, policy_loss = 103.10604095458984, value_loss = 1748.9534912109375\n",
      "236: episode_rewards = 18.0, policy_loss = 115.49236297607422, value_loss = 2039.9251708984375\n",
      "237: episode_rewards = 64.0, policy_loss = 1150.9310302734375, value_loss = 59103.24609375\n",
      "238: episode_rewards = 22.0, policy_loss = 165.6572265625, value_loss = 3497.147216796875\n",
      "239: episode_rewards = 14.0, policy_loss = 74.7838134765625, value_loss = 1027.419677734375\n",
      "240: episode_rewards = 22.0, policy_loss = 164.7482147216797, value_loss = 3495.677978515625\n",
      "241: episode_rewards = 12.0, policy_loss = 60.50974655151367, value_loss = 651.8364868164062\n",
      "242: episode_rewards = 20.0, policy_loss = 138.05865478515625, value_loss = 2658.529541015625\n",
      "243: episode_rewards = 34.0, policy_loss = 377.1037292480469, value_loss = 11207.517578125\n",
      "244: episode_rewards = 20.0, policy_loss = 139.06149291992188, value_loss = 2654.5380859375\n",
      "245: episode_rewards = 48.0, policy_loss = 685.7529296875, value_loss = 28094.76953125\n",
      "246: episode_rewards = 19.0, policy_loss = 127.455322265625, value_loss = 2337.697265625\n",
      "247: episode_rewards = 41.0, policy_loss = 513.3475341796875, value_loss = 18640.068359375\n",
      "248: episode_rewards = 32.0, policy_loss = 329.80303955078125, value_loss = 9572.6748046875\n",
      "249: episode_rewards = 14.0, policy_loss = 79.98717498779297, value_loss = 975.7605590820312\n",
      "250: episode_rewards = 39.0, policy_loss = 470.0213317871094, value_loss = 16270.6689453125\n",
      "251: episode_rewards = 17.0, policy_loss = 102.2137451171875, value_loss = 1700.65478515625\n",
      "252: episode_rewards = 23.0, policy_loss = 178.25100708007812, value_loss = 3897.241455078125\n",
      "253: episode_rewards = 46.0, policy_loss = 627.9389038085938, value_loss = 25202.01953125\n",
      "254: episode_rewards = 21.0, policy_loss = 152.98318481445312, value_loss = 3021.085205078125\n",
      "255: episode_rewards = 70.0, policy_loss = 1333.2177734375, value_loss = 73601.171875\n",
      "256: episode_rewards = 37.0, policy_loss = 422.315673828125, value_loss = 14156.9384765625\n",
      "257: episode_rewards = 52.0, policy_loss = 788.3259887695312, value_loss = 34504.875\n",
      "258: episode_rewards = 22.0, policy_loss = 167.75062561035156, value_loss = 3460.606201171875\n",
      "259: episode_rewards = 38.0, policy_loss = 460.26806640625, value_loss = 15037.9345703125\n",
      "260: episode_rewards = 33.0, policy_loss = 349.6744384765625, value_loss = 10383.69140625\n",
      "261: episode_rewards = 19.0, policy_loss = 129.0939483642578, value_loss = 2272.401123046875\n",
      "262: episode_rewards = 10.0, policy_loss = 42.57194519042969, value_loss = 391.18524169921875\n",
      "263: episode_rewards = 16.0, policy_loss = 96.75068664550781, value_loss = 1437.851806640625\n",
      "264: episode_rewards = 22.0, policy_loss = 167.2516632080078, value_loss = 3436.546630859375\n",
      "265: episode_rewards = 28.0, policy_loss = 255.9658203125, value_loss = 6625.4873046875\n",
      "266: episode_rewards = 34.0, policy_loss = 363.2597961425781, value_loss = 11213.08984375\n",
      "267: episode_rewards = 14.0, policy_loss = 72.1711654663086, value_loss = 959.6773071289062\n",
      "268: episode_rewards = 23.0, policy_loss = 182.43197631835938, value_loss = 3879.41552734375\n",
      "269: episode_rewards = 38.0, policy_loss = 442.7935485839844, value_loss = 15055.412109375\n",
      "270: episode_rewards = 24.0, policy_loss = 189.31761169433594, value_loss = 4319.63232421875\n",
      "271: episode_rewards = 30.0, policy_loss = 292.8525390625, value_loss = 7960.63037109375\n",
      "272: episode_rewards = 19.0, policy_loss = 127.0904541015625, value_loss = 2281.870849609375\n",
      "273: episode_rewards = 27.0, policy_loss = 238.49880981445312, value_loss = 5981.61181640625\n",
      "274: episode_rewards = 59.0, policy_loss = 988.3323364257812, value_loss = 47590.9453125\n",
      "275: episode_rewards = 16.0, policy_loss = 92.13407897949219, value_loss = 1453.263671875\n",
      "276: episode_rewards = 15.0, policy_loss = 84.26631927490234, value_loss = 1185.7476806640625\n",
      "277: episode_rewards = 45.0, policy_loss = 604.72900390625, value_loss = 23480.125\n",
      "278: episode_rewards = 14.0, policy_loss = 78.09590148925781, value_loss = 933.1399536132812\n",
      "279: episode_rewards = 12.0, policy_loss = 56.95710372924805, value_loss = 642.986328125\n",
      "280: episode_rewards = 48.0, policy_loss = 675.1674194335938, value_loss = 27812.365234375\n",
      "281: episode_rewards = 17.0, policy_loss = 102.74059295654297, value_loss = 1686.065673828125\n",
      "282: episode_rewards = 41.0, policy_loss = 510.87200927734375, value_loss = 18491.783203125\n",
      "283: episode_rewards = 11.0, policy_loss = 53.138919830322266, value_loss = 471.60382080078125\n",
      "284: episode_rewards = 27.0, policy_loss = 238.67977905273438, value_loss = 5951.28515625\n",
      "285: episode_rewards = 38.0, policy_loss = 435.7267761230469, value_loss = 15007.96484375\n",
      "286: episode_rewards = 16.0, policy_loss = 97.28549194335938, value_loss = 1388.0675048828125\n",
      "287: episode_rewards = 19.0, policy_loss = 126.72602844238281, value_loss = 2270.29931640625\n",
      "288: episode_rewards = 37.0, policy_loss = 416.8194274902344, value_loss = 13997.1474609375\n",
      "289: episode_rewards = 54.0, policy_loss = 832.9381713867188, value_loss = 37770.47265625\n",
      "290: episode_rewards = 33.0, policy_loss = 342.18560791015625, value_loss = 10287.1181640625\n",
      "291: episode_rewards = 15.0, policy_loss = 88.95521545410156, value_loss = 1178.4251708984375\n",
      "292: episode_rewards = 17.0, policy_loss = 99.81497955322266, value_loss = 1665.0740966796875\n",
      "293: episode_rewards = 49.0, policy_loss = 719.67138671875, value_loss = 29209.892578125\n",
      "294: episode_rewards = 21.0, policy_loss = 149.04336547851562, value_loss = 3004.3564453125\n",
      "295: episode_rewards = 47.0, policy_loss = 654.143310546875, value_loss = 26169.666015625\n",
      "296: episode_rewards = 33.0, policy_loss = 347.5527038574219, value_loss = 10281.8935546875\n",
      "297: episode_rewards = 32.0, policy_loss = 322.7079772949219, value_loss = 9398.615234375\n",
      "298: episode_rewards = 33.0, policy_loss = 334.4748840332031, value_loss = 10271.7783203125\n",
      "299: episode_rewards = 83.0, policy_loss = 1794.079833984375, value_loss = 110688.7890625\n",
      "300: episode_rewards = 21.0, policy_loss = 146.8502197265625, value_loss = 2942.9609375\n",
      "301: episode_rewards = 22.0, policy_loss = 165.79229736328125, value_loss = 3376.2998046875\n",
      "302: episode_rewards = 12.0, policy_loss = 56.11103057861328, value_loss = 624.5835571289062\n",
      "303: episode_rewards = 39.0, policy_loss = 459.3927001953125, value_loss = 16010.0390625\n",
      "304: episode_rewards = 22.0, policy_loss = 162.0511474609375, value_loss = 3390.117431640625\n",
      "305: episode_rewards = 53.0, policy_loss = 808.176513671875, value_loss = 35818.57421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306: episode_rewards = 53.0, policy_loss = 823.3262329101562, value_loss = 35711.75\n",
      "307: episode_rewards = 45.0, policy_loss = 594.600830078125, value_loss = 23358.310546875\n",
      "308: episode_rewards = 28.0, policy_loss = 253.91128540039062, value_loss = 6516.7177734375\n",
      "309: episode_rewards = 77.0, policy_loss = 1576.7615966796875, value_loss = 91965.875\n",
      "310: episode_rewards = 23.0, policy_loss = 174.35679626464844, value_loss = 3825.171875\n",
      "311: episode_rewards = 16.0, policy_loss = 98.76451873779297, value_loss = 1367.4127197265625\n",
      "312: episode_rewards = 62.0, policy_loss = 1070.3935546875, value_loss = 53524.13671875\n",
      "313: episode_rewards = 14.0, policy_loss = 69.63106536865234, value_loss = 938.92724609375\n",
      "314: episode_rewards = 20.0, policy_loss = 138.63719177246094, value_loss = 2554.320556640625\n",
      "315: episode_rewards = 28.0, policy_loss = 248.41342163085938, value_loss = 6510.31494140625\n",
      "316: episode_rewards = 49.0, policy_loss = 694.5638427734375, value_loss = 29122.392578125\n",
      "317: episode_rewards = 29.0, policy_loss = 266.74859619140625, value_loss = 7093.7509765625\n",
      "318: episode_rewards = 120.0, policy_loss = 3347.891845703125, value_loss = 263208.5\n",
      "319: episode_rewards = 27.0, policy_loss = 231.68385314941406, value_loss = 5871.56787109375\n",
      "320: episode_rewards = 46.0, policy_loss = 616.3910522460938, value_loss = 24638.873046875\n",
      "321: episode_rewards = 52.0, policy_loss = 778.2984008789062, value_loss = 33820.19140625\n",
      "322: episode_rewards = 21.0, policy_loss = 149.19549560546875, value_loss = 2893.34619140625\n",
      "323: episode_rewards = 12.0, policy_loss = 54.450050354003906, value_loss = 596.35205078125\n",
      "324: episode_rewards = 15.0, policy_loss = 80.32365417480469, value_loss = 1127.1756591796875\n",
      "325: episode_rewards = 57.0, policy_loss = 907.5303955078125, value_loss = 42810.2890625\n",
      "326: episode_rewards = 17.0, policy_loss = 106.0608139038086, value_loss = 1579.8193359375\n",
      "327: episode_rewards = 40.0, policy_loss = 475.2383117675781, value_loss = 16847.525390625\n",
      "328: episode_rewards = 34.0, policy_loss = 353.08795166015625, value_loss = 10923.220703125\n",
      "329: episode_rewards = 34.0, policy_loss = 355.40118408203125, value_loss = 10822.892578125\n",
      "330: episode_rewards = 26.0, policy_loss = 215.12257385253906, value_loss = 5267.0751953125\n",
      "331: episode_rewards = 19.0, policy_loss = 123.30876159667969, value_loss = 2200.103759765625\n",
      "332: episode_rewards = 33.0, policy_loss = 335.6736145019531, value_loss = 10010.9013671875\n",
      "333: episode_rewards = 31.0, policy_loss = 294.884765625, value_loss = 8529.7236328125\n",
      "334: episode_rewards = 82.0, policy_loss = 1724.0848388671875, value_loss = 106775.4765625\n",
      "335: episode_rewards = 70.0, policy_loss = 1301.602783203125, value_loss = 72228.9375\n",
      "336: episode_rewards = 30.0, policy_loss = 277.3800354003906, value_loss = 7704.9736328125\n",
      "337: episode_rewards = 26.0, policy_loss = 213.11375427246094, value_loss = 5197.96875\n",
      "338: episode_rewards = 34.0, policy_loss = 352.9594421386719, value_loss = 10784.4482421875\n",
      "339: episode_rewards = 26.0, policy_loss = 213.9212188720703, value_loss = 5230.8037109375\n",
      "340: episode_rewards = 13.0, policy_loss = 63.6513557434082, value_loss = 734.4114990234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-27 23:04:22,737] Starting new video recorder writing to /Users/fchua/Documents/torch_projects/pytorch_tutorials/pytorch-deep-rl/cartpole/openaigym.video.0.68446.video000343.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341: episode_rewards = 46.0, policy_loss = 601.8141479492188, value_loss = 24353.27734375\n",
      "342: episode_rewards = 36.0, policy_loss = 389.9230041503906, value_loss = 12686.634765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fchua/Applications/miniconda/lib/python3.5/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343: episode_rewards = 38.0, policy_loss = 438.1608581542969, value_loss = 14612.0244140625\n",
      "344: episode_rewards = 52.0, policy_loss = 764.287841796875, value_loss = 33593.671875\n",
      "345: episode_rewards = 62.0, policy_loss = 1077.2249755859375, value_loss = 52790.21484375\n",
      "346: episode_rewards = 16.0, policy_loss = 87.27363586425781, value_loss = 1333.8175048828125\n",
      "347: episode_rewards = 47.0, policy_loss = 655.2194213867188, value_loss = 25701.140625\n",
      "348: episode_rewards = 22.0, policy_loss = 156.07040405273438, value_loss = 3239.634765625\n",
      "349: episode_rewards = 18.0, policy_loss = 119.74655151367188, value_loss = 1839.40625\n",
      "350: episode_rewards = 37.0, policy_loss = 413.2478942871094, value_loss = 13621.74609375\n",
      "351: episode_rewards = 49.0, policy_loss = 678.260986328125, value_loss = 28774.228515625\n",
      "352: episode_rewards = 29.0, policy_loss = 264.3946228027344, value_loss = 6900.84228515625\n",
      "353: episode_rewards = 27.0, policy_loss = 225.0675506591797, value_loss = 5707.36572265625\n",
      "354: episode_rewards = 29.0, policy_loss = 266.432861328125, value_loss = 6935.83642578125\n",
      "355: episode_rewards = 34.0, policy_loss = 348.7895812988281, value_loss = 10665.263671875\n",
      "356: episode_rewards = 50.0, policy_loss = 725.582275390625, value_loss = 29993.1796875\n",
      "357: episode_rewards = 32.0, policy_loss = 317.12042236328125, value_loss = 9181.4853515625\n",
      "358: episode_rewards = 91.0, policy_loss = 2038.56787109375, value_loss = 136811.359375\n",
      "359: episode_rewards = 16.0, policy_loss = 83.24942016601562, value_loss = 1285.5533447265625\n",
      "360: episode_rewards = 18.0, policy_loss = 111.2346420288086, value_loss = 1851.9276123046875\n",
      "361: episode_rewards = 42.0, policy_loss = 513.6976928710938, value_loss = 19004.955078125\n",
      "362: episode_rewards = 30.0, policy_loss = 276.58380126953125, value_loss = 7507.0966796875\n",
      "363: episode_rewards = 77.0, policy_loss = 1548.603271484375, value_loss = 90779.109375\n",
      "364: episode_rewards = 43.0, policy_loss = 540.5587768554688, value_loss = 20191.708984375\n",
      "365: episode_rewards = 65.0, policy_loss = 1147.9031982421875, value_loss = 59457.28515625\n",
      "366: episode_rewards = 42.0, policy_loss = 523.7822875976562, value_loss = 18670.0234375\n",
      "367: episode_rewards = 25.0, policy_loss = 192.20762634277344, value_loss = 4607.404296875\n",
      "368: episode_rewards = 16.0, policy_loss = 92.89463806152344, value_loss = 1298.2506103515625\n",
      "369: episode_rewards = 25.0, policy_loss = 193.78440856933594, value_loss = 4552.15234375\n",
      "370: episode_rewards = 34.0, policy_loss = 338.0373840332031, value_loss = 10698.015625\n",
      "371: episode_rewards = 101.0, policy_loss = 2451.319580078125, value_loss = 174948.90625\n",
      "372: episode_rewards = 25.0, policy_loss = 193.0706024169922, value_loss = 4563.8544921875\n",
      "373: episode_rewards = 72.0, policy_loss = 1361.6055908203125, value_loss = 76607.2578125\n",
      "374: episode_rewards = 31.0, policy_loss = 287.1112365722656, value_loss = 8227.833984375\n",
      "375: episode_rewards = 29.0, policy_loss = 264.6358642578125, value_loss = 6900.29345703125\n",
      "376: episode_rewards = 21.0, policy_loss = 143.2646026611328, value_loss = 2819.454345703125\n",
      "377: episode_rewards = 28.0, policy_loss = 244.99002075195312, value_loss = 6159.68505859375\n",
      "378: episode_rewards = 21.0, policy_loss = 140.24343872070312, value_loss = 2744.89599609375\n",
      "379: episode_rewards = 31.0, policy_loss = 287.2085266113281, value_loss = 8246.9921875\n",
      "380: episode_rewards = 36.0, policy_loss = 397.03240966796875, value_loss = 12318.724609375\n",
      "381: episode_rewards = 21.0, policy_loss = 138.97817993164062, value_loss = 2743.851806640625\n",
      "382: episode_rewards = 26.0, policy_loss = 206.66366577148438, value_loss = 5005.43017578125\n",
      "383: episode_rewards = 30.0, policy_loss = 267.97021484375, value_loss = 7446.2138671875\n",
      "384: episode_rewards = 25.0, policy_loss = 188.3850860595703, value_loss = 4547.15771484375\n",
      "385: episode_rewards = 23.0, policy_loss = 176.59678649902344, value_loss = 3571.147705078125\n",
      "386: episode_rewards = 13.0, policy_loss = 68.49603271484375, value_loss = 679.8695068359375\n",
      "387: episode_rewards = 60.0, policy_loss = 979.1548461914062, value_loss = 47987.71875\n",
      "388: episode_rewards = 63.0, policy_loss = 1070.85009765625, value_loss = 54653.1796875\n",
      "389: episode_rewards = 39.0, policy_loss = 437.87542724609375, value_loss = 15334.611328125\n",
      "390: episode_rewards = 37.0, policy_loss = 398.9808044433594, value_loss = 13381.8740234375\n",
      "391: episode_rewards = 15.0, policy_loss = 73.15563201904297, value_loss = 1004.22607421875\n",
      "392: episode_rewards = 26.0, policy_loss = 205.2182159423828, value_loss = 4918.4208984375\n",
      "393: episode_rewards = 16.0, policy_loss = 92.09329223632812, value_loss = 1280.525634765625\n",
      "394: episode_rewards = 28.0, policy_loss = 243.96913146972656, value_loss = 6142.77783203125\n",
      "395: episode_rewards = 18.0, policy_loss = 101.93046569824219, value_loss = 1729.4029541015625\n",
      "396: episode_rewards = 32.0, policy_loss = 307.9819641113281, value_loss = 8823.6796875\n",
      "397: episode_rewards = 20.0, policy_loss = 133.37802124023438, value_loss = 2413.03662109375\n",
      "398: episode_rewards = 30.0, policy_loss = 268.9629211425781, value_loss = 7392.11083984375\n",
      "399: episode_rewards = 54.0, policy_loss = 838.2241821289062, value_loss = 35843.34375\n",
      "400: episode_rewards = 35.0, policy_loss = 349.8542785644531, value_loss = 11410.646484375\n",
      "401: episode_rewards = 46.0, policy_loss = 588.1701049804688, value_loss = 23944.94140625\n",
      "402: episode_rewards = 26.0, policy_loss = 206.75491333007812, value_loss = 4985.072265625\n",
      "403: episode_rewards = 16.0, policy_loss = 81.73766326904297, value_loss = 1238.0087890625\n",
      "404: episode_rewards = 22.0, policy_loss = 147.2687530517578, value_loss = 3118.48046875\n",
      "405: episode_rewards = 17.0, policy_loss = 96.01927947998047, value_loss = 1462.41552734375\n",
      "406: episode_rewards = 47.0, policy_loss = 626.3338012695312, value_loss = 25100.830078125\n",
      "407: episode_rewards = 25.0, policy_loss = 186.7101287841797, value_loss = 4452.318359375\n",
      "408: episode_rewards = 19.0, policy_loss = 110.44197082519531, value_loss = 2005.8450927734375\n",
      "409: episode_rewards = 35.0, policy_loss = 359.63653564453125, value_loss = 11276.1435546875\n",
      "410: episode_rewards = 22.0, policy_loss = 163.7639923095703, value_loss = 3109.88427734375\n",
      "411: episode_rewards = 43.0, policy_loss = 514.3900146484375, value_loss = 19814.876953125\n",
      "412: episode_rewards = 37.0, policy_loss = 390.2146301269531, value_loss = 13201.8369140625\n",
      "413: episode_rewards = 37.0, policy_loss = 399.11773681640625, value_loss = 13193.7685546875\n",
      "414: episode_rewards = 26.0, policy_loss = 203.8567352294922, value_loss = 5000.7353515625\n",
      "415: episode_rewards = 29.0, policy_loss = 244.2249298095703, value_loss = 6664.431640625\n",
      "416: episode_rewards = 27.0, policy_loss = 218.91297912597656, value_loss = 5552.796875\n",
      "417: episode_rewards = 23.0, policy_loss = 167.75120544433594, value_loss = 3458.366943359375\n",
      "418: episode_rewards = 13.0, policy_loss = 56.08748245239258, value_loss = 639.595947265625\n",
      "419: episode_rewards = 56.0, policy_loss = 876.3859252929688, value_loss = 39605.90234375\n",
      "420: episode_rewards = 42.0, policy_loss = 516.012451171875, value_loss = 18441.646484375\n",
      "421: episode_rewards = 27.0, policy_loss = 218.6669921875, value_loss = 5394.12646484375\n",
      "422: episode_rewards = 44.0, policy_loss = 567.635986328125, value_loss = 20849.537109375\n",
      "423: episode_rewards = 13.0, policy_loss = 55.55753707885742, value_loss = 624.3621826171875\n",
      "424: episode_rewards = 22.0, policy_loss = 155.5836639404297, value_loss = 3141.7265625\n",
      "425: episode_rewards = 25.0, policy_loss = 187.7964324951172, value_loss = 4383.6240234375\n",
      "426: episode_rewards = 25.0, policy_loss = 196.98370361328125, value_loss = 4460.6796875\n",
      "427: episode_rewards = 24.0, policy_loss = 176.42282104492188, value_loss = 3930.724853515625\n",
      "428: episode_rewards = 29.0, policy_loss = 260.075439453125, value_loss = 6759.47705078125\n",
      "429: episode_rewards = 30.0, policy_loss = 260.5226745605469, value_loss = 7202.65185546875\n",
      "430: episode_rewards = 22.0, policy_loss = 150.37799072265625, value_loss = 3034.0888671875\n",
      "431: episode_rewards = 24.0, policy_loss = 180.32615661621094, value_loss = 3994.759765625\n",
      "432: episode_rewards = 29.0, policy_loss = 260.377685546875, value_loss = 6753.8486328125\n",
      "433: episode_rewards = 14.0, policy_loss = 60.52958679199219, value_loss = 832.7625122070312\n",
      "434: episode_rewards = 70.0, policy_loss = 1256.3321533203125, value_loss = 70759.625\n",
      "435: episode_rewards = 34.0, policy_loss = 335.94024658203125, value_loss = 10358.3623046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436: episode_rewards = 56.0, policy_loss = 849.531494140625, value_loss = 39909.02734375\n",
      "437: episode_rewards = 34.0, policy_loss = 354.5043029785156, value_loss = 10445.255859375\n",
      "438: episode_rewards = 42.0, policy_loss = 503.43316650390625, value_loss = 18586.806640625\n",
      "439: episode_rewards = 21.0, policy_loss = 147.1937713623047, value_loss = 2696.1572265625\n",
      "440: episode_rewards = 44.0, policy_loss = 536.603271484375, value_loss = 21040.990234375\n",
      "441: episode_rewards = 52.0, policy_loss = 733.8985595703125, value_loss = 32520.744140625\n",
      "442: episode_rewards = 20.0, policy_loss = 128.01742553710938, value_loss = 2356.491943359375\n",
      "443: episode_rewards = 39.0, policy_loss = 427.223876953125, value_loss = 15053.974609375\n",
      "444: episode_rewards = 22.0, policy_loss = 153.6121826171875, value_loss = 3043.9296875\n",
      "445: episode_rewards = 56.0, policy_loss = 850.439453125, value_loss = 39570.85546875\n",
      "446: episode_rewards = 26.0, policy_loss = 209.1680145263672, value_loss = 4734.4482421875\n",
      "447: episode_rewards = 32.0, policy_loss = 299.0152282714844, value_loss = 8855.23046875\n",
      "448: episode_rewards = 101.0, policy_loss = 2402.436767578125, value_loss = 172491.6875\n",
      "449: episode_rewards = 51.0, policy_loss = 704.96533203125, value_loss = 31119.642578125\n",
      "450: episode_rewards = 23.0, policy_loss = 162.64666748046875, value_loss = 3481.89404296875\n",
      "451: episode_rewards = 45.0, policy_loss = 554.5662231445312, value_loss = 22259.716796875\n",
      "452: episode_rewards = 21.0, policy_loss = 132.12506103515625, value_loss = 2602.44873046875\n",
      "453: episode_rewards = 36.0, policy_loss = 369.3565368652344, value_loss = 11984.57421875\n",
      "454: episode_rewards = 75.0, policy_loss = 1421.0076904296875, value_loss = 83292.03125\n",
      "455: episode_rewards = 20.0, policy_loss = 124.15218353271484, value_loss = 2226.1337890625\n",
      "456: episode_rewards = 24.0, policy_loss = 178.14210510253906, value_loss = 3856.025634765625\n",
      "457: episode_rewards = 38.0, policy_loss = 400.9102783203125, value_loss = 14100.765625\n",
      "458: episode_rewards = 76.0, policy_loss = 1433.298095703125, value_loss = 86185.7890625\n",
      "459: episode_rewards = 21.0, policy_loss = 136.5918426513672, value_loss = 2655.0419921875\n",
      "460: episode_rewards = 13.0, policy_loss = 60.228851318359375, value_loss = 604.4530639648438\n",
      "461: episode_rewards = 26.0, policy_loss = 208.80789184570312, value_loss = 4779.83203125\n",
      "462: episode_rewards = 50.0, policy_loss = 666.4891967773438, value_loss = 29280.884765625\n",
      "463: episode_rewards = 46.0, policy_loss = 592.12548828125, value_loss = 23342.046875\n",
      "464: episode_rewards = 16.0, policy_loss = 85.15986633300781, value_loss = 1209.0372314453125\n",
      "465: episode_rewards = 43.0, policy_loss = 524.7378540039062, value_loss = 19362.197265625\n",
      "466: episode_rewards = 64.0, policy_loss = 1058.39990234375, value_loss = 55481.39453125\n",
      "467: episode_rewards = 14.0, policy_loss = 68.17884826660156, value_loss = 806.5721435546875\n",
      "468: episode_rewards = 24.0, policy_loss = 172.0723876953125, value_loss = 3889.938720703125\n",
      "469: episode_rewards = 51.0, policy_loss = 707.0780639648438, value_loss = 30541.455078125\n",
      "470: episode_rewards = 24.0, policy_loss = 177.75994873046875, value_loss = 3770.86083984375\n",
      "471: episode_rewards = 18.0, policy_loss = 103.23542022705078, value_loss = 1663.424072265625\n",
      "472: episode_rewards = 65.0, policy_loss = 1104.2451171875, value_loss = 57697.765625\n",
      "473: episode_rewards = 18.0, policy_loss = 101.93605041503906, value_loss = 1674.0263671875\n",
      "474: episode_rewards = 39.0, policy_loss = 436.665283203125, value_loss = 14807.115234375\n",
      "475: episode_rewards = 20.0, policy_loss = 125.72993469238281, value_loss = 2249.06591796875\n",
      "476: episode_rewards = 25.0, policy_loss = 183.47592163085938, value_loss = 4324.443359375\n",
      "477: episode_rewards = 26.0, policy_loss = 208.3598175048828, value_loss = 4734.50830078125\n",
      "478: episode_rewards = 43.0, policy_loss = 513.669677734375, value_loss = 19401.634765625\n",
      "479: episode_rewards = 64.0, policy_loss = 1036.922607421875, value_loss = 55701.58984375\n",
      "480: episode_rewards = 26.0, policy_loss = 207.14208984375, value_loss = 4643.80322265625\n",
      "481: episode_rewards = 16.0, policy_loss = 83.83772277832031, value_loss = 1130.8232421875\n",
      "482: episode_rewards = 54.0, policy_loss = 777.804443359375, value_loss = 35561.56640625\n",
      "483: episode_rewards = 24.0, policy_loss = 172.5537872314453, value_loss = 3827.3662109375\n",
      "484: episode_rewards = 26.0, policy_loss = 197.70887756347656, value_loss = 4790.91259765625\n",
      "485: episode_rewards = 22.0, policy_loss = 144.39456176757812, value_loss = 2930.109375\n",
      "486: episode_rewards = 19.0, policy_loss = 118.1247329711914, value_loss = 1935.6494140625\n",
      "487: episode_rewards = 56.0, policy_loss = 821.3402709960938, value_loss = 38939.7890625\n",
      "488: episode_rewards = 45.0, policy_loss = 561.6058349609375, value_loss = 21706.54296875\n",
      "489: episode_rewards = 51.0, policy_loss = 715.2176513671875, value_loss = 30393.8046875\n",
      "490: episode_rewards = 43.0, policy_loss = 514.3626708984375, value_loss = 19238.373046875\n",
      "491: episode_rewards = 38.0, policy_loss = 412.1862487792969, value_loss = 13639.2294921875\n",
      "492: episode_rewards = 84.0, policy_loss = 1703.1329345703125, value_loss = 109297.109375\n",
      "493: episode_rewards = 31.0, policy_loss = 274.7948303222656, value_loss = 7827.5693359375\n",
      "494: episode_rewards = 46.0, policy_loss = 590.24755859375, value_loss = 22886.33984375\n",
      "495: episode_rewards = 14.0, policy_loss = 60.618595123291016, value_loss = 751.4137573242188\n",
      "496: episode_rewards = 23.0, policy_loss = 163.1883544921875, value_loss = 3277.06201171875\n",
      "497: episode_rewards = 59.0, policy_loss = 903.5059814453125, value_loss = 44735.8046875\n",
      "498: episode_rewards = 21.0, policy_loss = 134.011474609375, value_loss = 2474.20703125\n",
      "499: episode_rewards = 23.0, policy_loss = 152.917724609375, value_loss = 3281.395751953125\n",
      "500: episode_rewards = 47.0, policy_loss = 594.3062133789062, value_loss = 24305.8984375\n",
      "501: episode_rewards = 40.0, policy_loss = 437.4314880371094, value_loss = 15822.5458984375\n",
      "502: episode_rewards = 36.0, policy_loss = 376.61273193359375, value_loss = 11623.830078125\n",
      "503: episode_rewards = 14.0, policy_loss = 65.7770004272461, value_loss = 758.695068359375\n",
      "504: episode_rewards = 57.0, policy_loss = 858.5844116210938, value_loss = 40483.87890625\n",
      "505: episode_rewards = 40.0, policy_loss = 430.13800048828125, value_loss = 15717.3193359375\n",
      "506: episode_rewards = 34.0, policy_loss = 341.8001708984375, value_loss = 9877.7490234375\n",
      "507: episode_rewards = 47.0, policy_loss = 595.5575561523438, value_loss = 24194.078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-27 23:04:30,451] Starting new video recorder writing to /Users/fchua/Documents/torch_projects/pytorch_tutorials/pytorch-deep-rl/cartpole/openaigym.video.0.68446.video000512.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508: episode_rewards = 53.0, policy_loss = 748.8604125976562, value_loss = 33394.35546875\n",
      "509: episode_rewards = 11.0, policy_loss = 39.5349235534668, value_loss = 341.63909912109375\n",
      "510: episode_rewards = 79.0, policy_loss = 1562.3243408203125, value_loss = 92948.9140625\n",
      "511: episode_rewards = 27.0, policy_loss = 211.83370971679688, value_loss = 5288.83349609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fchua/Applications/miniconda/lib/python3.5/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512: episode_rewards = 41.0, policy_loss = 464.9590759277344, value_loss = 16734.36328125\n",
      "513: episode_rewards = 38.0, policy_loss = 419.6692199707031, value_loss = 13504.271484375\n",
      "514: episode_rewards = 29.0, policy_loss = 228.746826171875, value_loss = 6417.48876953125\n",
      "515: episode_rewards = 43.0, policy_loss = 491.3747863769531, value_loss = 19053.59375\n",
      "516: episode_rewards = 11.0, policy_loss = 39.409263610839844, value_loss = 332.14190673828125\n",
      "517: episode_rewards = 67.0, policy_loss = 1187.1192626953125, value_loss = 60850.08984375\n",
      "518: episode_rewards = 28.0, policy_loss = 220.3985137939453, value_loss = 5657.56396484375\n",
      "519: episode_rewards = 46.0, policy_loss = 574.6437377929688, value_loss = 22764.142578125\n",
      "520: episode_rewards = 62.0, policy_loss = 987.9254150390625, value_loss = 49994.92578125\n",
      "521: episode_rewards = 26.0, policy_loss = 187.7287139892578, value_loss = 4585.43212890625\n",
      "522: episode_rewards = 33.0, policy_loss = 297.2423400878906, value_loss = 9072.728515625\n",
      "523: episode_rewards = 44.0, policy_loss = 537.4188842773438, value_loss = 20082.5234375\n",
      "524: episode_rewards = 23.0, policy_loss = 153.94261169433594, value_loss = 3258.423828125\n",
      "525: episode_rewards = 11.0, policy_loss = 39.36582946777344, value_loss = 324.1832275390625\n",
      "526: episode_rewards = 36.0, policy_loss = 351.5403137207031, value_loss = 11520.201171875\n",
      "527: episode_rewards = 172.0, policy_loss = 5754.77001953125, value_loss = 552344.0625\n",
      "528: episode_rewards = 16.0, policy_loss = 88.587646484375, value_loss = 1100.0850830078125\n",
      "529: episode_rewards = 35.0, policy_loss = 354.82861328125, value_loss = 10687.2802734375\n",
      "530: episode_rewards = 29.0, policy_loss = 248.05734252929688, value_loss = 6042.330078125\n",
      "531: episode_rewards = 25.0, policy_loss = 179.65663146972656, value_loss = 4014.26416015625\n",
      "532: episode_rewards = 34.0, policy_loss = 316.4290771484375, value_loss = 9738.5537109375\n",
      "533: episode_rewards = 96.0, policy_loss = 2154.3525390625, value_loss = 149665.875\n",
      "534: episode_rewards = 38.0, policy_loss = 388.9792785644531, value_loss = 13427.5986328125\n",
      "535: episode_rewards = 39.0, policy_loss = 437.7017517089844, value_loss = 14104.392578125\n",
      "536: episode_rewards = 20.0, policy_loss = 121.15811920166016, value_loss = 2044.4989013671875\n",
      "537: episode_rewards = 25.0, policy_loss = 171.18385314941406, value_loss = 4041.40380859375\n",
      "538: episode_rewards = 27.0, policy_loss = 197.5764923095703, value_loss = 5104.740234375\n",
      "539: episode_rewards = 37.0, policy_loss = 374.03546142578125, value_loss = 12166.2021484375\n",
      "540: episode_rewards = 15.0, policy_loss = 85.12223052978516, value_loss = 847.34716796875\n",
      "541: episode_rewards = 25.0, policy_loss = 188.6261749267578, value_loss = 4048.047119140625\n",
      "542: episode_rewards = 23.0, policy_loss = 145.77374267578125, value_loss = 3133.11767578125\n",
      "543: episode_rewards = 25.0, policy_loss = 183.87977600097656, value_loss = 4079.758544921875\n",
      "544: episode_rewards = 31.0, policy_loss = 258.7830810546875, value_loss = 7483.4560546875\n",
      "545: episode_rewards = 32.0, policy_loss = 277.7762756347656, value_loss = 8189.08984375\n",
      "546: episode_rewards = 12.0, policy_loss = 52.03298568725586, value_loss = 436.37347412109375\n",
      "547: episode_rewards = 42.0, policy_loss = 478.5267028808594, value_loss = 17311.666015625\n",
      "548: episode_rewards = 47.0, policy_loss = 589.9232788085938, value_loss = 23692.431640625\n",
      "549: episode_rewards = 41.0, policy_loss = 471.0545349121094, value_loss = 16239.587890625\n",
      "550: episode_rewards = 47.0, policy_loss = 600.9494018554688, value_loss = 23590.259765625\n",
      "551: episode_rewards = 42.0, policy_loss = 471.8846130371094, value_loss = 17607.89453125\n",
      "552: episode_rewards = 86.0, policy_loss = 1756.5748291015625, value_loss = 113534.0859375\n",
      "553: episode_rewards = 30.0, policy_loss = 248.5101318359375, value_loss = 6679.662109375\n",
      "554: episode_rewards = 23.0, policy_loss = 143.34661865234375, value_loss = 3130.517578125\n",
      "555: episode_rewards = 21.0, policy_loss = 129.53741455078125, value_loss = 2310.9931640625\n",
      "556: episode_rewards = 27.0, policy_loss = 205.7501983642578, value_loss = 4864.734375\n",
      "557: episode_rewards = 27.0, policy_loss = 194.99888610839844, value_loss = 5021.09619140625\n",
      "558: episode_rewards = 31.0, policy_loss = 267.58856201171875, value_loss = 7277.96533203125\n",
      "559: episode_rewards = 48.0, policy_loss = 631.0137939453125, value_loss = 24843.498046875\n",
      "560: episode_rewards = 20.0, policy_loss = 110.17911529541016, value_loss = 2033.6573486328125\n",
      "561: episode_rewards = 12.0, policy_loss = 42.39986801147461, value_loss = 405.3576354980469\n",
      "562: episode_rewards = 57.0, policy_loss = 869.7337036132812, value_loss = 39018.07421875\n",
      "563: episode_rewards = 33.0, policy_loss = 289.45111083984375, value_loss = 8789.7294921875\n",
      "564: episode_rewards = 27.0, policy_loss = 207.7748565673828, value_loss = 4891.21533203125\n",
      "565: episode_rewards = 46.0, policy_loss = 557.879638671875, value_loss = 22078.10546875\n",
      "566: episode_rewards = 33.0, policy_loss = 306.3204650878906, value_loss = 8898.9453125\n",
      "567: episode_rewards = 28.0, policy_loss = 219.61358642578125, value_loss = 5386.0458984375\n",
      "568: episode_rewards = 21.0, policy_loss = 139.43072509765625, value_loss = 2353.57275390625\n",
      "569: episode_rewards = 19.0, policy_loss = 119.43880462646484, value_loss = 1760.12646484375\n",
      "570: episode_rewards = 18.0, policy_loss = 91.56982421875, value_loss = 1457.4600830078125\n",
      "571: episode_rewards = 77.0, policy_loss = 1466.9478759765625, value_loss = 85619.3203125\n",
      "572: episode_rewards = 49.0, policy_loss = 618.215576171875, value_loss = 26321.36328125\n",
      "573: episode_rewards = 17.0, policy_loss = 77.84638977050781, value_loss = 1230.5458984375\n",
      "574: episode_rewards = 62.0, policy_loss = 994.5729370117188, value_loss = 48846.03125\n",
      "575: episode_rewards = 47.0, policy_loss = 586.7775268554688, value_loss = 23520.322265625\n",
      "576: episode_rewards = 39.0, policy_loss = 401.32275390625, value_loss = 14014.248046875\n",
      "577: episode_rewards = 33.0, policy_loss = 296.1977233886719, value_loss = 8589.1708984375\n",
      "578: episode_rewards = 73.0, policy_loss = 1352.6461181640625, value_loss = 74816.203125\n",
      "579: episode_rewards = 30.0, policy_loss = 242.01565551757812, value_loss = 6653.89208984375\n",
      "580: episode_rewards = 166.0, policy_loss = 5499.65478515625, value_loss = 506241.5625\n",
      "581: episode_rewards = 29.0, policy_loss = 228.98825073242188, value_loss = 5963.37451171875\n",
      "582: episode_rewards = 82.0, policy_loss = 1682.8199462890625, value_loss = 99281.4765625\n",
      "583: episode_rewards = 44.0, policy_loss = 505.65740966796875, value_loss = 19488.875\n",
      "584: episode_rewards = 15.0, policy_loss = 66.64263153076172, value_loss = 791.906982421875\n",
      "585: episode_rewards = 45.0, policy_loss = 543.6043701171875, value_loss = 20706.888671875\n",
      "586: episode_rewards = 82.0, policy_loss = 1596.39599609375, value_loss = 100125.8359375\n",
      "587: episode_rewards = 19.0, policy_loss = 98.36546325683594, value_loss = 1714.7637939453125\n",
      "588: episode_rewards = 52.0, policy_loss = 709.846435546875, value_loss = 30809.611328125\n",
      "589: episode_rewards = 54.0, policy_loss = 778.846923828125, value_loss = 33649.71875\n",
      "590: episode_rewards = 40.0, policy_loss = 420.95904541015625, value_loss = 14859.9375\n",
      "591: episode_rewards = 20.0, policy_loss = 108.9612808227539, value_loss = 1987.872314453125\n",
      "592: episode_rewards = 31.0, policy_loss = 256.22650146484375, value_loss = 7228.10205078125\n",
      "593: episode_rewards = 51.0, policy_loss = 657.5467529296875, value_loss = 28989.857421875\n",
      "594: episode_rewards = 32.0, policy_loss = 281.92291259765625, value_loss = 7997.67529296875\n",
      "595: episode_rewards = 13.0, policy_loss = 54.406654357910156, value_loss = 525.916748046875\n",
      "596: episode_rewards = 45.0, policy_loss = 531.3740234375, value_loss = 20739.353515625\n",
      "597: episode_rewards = 38.0, policy_loss = 386.25750732421875, value_loss = 12741.71875\n",
      "598: episode_rewards = 59.0, policy_loss = 888.4088134765625, value_loss = 42556.61328125\n",
      "599: episode_rewards = 17.0, policy_loss = 81.9310531616211, value_loss = 1196.759765625\n",
      "600: episode_rewards = 31.0, policy_loss = 252.78504943847656, value_loss = 7261.43017578125\n",
      "601: episode_rewards = 32.0, policy_loss = 284.2349853515625, value_loss = 7951.54833984375\n",
      "602: episode_rewards = 53.0, policy_loss = 731.4713134765625, value_loss = 31875.875\n",
      "603: episode_rewards = 42.0, policy_loss = 472.55029296875, value_loss = 16731.173828125\n",
      "604: episode_rewards = 29.0, policy_loss = 247.0914306640625, value_loss = 5832.08251953125\n",
      "605: episode_rewards = 50.0, policy_loss = 632.159423828125, value_loss = 27316.181640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606: episode_rewards = 58.0, policy_loss = 833.145751953125, value_loss = 40824.33203125\n",
      "607: episode_rewards = 21.0, policy_loss = 130.98768615722656, value_loss = 2248.456787109375\n",
      "608: episode_rewards = 56.0, policy_loss = 783.2951049804688, value_loss = 37311.0234375\n",
      "609: episode_rewards = 70.0, policy_loss = 1184.9638671875, value_loss = 66359.3828125\n",
      "610: episode_rewards = 16.0, policy_loss = 78.71940612792969, value_loss = 977.7740478515625\n",
      "611: episode_rewards = 69.0, policy_loss = 1197.19873046875, value_loss = 63584.98828125\n",
      "612: episode_rewards = 59.0, policy_loss = 864.4011840820312, value_loss = 42599.03515625\n",
      "613: episode_rewards = 34.0, policy_loss = 298.4146423339844, value_loss = 9311.3740234375\n",
      "614: episode_rewards = 62.0, policy_loss = 957.4479370117188, value_loss = 48242.61328125\n",
      "615: episode_rewards = 60.0, policy_loss = 897.1814575195312, value_loss = 44347.9921875\n",
      "616: episode_rewards = 42.0, policy_loss = 486.00146484375, value_loss = 16647.916015625\n",
      "617: episode_rewards = 49.0, policy_loss = 617.725341796875, value_loss = 25786.046875\n",
      "618: episode_rewards = 84.0, policy_loss = 1657.031494140625, value_loss = 104940.1484375\n",
      "619: episode_rewards = 78.0, policy_loss = 1489.866943359375, value_loss = 86690.4453125\n",
      "620: episode_rewards = 32.0, policy_loss = 281.15625, value_loss = 7770.09228515625\n",
      "621: episode_rewards = 17.0, policy_loss = 83.66120147705078, value_loss = 1197.150634765625\n",
      "622: episode_rewards = 40.0, policy_loss = 409.0635681152344, value_loss = 14658.8798828125\n",
      "623: episode_rewards = 34.0, policy_loss = 308.6794738769531, value_loss = 9283.29296875\n",
      "624: episode_rewards = 46.0, policy_loss = 563.5794067382812, value_loss = 21472.7578125\n",
      "625: episode_rewards = 63.0, policy_loss = 1010.819091796875, value_loss = 49967.4609375\n",
      "626: episode_rewards = 83.0, policy_loss = 1594.559326171875, value_loss = 101720.8671875\n",
      "627: episode_rewards = 64.0, policy_loss = 995.2914428710938, value_loss = 52462.20703125\n",
      "628: episode_rewards = 22.0, policy_loss = 138.96456909179688, value_loss = 2547.796630859375\n",
      "629: episode_rewards = 47.0, policy_loss = 570.0340576171875, value_loss = 22898.80078125\n",
      "630: episode_rewards = 24.0, policy_loss = 150.27734375, value_loss = 3416.4287109375\n",
      "631: episode_rewards = 41.0, policy_loss = 431.28460693359375, value_loss = 15745.388671875\n",
      "632: episode_rewards = 29.0, policy_loss = 241.61251831054688, value_loss = 5496.5625\n",
      "633: episode_rewards = 20.0, policy_loss = 112.0332260131836, value_loss = 1867.8154296875\n",
      "634: episode_rewards = 43.0, policy_loss = 483.8245544433594, value_loss = 17814.111328125\n",
      "635: episode_rewards = 19.0, policy_loss = 96.02873229980469, value_loss = 1673.746337890625\n",
      "636: episode_rewards = 73.0, policy_loss = 1271.7353515625, value_loss = 73099.8125\n",
      "637: episode_rewards = 52.0, policy_loss = 678.9136352539062, value_loss = 29779.625\n",
      "638: episode_rewards = 23.0, policy_loss = 143.36727905273438, value_loss = 2912.547119140625\n",
      "639: episode_rewards = 30.0, policy_loss = 244.3256378173828, value_loss = 6325.4228515625\n",
      "640: episode_rewards = 55.0, policy_loss = 782.5985717773438, value_loss = 34481.74609375\n",
      "641: episode_rewards = 47.0, policy_loss = 558.5391235351562, value_loss = 22767.083984375\n",
      "642: episode_rewards = 81.0, policy_loss = 1558.768798828125, value_loss = 94948.5078125\n",
      "643: episode_rewards = 30.0, policy_loss = 253.33114624023438, value_loss = 6177.9638671875\n",
      "644: episode_rewards = 28.0, policy_loss = 209.5766143798828, value_loss = 5201.2080078125\n",
      "645: episode_rewards = 38.0, policy_loss = 370.15386962890625, value_loss = 12474.380859375\n",
      "646: episode_rewards = 38.0, policy_loss = 382.8237609863281, value_loss = 12386.376953125\n",
      "647: episode_rewards = 63.0, policy_loss = 980.9690551757812, value_loss = 49593.078125\n",
      "648: episode_rewards = 38.0, policy_loss = 378.61517333984375, value_loss = 12393.55078125\n",
      "649: episode_rewards = 57.0, policy_loss = 784.5282592773438, value_loss = 38351.3515625\n",
      "650: episode_rewards = 33.0, policy_loss = 283.9890441894531, value_loss = 8357.1396484375\n",
      "651: episode_rewards = 33.0, policy_loss = 278.64544677734375, value_loss = 8436.095703125\n",
      "652: episode_rewards = 26.0, policy_loss = 170.13992309570312, value_loss = 4210.99658203125\n",
      "653: episode_rewards = 48.0, policy_loss = 604.122314453125, value_loss = 23629.80859375\n",
      "654: episode_rewards = 52.0, policy_loss = 678.1754150390625, value_loss = 29557.638671875\n",
      "655: episode_rewards = 115.0, policy_loss = 2957.763427734375, value_loss = 220218.859375\n",
      "656: episode_rewards = 51.0, policy_loss = 674.7696533203125, value_loss = 27895.6875\n",
      "657: episode_rewards = 29.0, policy_loss = 225.97537231445312, value_loss = 5615.138671875\n",
      "658: episode_rewards = 25.0, policy_loss = 173.65774536132812, value_loss = 3608.4052734375\n",
      "659: episode_rewards = 29.0, policy_loss = 218.6459503173828, value_loss = 5691.609375\n",
      "660: episode_rewards = 63.0, policy_loss = 960.6492919921875, value_loss = 49489.375\n",
      "661: episode_rewards = 29.0, policy_loss = 217.38401794433594, value_loss = 5581.62109375\n",
      "662: episode_rewards = 57.0, policy_loss = 837.8206176757812, value_loss = 37280.0625\n",
      "663: episode_rewards = 38.0, policy_loss = 368.4174499511719, value_loss = 12246.564453125\n",
      "664: episode_rewards = 57.0, policy_loss = 817.9114990234375, value_loss = 37618.93359375\n",
      "665: episode_rewards = 40.0, policy_loss = 407.634765625, value_loss = 14149.7138671875\n",
      "666: episode_rewards = 23.0, policy_loss = 143.5725555419922, value_loss = 2641.187255859375\n",
      "667: episode_rewards = 80.0, policy_loss = 1508.517822265625, value_loss = 90937.7578125\n",
      "668: episode_rewards = 45.0, policy_loss = 516.012451171875, value_loss = 19560.462890625\n",
      "669: episode_rewards = 14.0, policy_loss = 50.8267822265625, value_loss = 614.1220092773438\n",
      "670: episode_rewards = 28.0, policy_loss = 216.8356170654297, value_loss = 5083.5927734375\n",
      "671: episode_rewards = 38.0, policy_loss = 374.9372253417969, value_loss = 12094.302734375\n",
      "672: episode_rewards = 39.0, policy_loss = 378.4754638671875, value_loss = 13154.6181640625\n",
      "673: episode_rewards = 21.0, policy_loss = 115.97942352294922, value_loss = 1935.3544921875\n",
      "674: episode_rewards = 58.0, policy_loss = 846.7991333007812, value_loss = 39057.55078125\n",
      "675: episode_rewards = 51.0, policy_loss = 659.8067626953125, value_loss = 27837.796875\n",
      "676: episode_rewards = 75.0, policy_loss = 1332.9735107421875, value_loss = 77005.0078125\n",
      "677: episode_rewards = 48.0, policy_loss = 565.4087524414062, value_loss = 23746.279296875\n",
      "678: episode_rewards = 14.0, policy_loss = 60.088165283203125, value_loss = 559.1668090820312\n",
      "679: episode_rewards = 19.0, policy_loss = 90.94393157958984, value_loss = 1493.7401123046875\n",
      "680: episode_rewards = 18.0, policy_loss = 80.7325439453125, value_loss = 1236.6328125\n",
      "681: episode_rewards = 20.0, policy_loss = 97.82592010498047, value_loss = 1765.822509765625\n",
      "682: episode_rewards = 32.0, policy_loss = 263.55517578125, value_loss = 7239.59033203125\n",
      "683: episode_rewards = 39.0, policy_loss = 385.2415771484375, value_loss = 13125.6259765625\n",
      "684: episode_rewards = 35.0, policy_loss = 320.7904968261719, value_loss = 9675.5078125\n",
      "685: episode_rewards = 40.0, policy_loss = 432.8084411621094, value_loss = 13897.85546875\n",
      "686: episode_rewards = 25.0, policy_loss = 174.1549835205078, value_loss = 3541.668212890625\n",
      "687: episode_rewards = 80.0, policy_loss = 1468.035400390625, value_loss = 90524.3984375\n",
      "688: episode_rewards = 46.0, policy_loss = 539.9428100585938, value_loss = 20636.591796875\n",
      "689: episode_rewards = 42.0, policy_loss = 442.494873046875, value_loss = 16087.42578125\n",
      "690: episode_rewards = 69.0, policy_loss = 1130.7391357421875, value_loss = 61573.4765625\n",
      "691: episode_rewards = 59.0, policy_loss = 861.8038940429688, value_loss = 41013.98046875\n",
      "692: episode_rewards = 56.0, policy_loss = 765.9107055664062, value_loss = 35587.73828125\n",
      "693: episode_rewards = 18.0, policy_loss = 78.65194702148438, value_loss = 1267.612060546875\n",
      "694: episode_rewards = 37.0, policy_loss = 354.1192932128906, value_loss = 10989.228515625\n",
      "695: episode_rewards = 63.0, policy_loss = 942.4577026367188, value_loss = 48389.875\n",
      "696: episode_rewards = 67.0, policy_loss = 1041.05224609375, value_loss = 57380.28125\n",
      "697: episode_rewards = 16.0, policy_loss = 68.67584228515625, value_loss = 772.9588623046875\n",
      "698: episode_rewards = 34.0, policy_loss = 299.6893310546875, value_loss = 8567.248046875\n",
      "699: episode_rewards = 61.0, policy_loss = 904.801513671875, value_loss = 44200.2578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700: episode_rewards = 32.0, policy_loss = 271.5933837890625, value_loss = 7317.021484375\n",
      "701: episode_rewards = 47.0, policy_loss = 544.368408203125, value_loss = 21891.384765625\n",
      "702: episode_rewards = 49.0, policy_loss = 578.7902221679688, value_loss = 24511.68359375\n",
      "703: episode_rewards = 19.0, policy_loss = 99.107177734375, value_loss = 1518.087646484375\n",
      "704: episode_rewards = 124.0, policy_loss = 3245.630615234375, value_loss = 259369.078125\n",
      "705: episode_rewards = 32.0, policy_loss = 254.8053436279297, value_loss = 7222.4970703125\n",
      "706: episode_rewards = 36.0, policy_loss = 339.6987609863281, value_loss = 10143.71484375\n",
      "707: episode_rewards = 31.0, policy_loss = 239.6516571044922, value_loss = 6592.794921875\n",
      "708: episode_rewards = 127.0, policy_loss = 3276.797607421875, value_loss = 274250.46875\n",
      "709: episode_rewards = 29.0, policy_loss = 203.4124755859375, value_loss = 5366.72998046875\n",
      "710: episode_rewards = 12.0, policy_loss = 42.212303161621094, value_loss = 329.67291259765625\n",
      "711: episode_rewards = 30.0, policy_loss = 234.73086547851562, value_loss = 6035.6416015625\n",
      "712: episode_rewards = 20.0, policy_loss = 92.86803436279297, value_loss = 1668.0386962890625\n",
      "713: episode_rewards = 77.0, policy_loss = 1365.337646484375, value_loss = 81216.3515625\n",
      "714: episode_rewards = 49.0, policy_loss = 588.6104125976562, value_loss = 24078.1953125\n",
      "715: episode_rewards = 37.0, policy_loss = 334.3311767578125, value_loss = 10965.369140625\n",
      "716: episode_rewards = 40.0, policy_loss = 387.5801696777344, value_loss = 13902.4814453125\n",
      "717: episode_rewards = 22.0, policy_loss = 134.11468505859375, value_loss = 2057.485595703125\n",
      "718: episode_rewards = 46.0, policy_loss = 547.2005004882812, value_loss = 20220.939453125\n",
      "719: episode_rewards = 77.0, policy_loss = 1442.73779296875, value_loss = 79939.0546875\n",
      "720: episode_rewards = 27.0, policy_loss = 175.67494201660156, value_loss = 4242.61767578125\n",
      "721: episode_rewards = 62.0, policy_loss = 930.1041259765625, value_loss = 45559.30078125\n",
      "722: episode_rewards = 39.0, policy_loss = 382.4750061035156, value_loss = 12748.908203125\n",
      "723: episode_rewards = 70.0, policy_loss = 1166.6995849609375, value_loss = 62845.7734375\n",
      "724: episode_rewards = 118.0, policy_loss = 3000.447021484375, value_loss = 230478.09375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-27 23:04:42,296] Starting new video recorder writing to /Users/fchua/Documents/torch_projects/pytorch_tutorials/pytorch-deep-rl/cartpole/openaigym.video.0.68446.video000729.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725: episode_rewards = 89.0, policy_loss = 1798.2196044921875, value_loss = 115813.1953125\n",
      "726: episode_rewards = 28.0, policy_loss = 197.36737060546875, value_loss = 4541.3095703125\n",
      "727: episode_rewards = 37.0, policy_loss = 347.49468994140625, value_loss = 10883.548828125\n",
      "728: episode_rewards = 20.0, policy_loss = 104.02769470214844, value_loss = 1481.0845947265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fchua/Applications/miniconda/lib/python3.5/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729: episode_rewards = 30.0, policy_loss = 223.3844757080078, value_loss = 5687.078125\n",
      "730: episode_rewards = 16.0, policy_loss = 55.50937271118164, value_loss = 813.139892578125\n",
      "731: episode_rewards = 41.0, policy_loss = 417.5216979980469, value_loss = 14315.2861328125\n",
      "732: episode_rewards = 55.0, policy_loss = 785.9172973632812, value_loss = 32615.609375\n",
      "733: episode_rewards = 28.0, policy_loss = 188.38101196289062, value_loss = 4652.61181640625\n",
      "734: episode_rewards = 31.0, policy_loss = 229.23179626464844, value_loss = 6226.06689453125\n",
      "735: episode_rewards = 88.0, policy_loss = 1748.03955078125, value_loss = 112991.34375\n",
      "736: episode_rewards = 41.0, policy_loss = 440.6874084472656, value_loss = 13801.5947265625\n",
      "737: episode_rewards = 73.0, policy_loss = 1250.917236328125, value_loss = 70058.6328125\n",
      "738: episode_rewards = 28.0, policy_loss = 182.03945922851562, value_loss = 4654.0751953125\n",
      "739: episode_rewards = 29.0, policy_loss = 217.23587036132812, value_loss = 5120.1025390625\n",
      "740: episode_rewards = 29.0, policy_loss = 232.85330200195312, value_loss = 5282.7685546875\n",
      "741: episode_rewards = 56.0, policy_loss = 744.4683227539062, value_loss = 34448.90625\n",
      "742: episode_rewards = 38.0, policy_loss = 356.93304443359375, value_loss = 11283.2392578125\n",
      "743: episode_rewards = 25.0, policy_loss = 147.74191284179688, value_loss = 3196.6435546875\n",
      "744: episode_rewards = 17.0, policy_loss = 79.70335388183594, value_loss = 989.682373046875\n",
      "745: episode_rewards = 25.0, policy_loss = 152.40623474121094, value_loss = 3124.30078125\n",
      "746: episode_rewards = 24.0, policy_loss = 140.45941162109375, value_loss = 2765.065673828125\n",
      "747: episode_rewards = 39.0, policy_loss = 353.0307312011719, value_loss = 12426.3193359375\n",
      "748: episode_rewards = 34.0, policy_loss = 294.8797607421875, value_loss = 8285.2626953125\n",
      "749: episode_rewards = 19.0, policy_loss = 81.34756469726562, value_loss = 1350.0367431640625\n",
      "750: episode_rewards = 17.0, policy_loss = 62.920982360839844, value_loss = 861.1997680664062\n",
      "751: episode_rewards = 55.0, policy_loss = 716.1058959960938, value_loss = 32971.90625\n",
      "752: episode_rewards = 53.0, policy_loss = 664.1876831054688, value_loss = 29423.87109375\n",
      "753: episode_rewards = 17.0, policy_loss = 59.71283721923828, value_loss = 954.6638793945312\n",
      "754: episode_rewards = 23.0, policy_loss = 126.80093383789062, value_loss = 2481.21435546875\n",
      "755: episode_rewards = 35.0, policy_loss = 329.9134521484375, value_loss = 8996.8193359375\n",
      "756: episode_rewards = 22.0, policy_loss = 129.3140869140625, value_loss = 2233.248291015625\n",
      "757: episode_rewards = 69.0, policy_loss = 1105.584716796875, value_loss = 59575.0703125\n",
      "758: episode_rewards = 72.0, policy_loss = 1192.3699951171875, value_loss = 67228.375\n",
      "759: episode_rewards = 34.0, policy_loss = 283.9650573730469, value_loss = 7978.33642578125\n",
      "760: episode_rewards = 78.0, policy_loss = 1389.2679443359375, value_loss = 82193.2578125\n",
      "761: episode_rewards = 100.0, policy_loss = 2140.49755859375, value_loss = 153586.703125\n",
      "762: episode_rewards = 72.0, policy_loss = 1204.8453369140625, value_loss = 66831.1875\n",
      "763: episode_rewards = 85.0, policy_loss = 1661.9462890625, value_loss = 101154.3203125\n",
      "764: episode_rewards = 27.0, policy_loss = 166.61590576171875, value_loss = 4133.10888671875\n",
      "765: episode_rewards = 18.0, policy_loss = 74.26123809814453, value_loss = 1099.7978515625\n",
      "766: episode_rewards = 30.0, policy_loss = 212.25726318359375, value_loss = 5627.189453125\n",
      "767: episode_rewards = 74.0, policy_loss = 1289.4461669921875, value_loss = 71447.6328125\n",
      "768: episode_rewards = 30.0, policy_loss = 240.91856384277344, value_loss = 5669.958984375\n",
      "769: episode_rewards = 20.0, policy_loss = 89.4539794921875, value_loss = 1570.6480712890625\n",
      "770: episode_rewards = 69.0, policy_loss = 1111.1094970703125, value_loss = 59039.42578125\n",
      "771: episode_rewards = 63.0, policy_loss = 920.455078125, value_loss = 46477.015625\n",
      "772: episode_rewards = 151.0, policy_loss = 4315.791015625, value_loss = 395588.15625\n",
      "773: episode_rewards = 20.0, policy_loss = 93.83856201171875, value_loss = 1613.893798828125\n",
      "774: episode_rewards = 104.0, policy_loss = 2288.803466796875, value_loss = 167722.734375\n",
      "775: episode_rewards = 63.0, policy_loss = 891.7310791015625, value_loss = 46570.8828125\n",
      "776: episode_rewards = 50.0, policy_loss = 568.1251220703125, value_loss = 24720.685546875\n",
      "777: episode_rewards = 39.0, policy_loss = 361.8964538574219, value_loss = 12318.4521484375\n",
      "778: episode_rewards = 33.0, policy_loss = 271.1160888671875, value_loss = 7397.875\n",
      "779: episode_rewards = 52.0, policy_loss = 615.6500854492188, value_loss = 27570.798828125\n",
      "780: episode_rewards = 39.0, policy_loss = 384.2951354980469, value_loss = 12011.037109375\n",
      "781: episode_rewards = 42.0, policy_loss = 448.7381896972656, value_loss = 14835.7431640625\n",
      "782: episode_rewards = 28.0, policy_loss = 178.713623046875, value_loss = 4602.88427734375\n",
      "783: episode_rewards = 32.0, policy_loss = 249.98252868652344, value_loss = 6766.4755859375\n",
      "784: episode_rewards = 39.0, policy_loss = 351.2369384765625, value_loss = 12266.21875\n",
      "785: episode_rewards = 41.0, policy_loss = 417.2461242675781, value_loss = 13511.94921875\n",
      "786: episode_rewards = 41.0, policy_loss = 389.2215270996094, value_loss = 13891.21484375\n",
      "787: episode_rewards = 61.0, policy_loss = 893.4734497070312, value_loss = 41870.08984375\n",
      "788: episode_rewards = 21.0, policy_loss = 106.37513732910156, value_loss = 1809.27783203125\n",
      "789: episode_rewards = 11.0, policy_loss = 18.93056869506836, value_loss = 214.31796264648438\n",
      "790: episode_rewards = 40.0, policy_loss = 375.0263671875, value_loss = 13121.28515625\n",
      "791: episode_rewards = 94.0, policy_loss = 1939.249755859375, value_loss = 128912.609375\n",
      "792: episode_rewards = 29.0, policy_loss = 218.6276397705078, value_loss = 4822.353515625\n",
      "793: episode_rewards = 33.0, policy_loss = 253.96621704101562, value_loss = 7396.63720703125\n",
      "794: episode_rewards = 48.0, policy_loss = 528.0022583007812, value_loss = 21705.130859375\n",
      "795: episode_rewards = 62.0, policy_loss = 866.9953002929688, value_loss = 44023.12109375\n",
      "796: episode_rewards = 63.0, policy_loss = 948.2647094726562, value_loss = 45608.30078125\n",
      "797: episode_rewards = 77.0, policy_loss = 1303.3292236328125, value_loss = 77921.921875\n",
      "798: episode_rewards = 40.0, policy_loss = 389.7435607910156, value_loss = 12707.5439453125\n",
      "799: episode_rewards = 71.0, policy_loss = 1153.02197265625, value_loss = 62806.6328125\n",
      "800: episode_rewards = 61.0, policy_loss = 874.4754028320312, value_loss = 41759.9609375\n",
      "801: episode_rewards = 21.0, policy_loss = 97.37405395507812, value_loss = 1809.247802734375\n",
      "802: episode_rewards = 117.0, policy_loss = 2854.5576171875, value_loss = 218045.796875\n",
      "803: episode_rewards = 68.0, policy_loss = 1040.2149658203125, value_loss = 55970.44921875\n",
      "804: episode_rewards = 43.0, policy_loss = 427.3474426269531, value_loss = 15557.046875\n",
      "805: episode_rewards = 35.0, policy_loss = 281.9371032714844, value_loss = 8674.818359375\n",
      "806: episode_rewards = 21.0, policy_loss = 100.97715759277344, value_loss = 1712.5699462890625\n",
      "807: episode_rewards = 60.0, policy_loss = 846.5377807617188, value_loss = 39721.58984375\n",
      "808: episode_rewards = 96.0, policy_loss = 1905.278076171875, value_loss = 136262.859375\n",
      "809: episode_rewards = 69.0, policy_loss = 1100.993896484375, value_loss = 57726.08984375\n",
      "810: episode_rewards = 48.0, policy_loss = 558.9849243164062, value_loss = 21237.45703125\n",
      "811: episode_rewards = 37.0, policy_loss = 321.8056640625, value_loss = 10221.4501953125\n",
      "812: episode_rewards = 34.0, policy_loss = 261.0592956542969, value_loss = 7922.3095703125\n",
      "813: episode_rewards = 30.0, policy_loss = 249.491455078125, value_loss = 4785.60009765625\n",
      "814: episode_rewards = 94.0, policy_loss = 1970.228271484375, value_loss = 127773.9453125\n",
      "815: episode_rewards = 40.0, policy_loss = 368.2422180175781, value_loss = 12751.0732421875\n",
      "816: episode_rewards = 40.0, policy_loss = 369.6621398925781, value_loss = 12720.2470703125\n",
      "817: episode_rewards = 39.0, policy_loss = 358.62689208984375, value_loss = 11729.998046875\n",
      "818: episode_rewards = 60.0, policy_loss = 860.1177368164062, value_loss = 39096.82421875\n",
      "819: episode_rewards = 12.0, policy_loss = 27.721933364868164, value_loss = 261.30096435546875\n",
      "820: episode_rewards = 23.0, policy_loss = 134.84239196777344, value_loss = 2080.849609375\n",
      "821: episode_rewards = 26.0, policy_loss = 154.93505859375, value_loss = 3401.55078125\n",
      "822: episode_rewards = 61.0, policy_loss = 851.4513549804688, value_loss = 40896.39453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823: episode_rewards = 44.0, policy_loss = 477.3830261230469, value_loss = 16268.0771484375\n",
      "824: episode_rewards = 82.0, policy_loss = 1485.9241943359375, value_loss = 90254.796875\n",
      "825: episode_rewards = 30.0, policy_loss = 200.26678466796875, value_loss = 5337.2958984375\n",
      "826: episode_rewards = 64.0, policy_loss = 954.1470947265625, value_loss = 46756.2421875\n",
      "827: episode_rewards = 62.0, policy_loss = 886.127197265625, value_loss = 43069.92578125\n",
      "828: episode_rewards = 89.0, policy_loss = 1727.0499267578125, value_loss = 110903.5859375\n",
      "829: episode_rewards = 56.0, policy_loss = 732.3971557617188, value_loss = 32153.396484375\n",
      "830: episode_rewards = 21.0, policy_loss = 101.1202163696289, value_loss = 1668.6719970703125\n",
      "831: episode_rewards = 56.0, policy_loss = 689.8947143554688, value_loss = 32822.109375\n",
      "832: episode_rewards = 21.0, policy_loss = 95.4541244506836, value_loss = 1543.572021484375\n",
      "833: episode_rewards = 57.0, policy_loss = 736.144287109375, value_loss = 33774.97265625\n",
      "834: episode_rewards = 66.0, policy_loss = 986.6435546875, value_loss = 50907.1796875\n",
      "835: episode_rewards = 66.0, policy_loss = 959.083251953125, value_loss = 50494.74609375\n",
      "836: episode_rewards = 27.0, policy_loss = 163.49008178710938, value_loss = 3827.37646484375\n",
      "837: episode_rewards = 54.0, policy_loss = 653.891845703125, value_loss = 29443.23046875\n",
      "838: episode_rewards = 75.0, policy_loss = 1225.269775390625, value_loss = 70673.1953125\n",
      "839: episode_rewards = 49.0, policy_loss = 552.0260009765625, value_loss = 21795.59765625\n",
      "840: episode_rewards = 83.0, policy_loss = 1488.6129150390625, value_loss = 92455.28125\n",
      "841: episode_rewards = 18.0, policy_loss = 70.2201919555664, value_loss = 994.3089599609375\n",
      "842: episode_rewards = 55.0, policy_loss = 679.5198974609375, value_loss = 30818.099609375\n",
      "843: episode_rewards = 69.0, policy_loss = 1085.7291259765625, value_loss = 56750.08984375\n",
      "844: episode_rewards = 47.0, policy_loss = 505.3628845214844, value_loss = 19754.90234375\n",
      "845: episode_rewards = 137.0, policy_loss = 3548.20458984375, value_loss = 309859.4375\n",
      "846: episode_rewards = 52.0, policy_loss = 617.6572875976562, value_loss = 25695.56640625\n",
      "847: episode_rewards = 33.0, policy_loss = 244.3516845703125, value_loss = 6957.14404296875\n",
      "848: episode_rewards = 52.0, policy_loss = 606.5755004882812, value_loss = 25798.10546875\n",
      "849: episode_rewards = 41.0, policy_loss = 380.639892578125, value_loss = 13228.513671875\n",
      "850: episode_rewards = 33.0, policy_loss = 244.8358917236328, value_loss = 6924.2001953125\n",
      "851: episode_rewards = 79.0, policy_loss = 1373.185302734375, value_loss = 80541.9140625\n",
      "852: episode_rewards = 61.0, policy_loss = 825.5916748046875, value_loss = 40357.859375\n",
      "853: episode_rewards = 35.0, policy_loss = 263.7337341308594, value_loss = 8268.8876953125\n",
      "854: episode_rewards = 54.0, policy_loss = 674.4169921875, value_loss = 28757.884765625\n",
      "855: episode_rewards = 91.0, policy_loss = 1705.5594482421875, value_loss = 115432.8125\n",
      "856: episode_rewards = 17.0, policy_loss = 61.12535095214844, value_loss = 771.9342651367188\n",
      "857: episode_rewards = 68.0, policy_loss = 993.753173828125, value_loss = 54266.9140625\n",
      "858: episode_rewards = 23.0, policy_loss = 113.87513732910156, value_loss = 2035.802734375\n",
      "859: episode_rewards = 87.0, policy_loss = 1638.9849853515625, value_loss = 102895.75\n",
      "860: episode_rewards = 44.0, policy_loss = 462.983642578125, value_loss = 15905.4287109375\n",
      "861: episode_rewards = 44.0, policy_loss = 454.7134704589844, value_loss = 15455.267578125\n",
      "862: episode_rewards = 76.0, policy_loss = 1247.3447265625, value_loss = 71971.28125\n",
      "863: episode_rewards = 88.0, policy_loss = 1611.5606689453125, value_loss = 106173.1328125\n",
      "864: episode_rewards = 34.0, policy_loss = 276.3973388671875, value_loss = 7206.4921875\n",
      "865: episode_rewards = 79.0, policy_loss = 1352.839599609375, value_loss = 79689.2109375\n",
      "866: episode_rewards = 72.0, policy_loss = 1111.330810546875, value_loss = 62710.0546875\n",
      "867: episode_rewards = 47.0, policy_loss = 496.08453369140625, value_loss = 19169.02734375\n",
      "868: episode_rewards = 23.0, policy_loss = 106.82842254638672, value_loss = 2067.69580078125\n",
      "869: episode_rewards = 77.0, policy_loss = 1258.498291015625, value_loss = 75162.828125\n",
      "870: episode_rewards = 29.0, policy_loss = 178.6163330078125, value_loss = 4281.6845703125\n",
      "871: episode_rewards = 26.0, policy_loss = 154.32217407226562, value_loss = 2799.0849609375\n",
      "872: episode_rewards = 69.0, policy_loss = 1010.3737182617188, value_loss = 55219.73828125\n",
      "873: episode_rewards = 78.0, policy_loss = 1260.9915771484375, value_loss = 77463.453125\n",
      "874: episode_rewards = 25.0, policy_loss = 149.97222900390625, value_loss = 2645.35302734375\n",
      "875: episode_rewards = 26.0, policy_loss = 150.7454833984375, value_loss = 3057.89892578125\n",
      "876: episode_rewards = 38.0, policy_loss = 322.7953796386719, value_loss = 9882.3984375\n",
      "877: episode_rewards = 39.0, policy_loss = 327.53363037109375, value_loss = 11061.2255859375\n",
      "878: episode_rewards = 53.0, policy_loss = 607.9192504882812, value_loss = 26565.01171875\n",
      "879: episode_rewards = 65.0, policy_loss = 915.746826171875, value_loss = 46949.80078125\n",
      "880: episode_rewards = 85.0, policy_loss = 1500.2718505859375, value_loss = 95353.9453125\n",
      "881: episode_rewards = 33.0, policy_loss = 255.5563201904297, value_loss = 6115.8583984375\n",
      "882: episode_rewards = 74.0, policy_loss = 1143.3485107421875, value_loss = 66330.8203125\n",
      "883: episode_rewards = 48.0, policy_loss = 499.44671630859375, value_loss = 19794.69140625\n",
      "884: episode_rewards = 55.0, policy_loss = 713.52001953125, value_loss = 28638.78515625\n",
      "885: episode_rewards = 33.0, policy_loss = 229.67495727539062, value_loss = 6612.7880859375\n",
      "886: episode_rewards = 33.0, policy_loss = 224.5258331298828, value_loss = 6385.5224609375\n",
      "887: episode_rewards = 43.0, policy_loss = 393.1745300292969, value_loss = 14321.3505859375\n",
      "888: episode_rewards = 45.0, policy_loss = 447.759521484375, value_loss = 16317.345703125\n",
      "889: episode_rewards = 30.0, policy_loss = 191.8737030029297, value_loss = 4835.720703125\n",
      "890: episode_rewards = 57.0, policy_loss = 743.3126220703125, value_loss = 32261.724609375\n",
      "891: episode_rewards = 49.0, policy_loss = 511.35064697265625, value_loss = 21318.20703125\n",
      "892: episode_rewards = 99.0, policy_loss = 1981.52392578125, value_loss = 139537.6875\n",
      "893: episode_rewards = 21.0, policy_loss = 92.01211547851562, value_loss = 1244.88623046875\n",
      "894: episode_rewards = 47.0, policy_loss = 527.2804565429688, value_loss = 17939.76953125\n",
      "895: episode_rewards = 45.0, policy_loss = 414.7959289550781, value_loss = 16516.498046875\n",
      "896: episode_rewards = 41.0, policy_loss = 366.6659240722656, value_loss = 12589.435546875\n",
      "897: episode_rewards = 54.0, policy_loss = 655.6563110351562, value_loss = 27371.50390625\n",
      "898: episode_rewards = 67.0, policy_loss = 965.71923828125, value_loss = 50336.765625\n",
      "899: episode_rewards = 59.0, policy_loss = 757.5133666992188, value_loss = 35071.68359375\n",
      "900: episode_rewards = 41.0, policy_loss = 374.038818359375, value_loss = 12450.001953125\n",
      "901: episode_rewards = 31.0, policy_loss = 224.71484375, value_loss = 4647.376953125\n",
      "902: episode_rewards = 118.0, policy_loss = 2639.365478515625, value_loss = 213234.5\n",
      "903: episode_rewards = 66.0, policy_loss = 970.009765625, value_loss = 47869.4921875\n",
      "904: episode_rewards = 22.0, policy_loss = 92.72384643554688, value_loss = 1704.6715087890625\n",
      "905: episode_rewards = 34.0, policy_loss = 270.2690124511719, value_loss = 6817.552734375\n",
      "906: episode_rewards = 25.0, policy_loss = 112.11318969726562, value_loss = 2573.02978515625\n",
      "907: episode_rewards = 66.0, policy_loss = 911.7764282226562, value_loss = 47698.77734375\n",
      "908: episode_rewards = 120.0, policy_loss = 2789.085693359375, value_loss = 221558.5625\n",
      "909: episode_rewards = 57.0, policy_loss = 692.7764892578125, value_loss = 32058.041015625\n",
      "910: episode_rewards = 14.0, policy_loss = 30.355165481567383, value_loss = 371.00439453125\n",
      "911: episode_rewards = 75.0, policy_loss = 1289.8463134765625, value_loss = 65962.203125\n",
      "912: episode_rewards = 43.0, policy_loss = 381.408447265625, value_loss = 13809.1630859375\n",
      "913: episode_rewards = 84.0, policy_loss = 1481.793701171875, value_loss = 90619.6328125\n",
      "914: episode_rewards = 28.0, policy_loss = 178.725341796875, value_loss = 3630.84326171875\n",
      "915: episode_rewards = 56.0, policy_loss = 712.5361328125, value_loss = 30083.39453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916: episode_rewards = 39.0, policy_loss = 332.1866760253906, value_loss = 10134.4033203125\n",
      "917: episode_rewards = 41.0, policy_loss = 353.9958801269531, value_loss = 12254.5166015625\n",
      "918: episode_rewards = 33.0, policy_loss = 229.87318420410156, value_loss = 6296.951171875\n",
      "919: episode_rewards = 37.0, policy_loss = 285.54229736328125, value_loss = 8928.4638671875\n",
      "920: episode_rewards = 58.0, policy_loss = 711.4275512695312, value_loss = 32989.609375\n",
      "921: episode_rewards = 96.0, policy_loss = 1960.4896240234375, value_loss = 125583.4921875\n",
      "922: episode_rewards = 97.0, policy_loss = 1932.4112548828125, value_loss = 130020.953125\n",
      "923: episode_rewards = 58.0, policy_loss = 726.578369140625, value_loss = 33180.7890625\n",
      "924: episode_rewards = 37.0, policy_loss = 275.35894775390625, value_loss = 9015.986328125\n",
      "925: episode_rewards = 14.0, policy_loss = 25.628267288208008, value_loss = 365.03216552734375\n",
      "926: episode_rewards = 40.0, policy_loss = 321.34722900390625, value_loss = 11051.822265625\n",
      "927: episode_rewards = 33.0, policy_loss = 248.6548614501953, value_loss = 5913.80859375\n",
      "928: episode_rewards = 103.0, policy_loss = 2114.529052734375, value_loss = 150816.5625\n",
      "929: episode_rewards = 25.0, policy_loss = 119.4383544921875, value_loss = 2324.489013671875\n",
      "930: episode_rewards = 37.0, policy_loss = 277.2020263671875, value_loss = 8453.5439453125\n",
      "931: episode_rewards = 48.0, policy_loss = 485.96954345703125, value_loss = 19068.63671875\n",
      "932: episode_rewards = 72.0, policy_loss = 1070.2550048828125, value_loss = 59657.59375\n",
      "933: episode_rewards = 56.0, policy_loss = 683.3189697265625, value_loss = 29865.142578125\n",
      "934: episode_rewards = 29.0, policy_loss = 157.8743896484375, value_loss = 4143.13623046875\n",
      "935: episode_rewards = 140.0, policy_loss = 3582.982666015625, value_loss = 310545.875\n",
      "936: episode_rewards = 68.0, policy_loss = 983.5399780273438, value_loss = 50208.09375\n",
      "937: episode_rewards = 80.0, policy_loss = 1391.736083984375, value_loss = 77994.1015625\n",
      "938: episode_rewards = 39.0, policy_loss = 303.8207092285156, value_loss = 10024.947265625\n",
      "939: episode_rewards = 35.0, policy_loss = 265.2972106933594, value_loss = 7140.85693359375\n",
      "940: episode_rewards = 46.0, policy_loss = 456.11627197265625, value_loss = 16253.8212890625\n",
      "941: episode_rewards = 56.0, policy_loss = 694.4364624023438, value_loss = 29679.912109375\n",
      "942: episode_rewards = 35.0, policy_loss = 251.91973876953125, value_loss = 6816.89404296875\n",
      "943: episode_rewards = 67.0, policy_loss = 948.5482788085938, value_loss = 48120.234375\n",
      "944: episode_rewards = 60.0, policy_loss = 734.258544921875, value_loss = 35668.1484375\n",
      "945: episode_rewards = 56.0, policy_loss = 681.55419921875, value_loss = 29248.341796875\n",
      "946: episode_rewards = 16.0, policy_loss = 41.92262268066406, value_loss = 498.1535339355469\n",
      "947: episode_rewards = 61.0, policy_loss = 794.9984130859375, value_loss = 37432.98046875\n",
      "948: episode_rewards = 108.0, policy_loss = 2312.669921875, value_loss = 166611.703125\n",
      "949: episode_rewards = 43.0, policy_loss = 368.570068359375, value_loss = 13459.423828125\n",
      "950: episode_rewards = 49.0, policy_loss = 519.0692749023438, value_loss = 20030.828125\n",
      "951: episode_rewards = 51.0, policy_loss = 547.58935546875, value_loss = 22369.615234375\n",
      "952: episode_rewards = 62.0, policy_loss = 787.09423828125, value_loss = 38589.953125\n",
      "953: episode_rewards = 88.0, policy_loss = 1586.2584228515625, value_loss = 98587.734375\n",
      "954: episode_rewards = 43.0, policy_loss = 369.08953857421875, value_loss = 13104.2958984375\n",
      "955: episode_rewards = 44.0, policy_loss = 407.9685974121094, value_loss = 13668.2265625\n",
      "956: episode_rewards = 48.0, policy_loss = 483.7347412109375, value_loss = 17822.15234375\n",
      "957: episode_rewards = 22.0, policy_loss = 96.94378662109375, value_loss = 1423.33935546875\n",
      "958: episode_rewards = 41.0, policy_loss = 342.1015625, value_loss = 11132.044921875\n",
      "959: episode_rewards = 42.0, policy_loss = 369.98431396484375, value_loss = 12523.9150390625\n",
      "960: episode_rewards = 92.0, policy_loss = 1683.2747802734375, value_loss = 111415.53125\n",
      "961: episode_rewards = 60.0, policy_loss = 774.45947265625, value_loss = 35165.203125\n",
      "962: episode_rewards = 43.0, policy_loss = 375.66851806640625, value_loss = 13414.1328125\n",
      "963: episode_rewards = 50.0, policy_loss = 534.2949829101562, value_loss = 20969.0546875\n",
      "964: episode_rewards = 64.0, policy_loss = 809.073974609375, value_loss = 42079.51953125\n",
      "965: episode_rewards = 43.0, policy_loss = 412.85748291015625, value_loss = 13132.3720703125\n",
      "966: episode_rewards = 31.0, policy_loss = 184.54071044921875, value_loss = 4415.546875\n",
      "967: episode_rewards = 55.0, policy_loss = 638.2940673828125, value_loss = 26742.0859375\n",
      "968: episode_rewards = 52.0, policy_loss = 537.2146606445312, value_loss = 23067.361328125\n",
      "969: episode_rewards = 34.0, policy_loss = 228.808349609375, value_loss = 5962.0830078125\n",
      "970: episode_rewards = 134.0, policy_loss = 3293.126220703125, value_loss = 275489.46875\n",
      "971: episode_rewards = 30.0, policy_loss = 154.2989044189453, value_loss = 4171.27392578125\n",
      "972: episode_rewards = 64.0, policy_loss = 824.00927734375, value_loss = 41741.328125\n",
      "973: episode_rewards = 39.0, policy_loss = 294.2175598144531, value_loss = 9958.298828125\n",
      "974: episode_rewards = 29.0, policy_loss = 149.01315307617188, value_loss = 3484.649658203125\n",
      "975: episode_rewards = 28.0, policy_loss = 144.32577514648438, value_loss = 2985.14013671875\n",
      "976: episode_rewards = 51.0, policy_loss = 529.1023559570312, value_loss = 21850.361328125\n",
      "977: episode_rewards = 117.0, policy_loss = 2592.7978515625, value_loss = 199629.390625\n",
      "978: episode_rewards = 66.0, policy_loss = 938.888916015625, value_loss = 43846.2734375\n",
      "979: episode_rewards = 95.0, policy_loss = 1767.093505859375, value_loss = 118986.375\n",
      "980: episode_rewards = 148.0, policy_loss = 3968.79345703125, value_loss = 344872.34375\n",
      "981: episode_rewards = 121.0, policy_loss = 2738.5458984375, value_loss = 215523.8125\n",
      "982: episode_rewards = 48.0, policy_loss = 468.3612060546875, value_loss = 17561.52734375\n",
      "983: episode_rewards = 99.0, policy_loss = 1893.3299560546875, value_loss = 132182.4375\n",
      "984: episode_rewards = 51.0, policy_loss = 528.9882202148438, value_loss = 21831.58984375\n",
      "985: episode_rewards = 44.0, policy_loss = 406.6097717285156, value_loss = 13780.177734375\n",
      "986: episode_rewards = 52.0, policy_loss = 526.3678588867188, value_loss = 23070.12890625\n",
      "987: episode_rewards = 45.0, policy_loss = 421.8572082519531, value_loss = 14879.708984375\n",
      "988: episode_rewards = 40.0, policy_loss = 301.9411315917969, value_loss = 10484.0244140625\n",
      "989: episode_rewards = 40.0, policy_loss = 302.743896484375, value_loss = 10441.0126953125\n",
      "990: episode_rewards = 44.0, policy_loss = 404.9686584472656, value_loss = 13800.080078125\n",
      "991: episode_rewards = 60.0, policy_loss = 696.918701171875, value_loss = 33613.66796875\n",
      "992: episode_rewards = 42.0, policy_loss = 347.10626220703125, value_loss = 12006.16796875\n",
      "993: episode_rewards = 36.0, policy_loss = 253.21311950683594, value_loss = 7414.16796875\n",
      "994: episode_rewards = 72.0, policy_loss = 1121.2991943359375, value_loss = 55925.23828125\n",
      "995: episode_rewards = 24.0, policy_loss = 103.2650146484375, value_loss = 1915.4814453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-27 23:04:59,758] Starting new video recorder writing to /Users/fchua/Documents/torch_projects/pytorch_tutorials/pytorch-deep-rl/cartpole/openaigym.video.0.68446.video001000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996: episode_rewards = 74.0, policy_loss = 1084.1488037109375, value_loss = 60138.9453125\n",
      "997: episode_rewards = 39.0, policy_loss = 302.07061767578125, value_loss = 9440.109375\n",
      "998: episode_rewards = 24.0, policy_loss = 113.22563934326172, value_loss = 1781.8216552734375\n",
      "999: episode_rewards = 26.0, policy_loss = 124.0686264038086, value_loss = 2425.11669921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fchua/Applications/miniconda/lib/python3.5/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000: episode_rewards = 42.0, policy_loss = 338.2337951660156, value_loss = 11852.255859375\n",
      "1001: episode_rewards = 14.0, policy_loss = 14.212600708007812, value_loss = 323.1676025390625\n",
      "1002: episode_rewards = 106.0, policy_loss = 2121.61376953125, value_loss = 154848.421875\n",
      "1003: episode_rewards = 102.0, policy_loss = 1987.2374267578125, value_loss = 140460.0\n",
      "1004: episode_rewards = 39.0, policy_loss = 287.4305725097656, value_loss = 9289.15625\n",
      "1005: episode_rewards = 24.0, policy_loss = 99.23936462402344, value_loss = 1848.3311767578125\n",
      "1006: episode_rewards = 20.0, policy_loss = 55.9886474609375, value_loss = 974.9815673828125\n",
      "1007: episode_rewards = 53.0, policy_loss = 548.1070556640625, value_loss = 23365.234375\n",
      "1008: episode_rewards = 43.0, policy_loss = 361.15081787109375, value_loss = 12471.42578125\n",
      "1009: episode_rewards = 34.0, policy_loss = 234.97120666503906, value_loss = 5842.82373046875\n",
      "1010: episode_rewards = 20.0, policy_loss = 50.75023651123047, value_loss = 990.221435546875\n",
      "1011: episode_rewards = 154.0, policy_loss = 4090.104248046875, value_loss = 370770.21875\n",
      "1012: episode_rewards = 34.0, policy_loss = 211.41845703125, value_loss = 6071.884765625\n",
      "1013: episode_rewards = 126.0, policy_loss = 2957.5283203125, value_loss = 234383.546875\n",
      "1014: episode_rewards = 44.0, policy_loss = 385.293701171875, value_loss = 13280.783203125\n",
      "1015: episode_rewards = 54.0, policy_loss = 628.0089111328125, value_loss = 24160.189453125\n",
      "1016: episode_rewards = 79.0, policy_loss = 1210.05615234375, value_loss = 71027.8125\n",
      "1017: episode_rewards = 31.0, policy_loss = 171.2132568359375, value_loss = 4352.4150390625\n",
      "1018: episode_rewards = 69.0, policy_loss = 992.1658935546875, value_loss = 48168.3125\n",
      "1019: episode_rewards = 61.0, policy_loss = 713.781982421875, value_loss = 34257.84765625\n",
      "1020: episode_rewards = 76.0, policy_loss = 1187.631103515625, value_loss = 64075.41015625\n",
      "1021: episode_rewards = 70.0, policy_loss = 984.4815063476562, value_loss = 51081.36328125\n",
      "1022: episode_rewards = 35.0, policy_loss = 233.5877685546875, value_loss = 6444.78759765625\n",
      "1023: episode_rewards = 49.0, policy_loss = 453.0544738769531, value_loss = 17744.775390625\n",
      "1024: episode_rewards = 67.0, policy_loss = 875.11474609375, value_loss = 45462.87109375\n",
      "1025: episode_rewards = 114.0, policy_loss = 2535.80078125, value_loss = 179757.109375\n",
      "1026: episode_rewards = 90.0, policy_loss = 1542.0113525390625, value_loss = 99519.6015625\n",
      "1027: episode_rewards = 24.0, policy_loss = 97.19954681396484, value_loss = 1696.493408203125\n",
      "1028: episode_rewards = 51.0, policy_loss = 488.2420654296875, value_loss = 20224.1953125\n",
      "1029: episode_rewards = 30.0, policy_loss = 146.537109375, value_loss = 3535.685546875\n",
      "1030: episode_rewards = 51.0, policy_loss = 508.748779296875, value_loss = 20440.83203125\n",
      "1031: episode_rewards = 86.0, policy_loss = 1439.871826171875, value_loss = 87229.734375\n",
      "1032: episode_rewards = 42.0, policy_loss = 329.28070068359375, value_loss = 11108.28125\n",
      "1033: episode_rewards = 32.0, policy_loss = 203.2904815673828, value_loss = 4732.396484375\n",
      "1034: episode_rewards = 53.0, policy_loss = 556.3538818359375, value_loss = 22246.1015625\n",
      "1035: episode_rewards = 40.0, policy_loss = 288.6676025390625, value_loss = 9262.3857421875\n",
      "1036: episode_rewards = 35.0, policy_loss = 227.0277862548828, value_loss = 6308.0546875\n",
      "1037: episode_rewards = 37.0, policy_loss = 234.88282775878906, value_loss = 7262.359375\n",
      "1038: episode_rewards = 104.0, policy_loss = 2010.672119140625, value_loss = 144445.609375\n",
      "1039: episode_rewards = 25.0, policy_loss = 93.17423248291016, value_loss = 1779.580078125\n",
      "1040: episode_rewards = 106.0, policy_loss = 2245.924072265625, value_loss = 149240.953125\n",
      "1041: episode_rewards = 58.0, policy_loss = 659.7702026367188, value_loss = 29661.23046875\n",
      "1042: episode_rewards = 145.0, policy_loss = 3751.69287109375, value_loss = 315669.96875\n",
      "1043: episode_rewards = 91.0, policy_loss = 1654.4212646484375, value_loss = 101346.3046875\n",
      "1044: episode_rewards = 76.0, policy_loss = 1105.729736328125, value_loss = 62857.15234375\n",
      "1045: episode_rewards = 64.0, policy_loss = 782.199462890625, value_loss = 38611.5859375\n",
      "1046: episode_rewards = 23.0, policy_loss = 89.79949188232422, value_loss = 993.3660888671875\n",
      "1047: episode_rewards = 33.0, policy_loss = 190.30975341796875, value_loss = 5058.1494140625\n",
      "1048: episode_rewards = 35.0, policy_loss = 223.0377960205078, value_loss = 6224.33056640625\n",
      "1049: episode_rewards = 25.0, policy_loss = 98.54513549804688, value_loss = 1984.4788818359375\n",
      "1050: episode_rewards = 37.0, policy_loss = 264.9231262207031, value_loss = 6532.5078125\n",
      "1051: episode_rewards = 44.0, policy_loss = 355.51190185546875, value_loss = 12294.4453125\n",
      "1052: episode_rewards = 42.0, policy_loss = 316.010986328125, value_loss = 10209.078125\n",
      "1053: episode_rewards = 36.0, policy_loss = 219.26573181152344, value_loss = 6340.39794921875\n",
      "1054: episode_rewards = 89.0, policy_loss = 1555.553466796875, value_loss = 94820.1171875\n",
      "1055: episode_rewards = 62.0, policy_loss = 762.0531616210938, value_loss = 35319.8359375\n",
      "1056: episode_rewards = 38.0, policy_loss = 260.5626525878906, value_loss = 7928.740234375\n",
      "1057: episode_rewards = 54.0, policy_loss = 565.1116943359375, value_loss = 23400.951171875\n",
      "1058: episode_rewards = 50.0, policy_loss = 467.9608459472656, value_loss = 18306.234375\n",
      "1059: episode_rewards = 35.0, policy_loss = 229.39405822753906, value_loss = 5348.9375\n",
      "1060: episode_rewards = 38.0, policy_loss = 253.21951293945312, value_loss = 7973.19384765625\n",
      "1061: episode_rewards = 52.0, policy_loss = 503.4289245605469, value_loss = 20815.259765625\n",
      "1062: episode_rewards = 63.0, policy_loss = 766.6358032226562, value_loss = 35681.80078125\n",
      "1063: episode_rewards = 29.0, policy_loss = 141.65692138671875, value_loss = 3219.785888671875\n",
      "1064: episode_rewards = 18.0, policy_loss = 34.9423713684082, value_loss = 601.3699340820312\n",
      "1065: episode_rewards = 52.0, policy_loss = 514.5045166015625, value_loss = 21026.98828125\n",
      "1066: episode_rewards = 63.0, policy_loss = 743.62109375, value_loss = 36812.63671875\n",
      "1067: episode_rewards = 79.0, policy_loss = 1147.38818359375, value_loss = 69193.0703125\n",
      "1068: episode_rewards = 78.0, policy_loss = 1184.7933349609375, value_loss = 65821.96875\n",
      "1069: episode_rewards = 18.0, policy_loss = 13.728679656982422, value_loss = 730.8953247070312\n",
      "1070: episode_rewards = 31.0, policy_loss = 158.99172973632812, value_loss = 3631.255859375\n",
      "1071: episode_rewards = 46.0, policy_loss = 418.1076354980469, value_loss = 14206.541015625\n",
      "1072: episode_rewards = 40.0, policy_loss = 293.15130615234375, value_loss = 9203.42578125\n",
      "1073: episode_rewards = 55.0, policy_loss = 564.0867309570312, value_loss = 24679.35546875\n",
      "1074: episode_rewards = 51.0, policy_loss = 481.905517578125, value_loss = 19379.44140625\n",
      "1075: episode_rewards = 52.0, policy_loss = 502.94158935546875, value_loss = 20800.224609375\n",
      "1076: episode_rewards = 45.0, policy_loss = 371.6297912597656, value_loss = 13403.1484375\n",
      "1077: episode_rewards = 68.0, policy_loss = 909.9351806640625, value_loss = 43844.46875\n",
      "1078: episode_rewards = 37.0, policy_loss = 232.75711059570312, value_loss = 7204.39453125\n",
      "1079: episode_rewards = 19.0, policy_loss = 46.147361755371094, value_loss = 633.982177734375\n",
      "1080: episode_rewards = 62.0, policy_loss = 758.3056640625, value_loss = 34626.21484375\n",
      "1081: episode_rewards = 56.0, policy_loss = 579.162109375, value_loss = 25131.40625\n",
      "1082: episode_rewards = 24.0, policy_loss = 88.18478393554688, value_loss = 1598.333251953125\n",
      "1083: episode_rewards = 55.0, policy_loss = 597.88232421875, value_loss = 23859.63671875\n",
      "1084: episode_rewards = 52.0, policy_loss = 466.89959716796875, value_loss = 20172.23828125\n",
      "1085: episode_rewards = 58.0, policy_loss = 637.1106567382812, value_loss = 27522.697265625\n",
      "1086: episode_rewards = 42.0, policy_loss = 340.8746032714844, value_loss = 10492.0703125\n",
      "1087: episode_rewards = 45.0, policy_loss = 358.011962890625, value_loss = 13338.6669921875\n",
      "1088: episode_rewards = 89.0, policy_loss = 1556.599853515625, value_loss = 93089.734375\n",
      "1089: episode_rewards = 71.0, policy_loss = 971.7559814453125, value_loss = 49671.66015625\n",
      "1090: episode_rewards = 86.0, policy_loss = 1440.9642333984375, value_loss = 84730.5546875\n",
      "1091: episode_rewards = 60.0, policy_loss = 647.451904296875, value_loss = 30831.48046875\n",
      "1092: episode_rewards = 44.0, policy_loss = 358.6249084472656, value_loss = 12253.25\n",
      "1093: episode_rewards = 32.0, policy_loss = 162.20416259765625, value_loss = 4071.565185546875\n",
      "1094: episode_rewards = 34.0, policy_loss = 206.87986755371094, value_loss = 4544.1123046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095: episode_rewards = 47.0, policy_loss = 410.91802978515625, value_loss = 14403.33984375\n",
      "1096: episode_rewards = 44.0, policy_loss = 335.499267578125, value_loss = 11881.1015625\n",
      "1097: episode_rewards = 48.0, policy_loss = 398.9465026855469, value_loss = 15415.8115234375\n",
      "1098: episode_rewards = 82.0, policy_loss = 1219.79541015625, value_loss = 74808.859375\n",
      "1099: episode_rewards = 113.0, policy_loss = 2353.48828125, value_loss = 169784.25\n",
      "1100: episode_rewards = 46.0, policy_loss = 385.3077392578125, value_loss = 13358.23828125\n",
      "1101: episode_rewards = 36.0, policy_loss = 252.1839599609375, value_loss = 5936.80517578125\n",
      "1102: episode_rewards = 47.0, policy_loss = 397.5440368652344, value_loss = 14984.8828125\n",
      "1103: episode_rewards = 35.0, policy_loss = 183.484619140625, value_loss = 5496.2841796875\n",
      "1104: episode_rewards = 51.0, policy_loss = 463.27008056640625, value_loss = 19081.0546875\n",
      "1105: episode_rewards = 59.0, policy_loss = 645.796630859375, value_loss = 29555.78125\n",
      "1106: episode_rewards = 101.0, policy_loss = 1894.1861572265625, value_loss = 128549.640625\n",
      "1107: episode_rewards = 48.0, policy_loss = 405.7847900390625, value_loss = 15769.98046875\n",
      "1108: episode_rewards = 30.0, policy_loss = 142.6221466064453, value_loss = 2841.28955078125\n",
      "1109: episode_rewards = 29.0, policy_loss = 123.05892181396484, value_loss = 2707.1611328125\n",
      "1110: episode_rewards = 82.0, policy_loss = 1238.130126953125, value_loss = 74439.6015625\n",
      "1111: episode_rewards = 41.0, policy_loss = 332.6010437011719, value_loss = 9460.076171875\n",
      "1112: episode_rewards = 126.0, policy_loss = 2786.773681640625, value_loss = 220633.703125\n",
      "1113: episode_rewards = 66.0, policy_loss = 800.60009765625, value_loss = 39660.734375\n",
      "1114: episode_rewards = 88.0, policy_loss = 1459.9600830078125, value_loss = 87819.5625\n",
      "1115: episode_rewards = 74.0, policy_loss = 1036.9588623046875, value_loss = 54207.26171875\n",
      "1116: episode_rewards = 50.0, policy_loss = 463.3753662109375, value_loss = 17814.96484375\n",
      "1117: episode_rewards = 101.0, policy_loss = 1817.557373046875, value_loss = 127848.515625\n",
      "1118: episode_rewards = 44.0, policy_loss = 340.7350769042969, value_loss = 11115.8125\n",
      "1119: episode_rewards = 56.0, policy_loss = 563.6334228515625, value_loss = 24182.931640625\n",
      "1120: episode_rewards = 52.0, policy_loss = 508.604248046875, value_loss = 19484.099609375\n",
      "1121: episode_rewards = 67.0, policy_loss = 842.3116455078125, value_loss = 41269.51171875\n",
      "1122: episode_rewards = 65.0, policy_loss = 750.4207153320312, value_loss = 37816.42578125\n",
      "1123: episode_rewards = 77.0, policy_loss = 1176.74755859375, value_loss = 60457.5703125\n",
      "1124: episode_rewards = 100.0, policy_loss = 1803.5841064453125, value_loss = 123712.984375\n",
      "1125: episode_rewards = 59.0, policy_loss = 657.22412109375, value_loss = 28617.619140625\n",
      "1126: episode_rewards = 26.0, policy_loss = 106.06007385253906, value_loss = 1899.447509765625\n",
      "1127: episode_rewards = 49.0, policy_loss = 471.1612854003906, value_loss = 15836.4951171875\n",
      "1128: episode_rewards = 64.0, policy_loss = 783.2216186523438, value_loss = 35779.38671875\n",
      "1129: episode_rewards = 42.0, policy_loss = 319.08642578125, value_loss = 9797.736328125\n",
      "1130: episode_rewards = 46.0, policy_loss = 386.2969665527344, value_loss = 13246.59375\n",
      "1131: episode_rewards = 74.0, policy_loss = 1012.309814453125, value_loss = 53645.1015625\n",
      "1132: episode_rewards = 79.0, policy_loss = 1128.64697265625, value_loss = 64569.6796875\n",
      "1133: episode_rewards = 65.0, policy_loss = 739.671142578125, value_loss = 37338.55859375\n",
      "1134: episode_rewards = 30.0, policy_loss = 136.31333923339844, value_loss = 3159.625732421875\n",
      "1135: episode_rewards = 69.0, policy_loss = 919.7200927734375, value_loss = 44786.1015625\n",
      "1136: episode_rewards = 81.0, policy_loss = 1299.5521240234375, value_loss = 68675.8046875\n",
      "1137: episode_rewards = 79.0, policy_loss = 1167.6943359375, value_loss = 64155.09375\n",
      "1138: episode_rewards = 35.0, policy_loss = 191.39759826660156, value_loss = 5373.587890625\n",
      "1139: episode_rewards = 50.0, policy_loss = 470.077392578125, value_loss = 16798.84375\n",
      "1140: episode_rewards = 57.0, policy_loss = 550.6666870117188, value_loss = 24851.28125\n",
      "1141: episode_rewards = 105.0, policy_loss = 1902.6517333984375, value_loss = 137685.5625\n",
      "1142: episode_rewards = 75.0, policy_loss = 1051.5972900390625, value_loss = 55792.42578125\n",
      "1143: episode_rewards = 60.0, policy_loss = 651.0255737304688, value_loss = 28548.294921875\n",
      "1144: episode_rewards = 45.0, policy_loss = 343.71087646484375, value_loss = 12157.6455078125\n",
      "1145: episode_rewards = 124.0, policy_loss = 2761.05078125, value_loss = 206454.328125\n",
      "1146: episode_rewards = 82.0, policy_loss = 1204.055419921875, value_loss = 70976.8515625\n",
      "1147: episode_rewards = 97.0, policy_loss = 1641.625732421875, value_loss = 111643.6875\n",
      "1148: episode_rewards = 61.0, policy_loss = 641.4181518554688, value_loss = 31020.7421875\n",
      "1149: episode_rewards = 35.0, policy_loss = 205.62960815429688, value_loss = 4973.65234375\n",
      "1150: episode_rewards = 97.0, policy_loss = 1743.9766845703125, value_loss = 110834.28125\n",
      "1151: episode_rewards = 51.0, policy_loss = 435.4468078613281, value_loss = 17834.3046875\n",
      "1152: episode_rewards = 72.0, policy_loss = 987.7030029296875, value_loss = 48197.74609375\n",
      "1153: episode_rewards = 71.0, policy_loss = 896.1206665039062, value_loss = 47294.09375\n",
      "1154: episode_rewards = 58.0, policy_loss = 593.0740356445312, value_loss = 25619.63671875\n",
      "1155: episode_rewards = 59.0, policy_loss = 587.0619506835938, value_loss = 27323.83984375\n",
      "1156: episode_rewards = 74.0, policy_loss = 975.7896118164062, value_loss = 53182.3515625\n",
      "1157: episode_rewards = 40.0, policy_loss = 240.42828369140625, value_loss = 7911.11328125\n",
      "1158: episode_rewards = 9.0, policy_loss = -30.501190185546875, value_loss = 219.7222137451172\n",
      "1159: episode_rewards = 83.0, policy_loss = 1226.755126953125, value_loss = 72183.71875\n",
      "1160: episode_rewards = 55.0, policy_loss = 496.5677185058594, value_loss = 21517.5390625\n",
      "1161: episode_rewards = 44.0, policy_loss = 323.7978210449219, value_loss = 10987.662109375\n",
      "1162: episode_rewards = 50.0, policy_loss = 433.05352783203125, value_loss = 16478.57421875\n",
      "1163: episode_rewards = 59.0, policy_loss = 582.1092529296875, value_loss = 26975.4375\n",
      "1164: episode_rewards = 33.0, policy_loss = 159.89320373535156, value_loss = 4172.34326171875\n",
      "1165: episode_rewards = 99.0, policy_loss = 1760.652587890625, value_loss = 115810.4453125\n",
      "1166: episode_rewards = 70.0, policy_loss = 866.4461669921875, value_loss = 44325.734375\n",
      "1167: episode_rewards = 73.0, policy_loss = 903.997802734375, value_loss = 49721.83984375\n",
      "1168: episode_rewards = 162.0, policy_loss = 4295.162109375, value_loss = 380025.09375\n",
      "1169: episode_rewards = 39.0, policy_loss = 246.68316650390625, value_loss = 6449.8984375\n",
      "1170: episode_rewards = 106.0, policy_loss = 1947.157470703125, value_loss = 137497.453125\n",
      "1171: episode_rewards = 24.0, policy_loss = 73.35104370117188, value_loss = 1225.951904296875\n",
      "1172: episode_rewards = 86.0, policy_loss = 1327.2244873046875, value_loss = 78794.3984375\n",
      "1173: episode_rewards = 65.0, policy_loss = 770.1489868164062, value_loss = 35409.37109375\n",
      "1174: episode_rewards = 46.0, policy_loss = 340.8222961425781, value_loss = 12315.9306640625\n",
      "1175: episode_rewards = 28.0, policy_loss = 120.55195617675781, value_loss = 2238.8935546875\n",
      "1176: episode_rewards = 58.0, policy_loss = 575.5634765625, value_loss = 24274.318359375\n",
      "1177: episode_rewards = 115.0, policy_loss = 2358.509521484375, value_loss = 167586.546875\n",
      "1178: episode_rewards = 73.0, policy_loss = 926.6878662109375, value_loss = 47999.43359375\n",
      "1179: episode_rewards = 90.0, policy_loss = 1463.1142578125, value_loss = 88122.1328125\n",
      "1180: episode_rewards = 59.0, policy_loss = 603.4281005859375, value_loss = 27153.71875\n",
      "1181: episode_rewards = 24.0, policy_loss = 45.864990234375, value_loss = 1203.9798583984375\n",
      "1182: episode_rewards = 75.0, policy_loss = 944.5704956054688, value_loss = 53526.7109375\n",
      "1183: episode_rewards = 45.0, policy_loss = 320.7076416015625, value_loss = 10488.7470703125\n",
      "1184: episode_rewards = 77.0, policy_loss = 1020.1314086914062, value_loss = 55948.4296875\n",
      "1185: episode_rewards = 21.0, policy_loss = 8.444511413574219, value_loss = 794.870361328125\n",
      "1186: episode_rewards = 71.0, policy_loss = 912.9098510742188, value_loss = 46115.6484375\n",
      "1187: episode_rewards = 60.0, policy_loss = 598.2965698242188, value_loss = 27103.181640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188: episode_rewards = 70.0, policy_loss = 858.6215209960938, value_loss = 41970.609375\n",
      "1189: episode_rewards = 81.0, policy_loss = 1218.7266845703125, value_loss = 64618.50390625\n",
      "1190: episode_rewards = 84.0, policy_loss = 1300.601318359375, value_loss = 72780.1015625\n",
      "1191: episode_rewards = 52.0, policy_loss = 430.0082702636719, value_loss = 16836.080078125\n",
      "1192: episode_rewards = 77.0, policy_loss = 1103.7216796875, value_loss = 55225.37109375\n",
      "1193: episode_rewards = 16.0, policy_loss = -18.32070541381836, value_loss = 537.5418701171875\n",
      "1194: episode_rewards = 61.0, policy_loss = 593.8093872070312, value_loss = 28861.701171875\n",
      "1195: episode_rewards = 164.0, policy_loss = 4098.841796875, value_loss = 384722.3125\n",
      "1196: episode_rewards = 59.0, policy_loss = 604.5032958984375, value_loss = 25118.431640625\n",
      "1197: episode_rewards = 51.0, policy_loss = 433.1414489746094, value_loss = 16858.365234375\n",
      "1198: episode_rewards = 23.0, policy_loss = 31.120866775512695, value_loss = 963.1351928710938\n",
      "1199: episode_rewards = 61.0, policy_loss = 636.7615356445312, value_loss = 28593.00390625\n",
      "1200: episode_rewards = 39.0, policy_loss = 200.5047607421875, value_loss = 6447.28955078125\n",
      "1201: episode_rewards = 69.0, policy_loss = 810.7031860351562, value_loss = 40970.23046875\n",
      "1202: episode_rewards = 105.0, policy_loss = 1888.828857421875, value_loss = 130844.890625\n",
      "1203: episode_rewards = 36.0, policy_loss = 202.5140838623047, value_loss = 4940.029296875\n",
      "1204: episode_rewards = 37.0, policy_loss = 160.09815979003906, value_loss = 5465.8857421875\n",
      "1205: episode_rewards = 33.0, policy_loss = 165.5332794189453, value_loss = 3890.142333984375\n",
      "1206: episode_rewards = 62.0, policy_loss = 644.7119140625, value_loss = 29066.419921875\n",
      "1207: episode_rewards = 19.0, policy_loss = 11.362613677978516, value_loss = 553.0523681640625\n",
      "1208: episode_rewards = 66.0, policy_loss = 715.8787231445312, value_loss = 34610.8984375\n",
      "1209: episode_rewards = 79.0, policy_loss = 1102.3046875, value_loss = 59225.93359375\n",
      "1210: episode_rewards = 73.0, policy_loss = 943.3941650390625, value_loss = 48106.4453125\n",
      "1211: episode_rewards = 40.0, policy_loss = 224.69163513183594, value_loss = 6600.60791015625\n",
      "1212: episode_rewards = 53.0, policy_loss = 445.8439636230469, value_loss = 18654.1875\n",
      "1213: episode_rewards = 55.0, policy_loss = 485.5000915527344, value_loss = 20760.482421875\n",
      "1214: episode_rewards = 94.0, policy_loss = 1459.116455078125, value_loss = 96803.125\n",
      "1215: episode_rewards = 89.0, policy_loss = 1324.8658447265625, value_loss = 82463.1875\n",
      "1216: episode_rewards = 47.0, policy_loss = 354.53155517578125, value_loss = 12715.740234375\n",
      "1217: episode_rewards = 44.0, policy_loss = 291.7551574707031, value_loss = 10135.095703125\n",
      "1218: episode_rewards = 40.0, policy_loss = 258.7177734375, value_loss = 7305.8798828125\n",
      "1219: episode_rewards = 23.0, policy_loss = 34.92536544799805, value_loss = 895.5848999023438\n",
      "1220: episode_rewards = 30.0, policy_loss = 77.2014389038086, value_loss = 2680.190185546875\n",
      "1221: episode_rewards = 74.0, policy_loss = 909.4412231445312, value_loss = 48409.48046875\n",
      "1222: episode_rewards = 41.0, policy_loss = 254.47122192382812, value_loss = 7658.5283203125\n",
      "1223: episode_rewards = 65.0, policy_loss = 736.2838745117188, value_loss = 33458.890625\n",
      "1224: episode_rewards = 50.0, policy_loss = 385.88885498046875, value_loss = 14928.7080078125\n",
      "1225: episode_rewards = 68.0, policy_loss = 765.16748046875, value_loss = 38222.65234375\n",
      "1226: episode_rewards = 45.0, policy_loss = 277.30718994140625, value_loss = 10271.8857421875\n",
      "1227: episode_rewards = 59.0, policy_loss = 552.6171875, value_loss = 24774.037109375\n",
      "1228: episode_rewards = 36.0, policy_loss = 148.12535095214844, value_loss = 4665.921875\n",
      "1229: episode_rewards = 136.0, policy_loss = 3029.470458984375, value_loss = 244872.859375\n",
      "1230: episode_rewards = 46.0, policy_loss = 314.3816223144531, value_loss = 11477.9111328125\n",
      "1231: episode_rewards = 79.0, policy_loss = 1131.440673828125, value_loss = 58064.8359375\n",
      "1232: episode_rewards = 40.0, policy_loss = 197.9574432373047, value_loss = 6732.99462890625\n",
      "1233: episode_rewards = 42.0, policy_loss = 272.18536376953125, value_loss = 8266.8017578125\n",
      "1234: episode_rewards = 83.0, policy_loss = 1170.0030517578125, value_loss = 67648.140625\n",
      "1235: episode_rewards = 56.0, policy_loss = 492.2047424316406, value_loss = 20541.62890625\n",
      "1236: episode_rewards = 41.0, policy_loss = 228.3593292236328, value_loss = 7414.8427734375\n",
      "1237: episode_rewards = 89.0, policy_loss = 1328.250732421875, value_loss = 82280.140625\n",
      "1238: episode_rewards = 51.0, policy_loss = 384.02447509765625, value_loss = 15249.84765625\n",
      "1239: episode_rewards = 56.0, policy_loss = 454.79296875, value_loss = 21260.24609375\n",
      "1240: episode_rewards = 30.0, policy_loss = 85.41458892822266, value_loss = 2382.9072265625\n",
      "1241: episode_rewards = 153.0, policy_loss = 3741.90576171875, value_loss = 318453.71875\n",
      "1242: episode_rewards = 99.0, policy_loss = 1653.3072509765625, value_loss = 108904.28125\n",
      "1243: episode_rewards = 47.0, policy_loss = 327.0057373046875, value_loss = 11928.2275390625\n",
      "1244: episode_rewards = 55.0, policy_loss = 493.95458984375, value_loss = 20074.990234375\n",
      "1245: episode_rewards = 28.0, policy_loss = 86.3005599975586, value_loss = 1840.4085693359375\n",
      "1246: episode_rewards = 47.0, policy_loss = 279.20343017578125, value_loss = 11992.67578125\n",
      "1247: episode_rewards = 68.0, policy_loss = 767.9718627929688, value_loss = 37302.7734375\n",
      "1248: episode_rewards = 37.0, policy_loss = 175.2317352294922, value_loss = 5358.8564453125\n",
      "1249: episode_rewards = 66.0, policy_loss = 736.6513061523438, value_loss = 34310.52734375\n",
      "1250: episode_rewards = 61.0, policy_loss = 657.872314453125, value_loss = 25229.919921875\n",
      "1251: episode_rewards = 43.0, policy_loss = 244.30380249023438, value_loss = 8339.3251953125\n",
      "1252: episode_rewards = 60.0, policy_loss = 619.6270751953125, value_loss = 25740.599609375\n",
      "1253: episode_rewards = 49.0, policy_loss = 352.6728210449219, value_loss = 13174.015625\n",
      "1254: episode_rewards = 71.0, policy_loss = 859.7787475585938, value_loss = 42008.390625\n",
      "1255: episode_rewards = 95.0, policy_loss = 1511.7081298828125, value_loss = 96128.7734375\n",
      "1256: episode_rewards = 59.0, policy_loss = 567.4367065429688, value_loss = 23818.19921875\n",
      "1257: episode_rewards = 73.0, policy_loss = 845.4466552734375, value_loss = 45353.78515625\n",
      "1258: episode_rewards = 91.0, policy_loss = 1361.5172119140625, value_loss = 85324.234375\n",
      "1259: episode_rewards = 117.0, policy_loss = 2279.5205078125, value_loss = 164730.921875\n",
      "1260: episode_rewards = 87.0, policy_loss = 1317.7591552734375, value_loss = 74114.3984375\n",
      "1261: episode_rewards = 92.0, policy_loss = 1373.34619140625, value_loss = 88030.1171875\n",
      "1262: episode_rewards = 70.0, policy_loss = 827.5980834960938, value_loss = 38643.62109375\n",
      "1263: episode_rewards = 54.0, policy_loss = 500.26104736328125, value_loss = 18006.896484375\n",
      "1264: episode_rewards = 48.0, policy_loss = 374.8780517578125, value_loss = 12728.7021484375\n",
      "1265: episode_rewards = 76.0, policy_loss = 907.7122802734375, value_loss = 51147.58203125\n",
      "1266: episode_rewards = 56.0, policy_loss = 510.9185791015625, value_loss = 19968.1640625\n",
      "1267: episode_rewards = 59.0, policy_loss = 563.21484375, value_loss = 23382.904296875\n",
      "1268: episode_rewards = 32.0, policy_loss = 129.93370056152344, value_loss = 3045.6796875\n",
      "1269: episode_rewards = 81.0, policy_loss = 1103.4715576171875, value_loss = 60331.65625\n",
      "1270: episode_rewards = 93.0, policy_loss = 1435.3831787109375, value_loss = 88818.21875\n",
      "1271: episode_rewards = 55.0, policy_loss = 454.94805908203125, value_loss = 18775.697265625\n",
      "1272: episode_rewards = 48.0, policy_loss = 324.56182861328125, value_loss = 11613.568359375\n",
      "1273: episode_rewards = 34.0, policy_loss = 115.68141174316406, value_loss = 3431.255126953125\n",
      "1274: episode_rewards = 126.0, policy_loss = 2597.441162109375, value_loss = 196018.6875\n",
      "1275: episode_rewards = 24.0, policy_loss = 44.62629318237305, value_loss = 1029.0360107421875\n",
      "1276: episode_rewards = 77.0, policy_loss = 969.0140380859375, value_loss = 51857.98828125\n",
      "1277: episode_rewards = 63.0, policy_loss = 676.9729614257812, value_loss = 29297.966796875\n",
      "1278: episode_rewards = 31.0, policy_loss = 88.18640899658203, value_loss = 2348.294921875\n",
      "1279: episode_rewards = 54.0, policy_loss = 446.58935546875, value_loss = 17153.43359375\n",
      "1280: episode_rewards = 20.0, policy_loss = 24.914920806884766, value_loss = 501.5909423828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281: episode_rewards = 77.0, policy_loss = 951.8681640625, value_loss = 52237.046875\n",
      "1282: episode_rewards = 83.0, policy_loss = 1093.423095703125, value_loss = 64106.46484375\n",
      "1283: episode_rewards = 60.0, policy_loss = 558.0509643554688, value_loss = 24892.3671875\n",
      "1284: episode_rewards = 38.0, policy_loss = 161.73977661132812, value_loss = 4761.2138671875\n",
      "1285: episode_rewards = 47.0, policy_loss = 280.74053955078125, value_loss = 10879.8466796875\n",
      "1286: episode_rewards = 39.0, policy_loss = 202.54025268554688, value_loss = 6023.2490234375\n",
      "1287: episode_rewards = 56.0, policy_loss = 430.0687255859375, value_loss = 19778.341796875\n",
      "1288: episode_rewards = 95.0, policy_loss = 1532.3143310546875, value_loss = 94067.875\n",
      "1289: episode_rewards = 58.0, policy_loss = 479.8298645019531, value_loss = 21376.1171875\n",
      "1290: episode_rewards = 69.0, policy_loss = 737.4441528320312, value_loss = 37017.9453125\n",
      "1291: episode_rewards = 72.0, policy_loss = 884.3441162109375, value_loss = 41607.27734375\n",
      "1292: episode_rewards = 187.0, policy_loss = 5045.72216796875, value_loss = 484721.28125\n",
      "1293: episode_rewards = 89.0, policy_loss = 1239.40576171875, value_loss = 78203.3515625\n",
      "1294: episode_rewards = 156.0, policy_loss = 3740.64111328125, value_loss = 321534.5\n",
      "1295: episode_rewards = 21.0, policy_loss = 17.816064834594727, value_loss = 600.0603637695312\n",
      "1296: episode_rewards = 141.0, policy_loss = 3109.842529296875, value_loss = 253891.53125\n",
      "1297: episode_rewards = 71.0, policy_loss = 809.1640014648438, value_loss = 41074.44921875\n",
      "1298: episode_rewards = 30.0, policy_loss = 89.001708984375, value_loss = 2271.814208984375\n",
      "1299: episode_rewards = 40.0, policy_loss = 208.51272583007812, value_loss = 6311.78857421875\n",
      "1300: episode_rewards = 180.0, policy_loss = 4828.0224609375, value_loss = 442395.28125\n",
      "1301: episode_rewards = 101.0, policy_loss = 1630.9188232421875, value_loss = 108692.09375\n",
      "1302: episode_rewards = 65.0, policy_loss = 662.8948364257812, value_loss = 29882.751953125\n",
      "1303: episode_rewards = 124.0, policy_loss = 2492.2822265625, value_loss = 182547.078125\n",
      "1304: episode_rewards = 67.0, policy_loss = 719.2943115234375, value_loss = 33661.72265625\n",
      "1305: episode_rewards = 68.0, policy_loss = 696.2652587890625, value_loss = 35082.34375\n",
      "1306: episode_rewards = 90.0, policy_loss = 1230.227783203125, value_loss = 79881.59375\n",
      "1307: episode_rewards = 33.0, policy_loss = 97.75425720214844, value_loss = 3302.955322265625\n",
      "1308: episode_rewards = 120.0, policy_loss = 2335.62744140625, value_loss = 167948.359375\n",
      "1309: episode_rewards = 65.0, policy_loss = 708.45068359375, value_loss = 28540.775390625\n",
      "1310: episode_rewards = 28.0, policy_loss = 57.113037109375, value_loss = 1567.9219970703125\n",
      "1311: episode_rewards = 97.0, policy_loss = 1563.572509765625, value_loss = 94713.8515625\n",
      "1312: episode_rewards = 47.0, policy_loss = 345.15399169921875, value_loss = 9954.9736328125\n",
      "1313: episode_rewards = 80.0, policy_loss = 1048.1107177734375, value_loss = 54500.9296875\n",
      "1314: episode_rewards = 135.0, policy_loss = 2824.08740234375, value_loss = 223625.625\n",
      "1315: episode_rewards = 83.0, policy_loss = 1056.6077880859375, value_loss = 61611.796875\n",
      "1316: episode_rewards = 63.0, policy_loss = 611.6619262695312, value_loss = 27439.416015625\n",
      "1317: episode_rewards = 50.0, policy_loss = 296.54583740234375, value_loss = 12173.5107421875\n",
      "1318: episode_rewards = 45.0, policy_loss = 238.52920532226562, value_loss = 8734.611328125\n",
      "1319: episode_rewards = 143.0, policy_loss = 3075.95556640625, value_loss = 256553.546875\n",
      "1320: episode_rewards = 115.0, policy_loss = 2030.494384765625, value_loss = 150446.40625\n",
      "1321: episode_rewards = 96.0, policy_loss = 1466.454345703125, value_loss = 92186.265625\n",
      "1322: episode_rewards = 200.0, policy_loss = 5660.1416015625, value_loss = 543147.6875\n",
      "1323: episode_rewards = 79.0, policy_loss = 916.0225830078125, value_loss = 53404.765625\n",
      "1324: episode_rewards = 136.0, policy_loss = 2805.3330078125, value_loss = 226008.765625\n",
      "1325: episode_rewards = 58.0, policy_loss = 427.9491271972656, value_loss = 20427.859375\n",
      "1326: episode_rewards = 38.0, policy_loss = 129.43138122558594, value_loss = 4838.63525390625\n",
      "1327: episode_rewards = 130.0, policy_loss = 2517.277099609375, value_loss = 201615.296875\n",
      "1328: episode_rewards = 74.0, policy_loss = 788.3798828125, value_loss = 42457.60546875\n",
      "1329: episode_rewards = 126.0, policy_loss = 2531.49560546875, value_loss = 185138.390625\n",
      "1330: episode_rewards = 67.0, policy_loss = 682.5493774414062, value_loss = 30527.3359375\n",
      "1331: episode_rewards = 32.0, policy_loss = 106.9578857421875, value_loss = 2622.868896484375\n",
      "1332: episode_rewards = 85.0, policy_loss = 1068.5174560546875, value_loss = 63925.43359375\n",
      "1333: episode_rewards = 67.0, policy_loss = 689.6796875, value_loss = 32005.4453125\n",
      "1334: episode_rewards = 53.0, policy_loss = 361.2282409667969, value_loss = 15106.134765625\n",
      "1335: episode_rewards = 52.0, policy_loss = 308.9650573730469, value_loss = 13742.3779296875\n",
      "1336: episode_rewards = 92.0, policy_loss = 1277.375732421875, value_loss = 80307.9765625\n",
      "1337: episode_rewards = 95.0, policy_loss = 1438.654052734375, value_loss = 85646.2734375\n",
      "1338: episode_rewards = 48.0, policy_loss = 190.56689453125, value_loss = 11623.6044921875\n",
      "1339: episode_rewards = 105.0, policy_loss = 1658.6817626953125, value_loss = 113443.5078125\n",
      "1340: episode_rewards = 148.0, policy_loss = 3303.9775390625, value_loss = 269781.90625\n",
      "1341: episode_rewards = 111.0, policy_loss = 1886.66552734375, value_loss = 132590.421875\n",
      "1342: episode_rewards = 39.0, policy_loss = 159.09837341308594, value_loss = 5368.55859375\n",
      "1343: episode_rewards = 144.0, policy_loss = 3081.926513671875, value_loss = 251557.5625\n",
      "1344: episode_rewards = 56.0, policy_loss = 427.99517822265625, value_loss = 16819.3359375\n",
      "1345: episode_rewards = 101.0, policy_loss = 1526.97802734375, value_loss = 102986.953125\n",
      "1346: episode_rewards = 96.0, policy_loss = 1340.617919921875, value_loss = 88297.1015625\n",
      "1347: episode_rewards = 122.0, policy_loss = 2290.357177734375, value_loss = 165568.359375\n",
      "1348: episode_rewards = 53.0, policy_loss = 343.5058288574219, value_loss = 14051.896484375\n",
      "1349: episode_rewards = 80.0, policy_loss = 943.3523559570312, value_loss = 50474.4453125\n",
      "1350: episode_rewards = 51.0, policy_loss = 316.314208984375, value_loss = 12351.994140625\n",
      "1351: episode_rewards = 46.0, policy_loss = 242.21298217773438, value_loss = 8586.1396484375\n",
      "1352: episode_rewards = 49.0, policy_loss = 289.5149841308594, value_loss = 10344.263671875\n",
      "1353: episode_rewards = 87.0, policy_loss = 1105.56494140625, value_loss = 66357.078125\n",
      "1354: episode_rewards = 117.0, policy_loss = 2092.827880859375, value_loss = 148090.515625\n",
      "1355: episode_rewards = 34.0, policy_loss = 67.03636932373047, value_loss = 2977.307373046875\n",
      "1356: episode_rewards = 73.0, policy_loss = 756.4786987304688, value_loss = 38772.359375\n",
      "1357: episode_rewards = 131.0, policy_loss = 2556.374267578125, value_loss = 198140.3125\n",
      "1358: episode_rewards = 52.0, policy_loss = 302.96478271484375, value_loss = 13136.716796875\n",
      "1359: episode_rewards = 126.0, policy_loss = 2289.622314453125, value_loss = 178468.71875\n",
      "1360: episode_rewards = 119.0, policy_loss = 2066.046142578125, value_loss = 154036.625\n",
      "1361: episode_rewards = 66.0, policy_loss = 553.1583862304688, value_loss = 28378.39453125\n",
      "1362: episode_rewards = 87.0, policy_loss = 1096.0477294921875, value_loss = 63968.7109375\n",
      "1363: episode_rewards = 200.0, policy_loss = 5418.736328125, value_loss = 522615.125\n",
      "1364: episode_rewards = 80.0, policy_loss = 941.901123046875, value_loss = 50028.79296875\n",
      "1365: episode_rewards = 97.0, policy_loss = 1385.2503662109375, value_loss = 88246.7890625\n",
      "1366: episode_rewards = 84.0, policy_loss = 975.3324584960938, value_loss = 58740.5234375\n",
      "1367: episode_rewards = 26.0, policy_loss = 20.152997970581055, value_loss = 1091.055419921875\n",
      "1368: episode_rewards = 54.0, policy_loss = 382.79278564453125, value_loss = 13812.91015625\n",
      "1369: episode_rewards = 26.0, policy_loss = 7.064248085021973, value_loss = 1259.9344482421875\n",
      "1370: episode_rewards = 98.0, policy_loss = 1469.0576171875, value_loss = 88818.5390625\n",
      "1371: episode_rewards = 77.0, policy_loss = 850.2178344726562, value_loss = 44226.89453125\n",
      "1372: episode_rewards = 174.0, policy_loss = 4100.1162109375, value_loss = 382594.15625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373: episode_rewards = 97.0, policy_loss = 1372.9014892578125, value_loss = 87970.203125\n",
      "1374: episode_rewards = 137.0, policy_loss = 2739.2451171875, value_loss = 215974.46875\n",
      "1375: episode_rewards = 78.0, policy_loss = 841.3056640625, value_loss = 45976.734375\n",
      "1376: episode_rewards = 88.0, policy_loss = 1172.1522216796875, value_loss = 65213.625\n",
      "1377: episode_rewards = 65.0, policy_loss = 537.1765747070312, value_loss = 26316.275390625\n",
      "1378: episode_rewards = 107.0, policy_loss = 1670.4036865234375, value_loss = 113502.109375\n",
      "1379: episode_rewards = 78.0, policy_loss = 847.9580078125, value_loss = 45947.078125\n",
      "1380: episode_rewards = 68.0, policy_loss = 615.23583984375, value_loss = 29659.140625\n",
      "1381: episode_rewards = 73.0, policy_loss = 767.015869140625, value_loss = 36616.78515625\n",
      "1382: episode_rewards = 124.0, policy_loss = 2287.263671875, value_loss = 166381.84375\n",
      "1383: episode_rewards = 159.0, policy_loss = 3487.666015625, value_loss = 307246.375\n",
      "1384: episode_rewards = 124.0, policy_loss = 2280.412841796875, value_loss = 164064.75\n",
      "1385: episode_rewards = 94.0, policy_loss = 1290.6669921875, value_loss = 77061.765625\n",
      "1386: episode_rewards = 64.0, policy_loss = 561.0322875976562, value_loss = 23826.0859375\n",
      "1387: episode_rewards = 121.0, policy_loss = 2084.6884765625, value_loss = 156022.984375\n",
      "1388: episode_rewards = 81.0, policy_loss = 937.9627075195312, value_loss = 50117.4296875\n",
      "1389: episode_rewards = 174.0, policy_loss = 4224.111328125, value_loss = 374453.40625\n",
      "1390: episode_rewards = 168.0, policy_loss = 4123.73681640625, value_loss = 341421.59375\n",
      "1391: episode_rewards = 148.0, policy_loss = 3107.599365234375, value_loss = 251161.546875\n",
      "1392: episode_rewards = 92.0, policy_loss = 1161.476806640625, value_loss = 73302.109375\n",
      "1393: episode_rewards = 129.0, policy_loss = 2426.804443359375, value_loss = 181428.359375\n",
      "1394: episode_rewards = 100.0, policy_loss = 1460.484130859375, value_loss = 92033.2578125\n",
      "1395: episode_rewards = 159.0, policy_loss = 3644.1416015625, value_loss = 298998.8125\n",
      "1396: episode_rewards = 76.0, policy_loss = 763.6897583007812, value_loss = 40795.71484375\n",
      "1397: episode_rewards = 81.0, policy_loss = 848.6746215820312, value_loss = 49572.37890625\n",
      "1398: episode_rewards = 171.0, policy_loss = 4250.97021484375, value_loss = 349078.375\n",
      "1399: episode_rewards = 149.0, policy_loss = 3062.9931640625, value_loss = 257174.140625\n",
      "1400: episode_rewards = 67.0, policy_loss = 589.5905151367188, value_loss = 28085.626953125\n",
      "1401: episode_rewards = 150.0, policy_loss = 3095.7578125, value_loss = 257371.6875\n",
      "1402: episode_rewards = 145.0, policy_loss = 2766.864013671875, value_loss = 237601.671875\n",
      "1403: episode_rewards = 58.0, policy_loss = 394.83587646484375, value_loss = 16166.9755859375\n",
      "1404: episode_rewards = 200.0, policy_loss = 5237.7275390625, value_loss = 486034.40625\n",
      "1405: episode_rewards = 200.0, policy_loss = 5338.3935546875, value_loss = 496154.71875\n",
      "1406: episode_rewards = 200.0, policy_loss = 5244.41259765625, value_loss = 492875.75\n",
      "1407: episode_rewards = 142.0, policy_loss = 2922.662841796875, value_loss = 213247.734375\n",
      "1408: episode_rewards = 94.0, policy_loss = 1149.839111328125, value_loss = 74973.9609375\n",
      "1409: episode_rewards = 158.0, policy_loss = 3506.1708984375, value_loss = 286725.9375\n",
      "1410: episode_rewards = 200.0, policy_loss = 5293.515625, value_loss = 488002.4375\n",
      "1411: episode_rewards = 179.0, policy_loss = 4226.7939453125, value_loss = 383822.9375\n",
      "1412: episode_rewards = 163.0, policy_loss = 3714.09765625, value_loss = 311583.03125\n",
      "1413: episode_rewards = 24.0, policy_loss = -7.061859607696533, value_loss = 876.8087768554688\n",
      "1414: episode_rewards = 200.0, policy_loss = 5137.16162109375, value_loss = 484551.625\n",
      "1415: episode_rewards = 200.0, policy_loss = 5265.6142578125, value_loss = 482537.1875\n",
      "1416: episode_rewards = 120.0, policy_loss = 1928.8533935546875, value_loss = 140358.84375\n",
      "1417: episode_rewards = 40.0, policy_loss = 91.97450256347656, value_loss = 4276.73388671875\n",
      "1418: episode_rewards = 57.0, policy_loss = 348.3233642578125, value_loss = 14591.71875\n",
      "1419: episode_rewards = 200.0, policy_loss = 5277.41357421875, value_loss = 482057.28125\n",
      "1420: episode_rewards = 163.0, policy_loss = 3534.66455078125, value_loss = 295891.375\n",
      "1421: episode_rewards = 200.0, policy_loss = 5094.25830078125, value_loss = 458959.4375\n",
      "1422: episode_rewards = 173.0, policy_loss = 3850.921875, value_loss = 336906.0625\n",
      "1423: episode_rewards = 200.0, policy_loss = 5160.50537109375, value_loss = 479062.71875\n",
      "1424: episode_rewards = 200.0, policy_loss = 5067.44091796875, value_loss = 481046.0\n",
      "1425: episode_rewards = 63.0, policy_loss = 423.20166015625, value_loss = 20674.572265625\n",
      "1426: episode_rewards = 154.0, policy_loss = 2932.975830078125, value_loss = 251116.921875\n",
      "1427: episode_rewards = 139.0, policy_loss = 2463.75537109375, value_loss = 205340.09375\n",
      "1428: episode_rewards = 33.0, policy_loss = 24.162921905517578, value_loss = 2155.30859375\n",
      "1429: episode_rewards = 125.0, policy_loss = 2201.589111328125, value_loss = 150960.5\n",
      "1430: episode_rewards = 154.0, policy_loss = 2927.6083984375, value_loss = 251431.5\n",
      "1431: episode_rewards = 200.0, policy_loss = 4907.8720703125, value_loss = 453133.96875\n",
      "1432: episode_rewards = 138.0, policy_loss = 2303.168701171875, value_loss = 200691.78125\n",
      "1433: episode_rewards = 192.0, policy_loss = 4499.4638671875, value_loss = 435690.65625\n",
      "1434: episode_rewards = 54.0, policy_loss = 214.9353485107422, value_loss = 11940.841796875\n",
      "1435: episode_rewards = 35.0, policy_loss = 8.268035888671875, value_loss = 2475.80224609375\n",
      "1436: episode_rewards = 149.0, policy_loss = 2701.25634765625, value_loss = 233897.015625\n",
      "1437: episode_rewards = 77.0, policy_loss = 772.990478515625, value_loss = 35979.671875\n",
      "1438: episode_rewards = 200.0, policy_loss = 4963.0244140625, value_loss = 463754.0625\n",
      "1439: episode_rewards = 20.0, policy_loss = -57.00584030151367, value_loss = 979.9317016601562\n",
      "1440: episode_rewards = 17.0, policy_loss = -79.18521881103516, value_loss = 1209.2113037109375\n",
      "1441: episode_rewards = 98.0, policy_loss = 1212.232177734375, value_loss = 78997.3359375\n",
      "1442: episode_rewards = 157.0, policy_loss = 3061.2099609375, value_loss = 266713.875\n",
      "1443: episode_rewards = 198.0, policy_loss = 4832.208984375, value_loss = 436247.34375\n",
      "1444: episode_rewards = 172.0, policy_loss = 3541.864990234375, value_loss = 324190.4375\n",
      "1445: episode_rewards = 200.0, policy_loss = 5052.48291015625, value_loss = 464287.28125\n",
      "1446: episode_rewards = 200.0, policy_loss = 4888.09765625, value_loss = 454850.15625\n",
      "1447: episode_rewards = 166.0, policy_loss = 3425.5078125, value_loss = 292737.84375\n",
      "1448: episode_rewards = 57.0, policy_loss = 325.55621337890625, value_loss = 12199.828125\n",
      "1449: episode_rewards = 80.0, policy_loss = 727.1838989257812, value_loss = 40951.37890625\n",
      "1450: episode_rewards = 200.0, policy_loss = 5065.9365234375, value_loss = 458845.375\n",
      "1451: episode_rewards = 129.0, policy_loss = 1993.75732421875, value_loss = 163283.25\n",
      "1452: episode_rewards = 200.0, policy_loss = 5104.9306640625, value_loss = 456430.625\n",
      "1453: episode_rewards = 200.0, policy_loss = 4911.6123046875, value_loss = 453240.4375\n",
      "1454: episode_rewards = 145.0, policy_loss = 2787.220947265625, value_loss = 212549.875\n",
      "1455: episode_rewards = 153.0, policy_loss = 3023.6376953125, value_loss = 244066.140625\n",
      "1456: episode_rewards = 127.0, policy_loss = 2104.05908203125, value_loss = 150604.15625\n",
      "1457: episode_rewards = 110.0, policy_loss = 1417.252197265625, value_loss = 102970.5\n",
      "1458: episode_rewards = 125.0, policy_loss = 1986.1751708984375, value_loss = 142179.375\n",
      "1459: episode_rewards = 200.0, policy_loss = 4863.98291015625, value_loss = 447500.90625\n",
      "1460: episode_rewards = 200.0, policy_loss = 4760.6552734375, value_loss = 440409.3125\n",
      "1461: episode_rewards = 171.0, policy_loss = 3751.45947265625, value_loss = 310486.5\n",
      "1462: episode_rewards = 109.0, policy_loss = 1517.8111572265625, value_loss = 94764.78125\n",
      "1463: episode_rewards = 200.0, policy_loss = 4837.5732421875, value_loss = 442166.8125\n",
      "1464: episode_rewards = 200.0, policy_loss = 4820.0673828125, value_loss = 446680.28125\n",
      "1465: episode_rewards = 200.0, policy_loss = 4856.69775390625, value_loss = 445291.21875\n",
      "1466: episode_rewards = 143.0, policy_loss = 2517.14599609375, value_loss = 199906.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467: episode_rewards = 176.0, policy_loss = 3817.246337890625, value_loss = 335465.875\n",
      "1468: episode_rewards = 194.0, policy_loss = 4468.34716796875, value_loss = 420616.875\n",
      "1469: episode_rewards = 152.0, policy_loss = 2902.714599609375, value_loss = 232863.828125\n",
      "1470: episode_rewards = 200.0, policy_loss = 4732.52978515625, value_loss = 438680.0625\n",
      "1471: episode_rewards = 200.0, policy_loss = 5046.55859375, value_loss = 416437.28125\n",
      "1472: episode_rewards = 122.0, policy_loss = 1769.652587890625, value_loss = 126042.3984375\n",
      "1473: episode_rewards = 94.0, policy_loss = 999.6367797851562, value_loss = 62185.01171875\n",
      "1474: episode_rewards = 176.0, policy_loss = 3700.847412109375, value_loss = 320582.0625\n",
      "1475: episode_rewards = 200.0, policy_loss = 4827.9482421875, value_loss = 438721.09375\n",
      "1476: episode_rewards = 200.0, policy_loss = 4746.32080078125, value_loss = 429785.28125\n",
      "1477: episode_rewards = 50.0, policy_loss = 66.2519302368164, value_loss = 9332.4580078125\n",
      "1478: episode_rewards = 200.0, policy_loss = 4819.39599609375, value_loss = 422475.15625\n",
      "1479: episode_rewards = 200.0, policy_loss = 4614.42333984375, value_loss = 406273.34375\n",
      "1480: episode_rewards = 72.0, policy_loss = 509.39385986328125, value_loss = 25368.625\n",
      "1481: episode_rewards = 153.0, policy_loss = 2854.9951171875, value_loss = 229822.953125\n",
      "1482: episode_rewards = 200.0, policy_loss = 4910.46484375, value_loss = 425692.78125\n",
      "1483: episode_rewards = 95.0, policy_loss = 1021.9972534179688, value_loss = 62557.21484375\n",
      "1484: episode_rewards = 125.0, policy_loss = 1718.6990966796875, value_loss = 134188.5\n",
      "1485: episode_rewards = 165.0, policy_loss = 3174.847412109375, value_loss = 264011.375\n",
      "1486: episode_rewards = 103.0, policy_loss = 1189.4649658203125, value_loss = 79837.0703125\n",
      "1487: episode_rewards = 200.0, policy_loss = 4699.38720703125, value_loss = 429801.0\n",
      "1488: episode_rewards = 108.0, policy_loss = 1301.31494140625, value_loss = 90924.4609375\n",
      "1489: episode_rewards = 172.0, policy_loss = 3552.021240234375, value_loss = 290707.71875\n",
      "1490: episode_rewards = 70.0, policy_loss = 483.4519348144531, value_loss = 22229.625\n",
      "1491: episode_rewards = 143.0, policy_loss = 2272.20458984375, value_loss = 174373.625\n",
      "1492: episode_rewards = 153.0, policy_loss = 2801.617919921875, value_loss = 226774.578125\n",
      "1493: episode_rewards = 82.0, policy_loss = 631.4076538085938, value_loss = 37122.09765625\n",
      "1494: episode_rewards = 177.0, policy_loss = 3389.884521484375, value_loss = 307152.71875\n",
      "1495: episode_rewards = 200.0, policy_loss = 4627.8017578125, value_loss = 423465.28125\n",
      "1496: episode_rewards = 13.0, policy_loss = -119.42601776123047, value_loss = 2111.861328125\n",
      "1497: episode_rewards = 117.0, policy_loss = 1599.8575439453125, value_loss = 110939.2265625\n",
      "1498: episode_rewards = 197.0, policy_loss = 4510.88134765625, value_loss = 411892.09375\n",
      "1499: episode_rewards = 138.0, policy_loss = 2041.325439453125, value_loss = 169116.109375\n",
      "1500: episode_rewards = 127.0, policy_loss = 1910.9986572265625, value_loss = 138277.171875\n",
      "1501: episode_rewards = 141.0, policy_loss = 2148.561767578125, value_loss = 178077.265625\n",
      "1502: episode_rewards = 200.0, policy_loss = 4634.18603515625, value_loss = 406361.6875\n",
      "1503: episode_rewards = 138.0, policy_loss = 2221.830810546875, value_loss = 169587.03125\n",
      "1504: episode_rewards = 200.0, policy_loss = 4586.64599609375, value_loss = 405848.59375\n",
      "1505: episode_rewards = 200.0, policy_loss = 4511.6826171875, value_loss = 405956.125\n",
      "1506: episode_rewards = 200.0, policy_loss = 4537.287109375, value_loss = 410762.375\n",
      "1507: episode_rewards = 100.0, policy_loss = 1112.9222412109375, value_loss = 67509.8828125\n",
      "1508: episode_rewards = 200.0, policy_loss = 4319.44580078125, value_loss = 390778.15625\n",
      "1509: episode_rewards = 200.0, policy_loss = 4552.7314453125, value_loss = 402683.96875\n",
      "1510: episode_rewards = 192.0, policy_loss = 4512.87744140625, value_loss = 376067.5\n",
      "1511: episode_rewards = 200.0, policy_loss = 4764.65869140625, value_loss = 415376.75\n",
      "1512: episode_rewards = 200.0, policy_loss = 4470.6328125, value_loss = 407343.75\n",
      "1513: episode_rewards = 86.0, policy_loss = 761.5833129882812, value_loss = 42763.96875\n",
      "1514: episode_rewards = 200.0, policy_loss = 4530.01416015625, value_loss = 404536.40625\n",
      "1515: episode_rewards = 199.0, policy_loss = 4421.56103515625, value_loss = 397724.625\n",
      "1516: episode_rewards = 50.0, policy_loss = 88.9697036743164, value_loss = 6618.921875\n",
      "1517: episode_rewards = 197.0, policy_loss = 4389.92236328125, value_loss = 394175.0\n",
      "1518: episode_rewards = 200.0, policy_loss = 4249.53173828125, value_loss = 373766.1875\n",
      "1519: episode_rewards = 200.0, policy_loss = 4285.5263671875, value_loss = 408451.0625\n",
      "1520: episode_rewards = 200.0, policy_loss = 4508.1357421875, value_loss = 408347.125\n",
      "1521: episode_rewards = 200.0, policy_loss = 4520.2841796875, value_loss = 404445.4375\n",
      "1522: episode_rewards = 177.0, policy_loss = 3576.362548828125, value_loss = 308096.0\n",
      "1523: episode_rewards = 200.0, policy_loss = 4473.53125, value_loss = 399861.875\n",
      "1524: episode_rewards = 96.0, policy_loss = 939.2361450195312, value_loss = 56182.83203125\n",
      "1525: episode_rewards = 200.0, policy_loss = 4389.93701171875, value_loss = 393814.40625\n",
      "1526: episode_rewards = 76.0, policy_loss = 517.8765258789062, value_loss = 25754.765625\n",
      "1527: episode_rewards = 148.0, policy_loss = 2478.461181640625, value_loss = 195612.28125\n",
      "1528: episode_rewards = 37.0, policy_loss = -49.78746032714844, value_loss = 2861.909423828125\n",
      "1529: episode_rewards = 154.0, policy_loss = 2659.1689453125, value_loss = 215716.140625\n",
      "1530: episode_rewards = 200.0, policy_loss = 4294.90087890625, value_loss = 391973.03125\n",
      "1531: episode_rewards = 158.0, policy_loss = 2963.06396484375, value_loss = 223269.453125\n",
      "1532: episode_rewards = 200.0, policy_loss = 4406.06494140625, value_loss = 395929.03125\n",
      "1533: episode_rewards = 200.0, policy_loss = 4562.3701171875, value_loss = 394006.09375\n",
      "1534: episode_rewards = 200.0, policy_loss = 4368.67236328125, value_loss = 394347.96875\n",
      "1535: episode_rewards = 163.0, policy_loss = 3041.944091796875, value_loss = 245191.921875\n",
      "1536: episode_rewards = 61.0, policy_loss = 230.6004180908203, value_loss = 12146.3505859375\n",
      "1537: episode_rewards = 200.0, policy_loss = 4662.4013671875, value_loss = 383096.53125\n",
      "1538: episode_rewards = 200.0, policy_loss = 4353.2216796875, value_loss = 368594.84375\n",
      "1539: episode_rewards = 102.0, policy_loss = 1090.697509765625, value_loss = 67622.046875\n",
      "1540: episode_rewards = 124.0, policy_loss = 1633.686767578125, value_loss = 116551.703125\n",
      "1541: episode_rewards = 131.0, policy_loss = 1847.107421875, value_loss = 132684.8125\n",
      "1542: episode_rewards = 200.0, policy_loss = 4452.9013671875, value_loss = 387006.0625\n",
      "1543: episode_rewards = 177.0, policy_loss = 3488.099609375, value_loss = 289101.6875\n",
      "1544: episode_rewards = 150.0, policy_loss = 2383.93896484375, value_loss = 194705.6875\n",
      "1545: episode_rewards = 190.0, policy_loss = 3970.744140625, value_loss = 348295.90625\n",
      "1546: episode_rewards = 95.0, policy_loss = 885.8846435546875, value_loss = 51263.8203125\n",
      "1547: episode_rewards = 17.0, policy_loss = -162.9791717529297, value_loss = 2966.365478515625\n",
      "1548: episode_rewards = 200.0, policy_loss = 4490.953125, value_loss = 379639.21875\n",
      "1549: episode_rewards = 102.0, policy_loss = 844.4075317382812, value_loss = 76873.859375\n",
      "1550: episode_rewards = 200.0, policy_loss = 4194.765625, value_loss = 347452.34375\n",
      "1551: episode_rewards = 200.0, policy_loss = 4164.39013671875, value_loss = 370590.09375\n",
      "1552: episode_rewards = 200.0, policy_loss = 4430.3486328125, value_loss = 374873.0625\n",
      "1553: episode_rewards = 137.0, policy_loss = 1929.84912109375, value_loss = 151582.46875\n",
      "1554: episode_rewards = 200.0, policy_loss = 4225.46044921875, value_loss = 354198.40625\n",
      "1555: episode_rewards = 183.0, policy_loss = 3579.94580078125, value_loss = 313449.90625\n",
      "1556: episode_rewards = 178.0, policy_loss = 3508.951416015625, value_loss = 286761.875\n",
      "1557: episode_rewards = 200.0, policy_loss = 4219.11474609375, value_loss = 364500.71875\n",
      "1558: episode_rewards = 200.0, policy_loss = 4158.21875, value_loss = 354317.375\n",
      "1559: episode_rewards = 200.0, policy_loss = 4343.763671875, value_loss = 376821.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560: episode_rewards = 197.0, policy_loss = 4263.71923828125, value_loss = 367148.5625\n",
      "1561: episode_rewards = 200.0, policy_loss = 4002.35400390625, value_loss = 358555.71875\n",
      "1562: episode_rewards = 45.0, policy_loss = -63.61740493774414, value_loss = 5282.55908203125\n",
      "1563: episode_rewards = 200.0, policy_loss = 4533.7109375, value_loss = 372876.53125\n",
      "1564: episode_rewards = 200.0, policy_loss = 4206.65576171875, value_loss = 349996.25\n",
      "1565: episode_rewards = 200.0, policy_loss = 4320.39990234375, value_loss = 377340.8125\n",
      "1566: episode_rewards = 200.0, policy_loss = 4178.75, value_loss = 339471.5625\n",
      "1567: episode_rewards = 183.0, policy_loss = 3637.634033203125, value_loss = 306254.0\n",
      "1568: episode_rewards = 200.0, policy_loss = 3922.526123046875, value_loss = 348733.71875\n",
      "1569: episode_rewards = 105.0, policy_loss = 825.556884765625, value_loss = 78585.8125\n",
      "1570: episode_rewards = 200.0, policy_loss = 4019.359375, value_loss = 351510.21875\n",
      "1571: episode_rewards = 200.0, policy_loss = 4438.24755859375, value_loss = 367457.5625\n",
      "1572: episode_rewards = 40.0, policy_loss = -115.0810546875, value_loss = 4000.54345703125\n",
      "1573: episode_rewards = 200.0, policy_loss = 4174.0146484375, value_loss = 355980.53125\n",
      "1574: episode_rewards = 197.0, policy_loss = 4159.62841796875, value_loss = 366264.65625\n",
      "1575: episode_rewards = 143.0, policy_loss = 2195.384033203125, value_loss = 155667.28125\n",
      "1576: episode_rewards = 200.0, policy_loss = 4276.2236328125, value_loss = 368919.0\n",
      "1577: episode_rewards = 141.0, policy_loss = 1714.450927734375, value_loss = 147889.453125\n",
      "1578: episode_rewards = 190.0, policy_loss = 3403.7509765625, value_loss = 294041.9375\n",
      "1579: episode_rewards = 163.0, policy_loss = 2812.860595703125, value_loss = 229060.8125\n",
      "1580: episode_rewards = 193.0, policy_loss = 3587.870361328125, value_loss = 307745.90625\n",
      "1581: episode_rewards = 74.0, policy_loss = 334.6610412597656, value_loss = 20490.12890625\n",
      "1582: episode_rewards = 200.0, policy_loss = 4048.459716796875, value_loss = 350677.90625\n",
      "1583: episode_rewards = 198.0, policy_loss = 3781.84521484375, value_loss = 352357.21875\n",
      "1584: episode_rewards = 200.0, policy_loss = 3846.274169921875, value_loss = 329673.28125\n",
      "1585: episode_rewards = 200.0, policy_loss = 4135.6806640625, value_loss = 371403.09375\n",
      "1586: episode_rewards = 174.0, policy_loss = 3140.530517578125, value_loss = 256403.703125\n",
      "1587: episode_rewards = 133.0, policy_loss = 1686.896728515625, value_loss = 125420.3359375\n",
      "1588: episode_rewards = 197.0, policy_loss = 4199.82080078125, value_loss = 350626.75\n",
      "1589: episode_rewards = 164.0, policy_loss = 2461.778564453125, value_loss = 212027.265625\n",
      "1590: episode_rewards = 186.0, policy_loss = 3223.264404296875, value_loss = 294178.6875\n",
      "1591: episode_rewards = 200.0, policy_loss = 3825.702392578125, value_loss = 329096.96875\n",
      "1592: episode_rewards = 183.0, policy_loss = 3530.583984375, value_loss = 294761.375\n",
      "1593: episode_rewards = 130.0, policy_loss = 1699.5423583984375, value_loss = 117578.7265625\n",
      "1594: episode_rewards = 200.0, policy_loss = 4005.7119140625, value_loss = 351481.125\n",
      "1595: episode_rewards = 157.0, policy_loss = 2256.10400390625, value_loss = 194374.921875\n",
      "1596: episode_rewards = 39.0, policy_loss = -103.61038970947266, value_loss = 3746.8369140625\n",
      "1597: episode_rewards = 200.0, policy_loss = 4430.21533203125, value_loss = 342876.75\n",
      "1598: episode_rewards = 146.0, policy_loss = 1786.7767333984375, value_loss = 159169.234375\n",
      "1599: episode_rewards = 200.0, policy_loss = 3824.542236328125, value_loss = 327153.15625\n",
      "1600: episode_rewards = 162.0, policy_loss = 2747.332275390625, value_loss = 207440.46875\n",
      "1601: episode_rewards = 51.0, policy_loss = -56.27268600463867, value_loss = 6585.71630859375\n",
      "1602: episode_rewards = 200.0, policy_loss = 3813.803955078125, value_loss = 341324.46875\n",
      "1603: episode_rewards = 190.0, policy_loss = 3413.59423828125, value_loss = 324674.21875\n",
      "1604: episode_rewards = 200.0, policy_loss = 3541.629638671875, value_loss = 318486.28125\n",
      "1605: episode_rewards = 187.0, policy_loss = 3123.427978515625, value_loss = 300884.46875\n",
      "1606: episode_rewards = 200.0, policy_loss = 3703.12060546875, value_loss = 319136.8125\n",
      "1607: episode_rewards = 150.0, policy_loss = 2199.785888671875, value_loss = 164215.25\n",
      "1608: episode_rewards = 110.0, policy_loss = 1144.662109375, value_loss = 70197.65625\n",
      "1609: episode_rewards = 200.0, policy_loss = 3958.7333984375, value_loss = 334741.25\n",
      "1610: episode_rewards = 197.0, policy_loss = 3527.3603515625, value_loss = 292905.75\n",
      "1611: episode_rewards = 200.0, policy_loss = 3909.010009765625, value_loss = 337776.5\n",
      "1612: episode_rewards = 200.0, policy_loss = 3621.822998046875, value_loss = 310283.84375\n",
      "1613: episode_rewards = 182.0, policy_loss = 2902.6982421875, value_loss = 247239.28125\n",
      "1614: episode_rewards = 200.0, policy_loss = 3595.645263671875, value_loss = 338521.84375\n",
      "1615: episode_rewards = 200.0, policy_loss = 3921.38623046875, value_loss = 344846.375\n",
      "1616: episode_rewards = 200.0, policy_loss = 3730.131103515625, value_loss = 327724.46875\n",
      "1617: episode_rewards = 200.0, policy_loss = 4005.749755859375, value_loss = 335790.21875\n",
      "1618: episode_rewards = 200.0, policy_loss = 3918.3046875, value_loss = 330371.8125\n",
      "1619: episode_rewards = 122.0, policy_loss = 1048.001220703125, value_loss = 97745.9609375\n",
      "1620: episode_rewards = 71.0, policy_loss = 168.06643676757812, value_loss = 16179.3408203125\n",
      "1621: episode_rewards = 200.0, policy_loss = 3902.96826171875, value_loss = 336958.65625\n",
      "1622: episode_rewards = 200.0, policy_loss = 3768.3154296875, value_loss = 319569.5\n",
      "1623: episode_rewards = 114.0, policy_loss = 1220.5859375, value_loss = 76501.90625\n",
      "1624: episode_rewards = 67.0, policy_loss = 165.04052734375, value_loss = 13560.716796875\n",
      "1625: episode_rewards = 200.0, policy_loss = 3755.238037109375, value_loss = 322833.75\n",
      "1626: episode_rewards = 200.0, policy_loss = 4160.732421875, value_loss = 345111.71875\n",
      "1627: episode_rewards = 53.0, policy_loss = -71.06553649902344, value_loss = 7764.17138671875\n",
      "1628: episode_rewards = 200.0, policy_loss = 3764.27978515625, value_loss = 319035.15625\n",
      "1629: episode_rewards = 196.0, policy_loss = 3715.54638671875, value_loss = 333066.34375\n",
      "1630: episode_rewards = 200.0, policy_loss = 3523.7099609375, value_loss = 314079.96875\n",
      "1631: episode_rewards = 189.0, policy_loss = 3653.515869140625, value_loss = 292669.90625\n",
      "1632: episode_rewards = 200.0, policy_loss = 4079.430908203125, value_loss = 331785.375\n",
      "1633: episode_rewards = 137.0, policy_loss = 1868.1689453125, value_loss = 123787.5390625\n",
      "1634: episode_rewards = 159.0, policy_loss = 2401.609375, value_loss = 194328.375\n",
      "1635: episode_rewards = 157.0, policy_loss = 2547.89892578125, value_loss = 182377.609375\n",
      "1636: episode_rewards = 134.0, policy_loss = 1656.529052734375, value_loss = 119585.875\n",
      "1637: episode_rewards = 122.0, policy_loss = 1343.2049560546875, value_loss = 87418.9609375\n",
      "1638: episode_rewards = 94.0, policy_loss = 535.139404296875, value_loss = 43100.265625\n",
      "1639: episode_rewards = 200.0, policy_loss = 3674.779541015625, value_loss = 293293.96875\n",
      "1640: episode_rewards = 168.0, policy_loss = 2713.90966796875, value_loss = 198375.4375\n",
      "1641: episode_rewards = 200.0, policy_loss = 3685.80224609375, value_loss = 327346.5625\n",
      "1642: episode_rewards = 155.0, policy_loss = 2334.587646484375, value_loss = 174029.6875\n",
      "1643: episode_rewards = 179.0, policy_loss = 3201.67919921875, value_loss = 248763.90625\n",
      "1644: episode_rewards = 40.0, policy_loss = -175.15821838378906, value_loss = 5558.85009765625\n",
      "1645: episode_rewards = 200.0, policy_loss = 3800.362548828125, value_loss = 315310.53125\n",
      "1646: episode_rewards = 155.0, policy_loss = 2291.2021484375, value_loss = 170224.65625\n",
      "1647: episode_rewards = 200.0, policy_loss = 3823.601318359375, value_loss = 325199.625\n",
      "1648: episode_rewards = 84.0, policy_loss = 289.16912841796875, value_loss = 26949.619140625\n",
      "1649: episode_rewards = 200.0, policy_loss = 3776.653076171875, value_loss = 315748.90625\n",
      "1650: episode_rewards = 85.0, policy_loss = 454.418212890625, value_loss = 28297.13671875\n",
      "1651: episode_rewards = 171.0, policy_loss = 2704.496826171875, value_loss = 222466.296875\n",
      "1652: episode_rewards = 138.0, policy_loss = 1813.76513671875, value_loss = 120672.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1653: episode_rewards = 179.0, policy_loss = 3018.573486328125, value_loss = 251889.0625\n",
      "1654: episode_rewards = 129.0, policy_loss = 1457.8017578125, value_loss = 103032.375\n",
      "1655: episode_rewards = 133.0, policy_loss = 1636.1781005859375, value_loss = 106409.0625\n",
      "1656: episode_rewards = 200.0, policy_loss = 3724.837158203125, value_loss = 321337.3125\n",
      "1657: episode_rewards = 200.0, policy_loss = 3904.8544921875, value_loss = 324929.84375\n",
      "1658: episode_rewards = 117.0, policy_loss = 1112.1968994140625, value_loss = 75732.625\n",
      "1659: episode_rewards = 200.0, policy_loss = 3847.247802734375, value_loss = 320986.6875\n",
      "1660: episode_rewards = 200.0, policy_loss = 3830.60302734375, value_loss = 291309.15625\n",
      "1661: episode_rewards = 124.0, policy_loss = 1309.5904541015625, value_loss = 92160.5703125\n",
      "1662: episode_rewards = 200.0, policy_loss = 3477.943603515625, value_loss = 287137.71875\n",
      "1663: episode_rewards = 160.0, policy_loss = 2280.896728515625, value_loss = 189788.609375\n",
      "1664: episode_rewards = 172.0, policy_loss = 2799.673828125, value_loss = 217399.109375\n",
      "1665: episode_rewards = 200.0, policy_loss = 3727.153076171875, value_loss = 321218.34375\n",
      "1666: episode_rewards = 200.0, policy_loss = 3543.883056640625, value_loss = 284258.15625\n",
      "1667: episode_rewards = 123.0, policy_loss = 1282.4559326171875, value_loss = 86855.75\n",
      "1668: episode_rewards = 60.0, policy_loss = -28.931182861328125, value_loss = 9616.931640625\n",
      "1669: episode_rewards = 112.0, policy_loss = 940.8362426757812, value_loss = 67234.234375\n",
      "1670: episode_rewards = 200.0, policy_loss = 3672.222900390625, value_loss = 304019.03125\n",
      "1671: episode_rewards = 200.0, policy_loss = 3673.5341796875, value_loss = 300695.21875\n",
      "1672: episode_rewards = 200.0, policy_loss = 3746.992919921875, value_loss = 303387.96875\n",
      "1673: episode_rewards = 200.0, policy_loss = 3887.39111328125, value_loss = 310446.625\n",
      "1674: episode_rewards = 200.0, policy_loss = 3634.082763671875, value_loss = 307702.25\n",
      "1675: episode_rewards = 200.0, policy_loss = 3878.5458984375, value_loss = 317409.71875\n",
      "1676: episode_rewards = 200.0, policy_loss = 3560.834228515625, value_loss = 295885.3125\n",
      "1677: episode_rewards = 200.0, policy_loss = 3551.161865234375, value_loss = 296251.53125\n",
      "1678: episode_rewards = 200.0, policy_loss = 3636.5654296875, value_loss = 303696.53125\n",
      "1679: episode_rewards = 200.0, policy_loss = 3568.13330078125, value_loss = 314933.125\n",
      "1680: episode_rewards = 200.0, policy_loss = 3793.6962890625, value_loss = 319044.78125\n",
      "1681: episode_rewards = 200.0, policy_loss = 3501.91015625, value_loss = 288766.40625\n",
      "1682: episode_rewards = 200.0, policy_loss = 3829.10595703125, value_loss = 307904.71875\n",
      "1683: episode_rewards = 200.0, policy_loss = 3796.204345703125, value_loss = 312163.28125\n",
      "1684: episode_rewards = 200.0, policy_loss = 3508.3798828125, value_loss = 291235.03125\n",
      "1685: episode_rewards = 200.0, policy_loss = 3508.272705078125, value_loss = 305390.84375\n",
      "1686: episode_rewards = 200.0, policy_loss = 3411.57568359375, value_loss = 318319.9375\n",
      "1687: episode_rewards = 116.0, policy_loss = 1029.5301513671875, value_loss = 69727.203125\n",
      "1688: episode_rewards = 171.0, policy_loss = 2165.453857421875, value_loss = 180979.5\n",
      "1689: episode_rewards = 157.0, policy_loss = 1661.49462890625, value_loss = 153974.734375\n",
      "1690: episode_rewards = 144.0, policy_loss = 1579.49462890625, value_loss = 116875.421875\n",
      "1691: episode_rewards = 200.0, policy_loss = 3521.338134765625, value_loss = 283341.15625\n",
      "1692: episode_rewards = 108.0, policy_loss = 608.2093505859375, value_loss = 55551.52734375\n",
      "1693: episode_rewards = 200.0, policy_loss = 3270.035400390625, value_loss = 277887.21875\n",
      "1694: episode_rewards = 200.0, policy_loss = 3551.9541015625, value_loss = 301326.375\n",
      "1695: episode_rewards = 139.0, policy_loss = 1762.71044921875, value_loss = 116637.8203125\n",
      "1696: episode_rewards = 200.0, policy_loss = 3575.165283203125, value_loss = 288782.625\n",
      "1697: episode_rewards = 200.0, policy_loss = 3801.436767578125, value_loss = 301578.1875\n",
      "1698: episode_rewards = 131.0, policy_loss = 1282.1895751953125, value_loss = 100918.453125\n",
      "1699: episode_rewards = 161.0, policy_loss = 1794.69970703125, value_loss = 167807.390625\n",
      "1700: episode_rewards = 200.0, policy_loss = 3182.7734375, value_loss = 270148.6875\n",
      "1701: episode_rewards = 200.0, policy_loss = 2952.124755859375, value_loss = 280316.8125\n",
      "1702: episode_rewards = 200.0, policy_loss = 3566.20947265625, value_loss = 294508.21875\n",
      "1703: episode_rewards = 59.0, policy_loss = -76.0342025756836, value_loss = 8859.8291015625\n",
      "1704: episode_rewards = 200.0, policy_loss = 3240.4765625, value_loss = 291706.34375\n",
      "1705: episode_rewards = 42.0, policy_loss = -275.0721435546875, value_loss = 6631.29736328125\n",
      "1706: episode_rewards = 200.0, policy_loss = 2971.798828125, value_loss = 256577.015625\n",
      "1707: episode_rewards = 185.0, policy_loss = 2751.85546875, value_loss = 218143.046875\n",
      "1708: episode_rewards = 35.0, policy_loss = -318.98046875, value_loss = 7311.40478515625\n",
      "1709: episode_rewards = 180.0, policy_loss = 2833.741455078125, value_loss = 219853.03125\n",
      "1710: episode_rewards = 200.0, policy_loss = 3150.427001953125, value_loss = 286202.46875\n",
      "1711: episode_rewards = 200.0, policy_loss = 3326.447509765625, value_loss = 279166.75\n",
      "1712: episode_rewards = 200.0, policy_loss = 3349.40771484375, value_loss = 290348.40625\n",
      "1713: episode_rewards = 200.0, policy_loss = 3411.921875, value_loss = 275583.5625\n",
      "1714: episode_rewards = 182.0, policy_loss = 2362.035400390625, value_loss = 242943.453125\n",
      "1715: episode_rewards = 200.0, policy_loss = 3598.85595703125, value_loss = 290934.21875\n",
      "1716: episode_rewards = 184.0, policy_loss = 2733.35888671875, value_loss = 226501.046875\n",
      "1717: episode_rewards = 200.0, policy_loss = 3213.210205078125, value_loss = 265968.90625\n",
      "1718: episode_rewards = 200.0, policy_loss = 3573.01123046875, value_loss = 288008.0625\n",
      "1719: episode_rewards = 200.0, policy_loss = 3585.87841796875, value_loss = 276390.3125\n",
      "1720: episode_rewards = 200.0, policy_loss = 3400.44091796875, value_loss = 288226.4375\n",
      "1721: episode_rewards = 182.0, policy_loss = 2909.9453125, value_loss = 229318.34375\n",
      "1722: episode_rewards = 152.0, policy_loss = 1869.7010498046875, value_loss = 137613.625\n",
      "1723: episode_rewards = 200.0, policy_loss = 3368.2265625, value_loss = 282940.75\n",
      "1724: episode_rewards = 90.0, policy_loss = 236.03858947753906, value_loss = 31565.33203125\n",
      "1725: episode_rewards = 200.0, policy_loss = 3424.62451171875, value_loss = 267895.75\n",
      "1726: episode_rewards = 200.0, policy_loss = 3375.457763671875, value_loss = 285231.5\n",
      "1727: episode_rewards = 157.0, policy_loss = 2104.0947265625, value_loss = 153431.578125\n",
      "1728: episode_rewards = 69.0, policy_loss = -129.3196258544922, value_loss = 15913.263671875\n",
      "1729: episode_rewards = 200.0, policy_loss = 3480.91259765625, value_loss = 288521.5\n",
      "1730: episode_rewards = 164.0, policy_loss = 2278.8837890625, value_loss = 173485.21875\n",
      "1731: episode_rewards = 167.0, policy_loss = 2386.15625, value_loss = 183456.5625\n",
      "1732: episode_rewards = 200.0, policy_loss = 3329.613037109375, value_loss = 278503.21875\n",
      "1733: episode_rewards = 200.0, policy_loss = 3477.081787109375, value_loss = 282453.59375\n",
      "1734: episode_rewards = 200.0, policy_loss = 3347.648193359375, value_loss = 270035.84375\n",
      "1735: episode_rewards = 200.0, policy_loss = 3152.1943359375, value_loss = 266958.59375\n",
      "1736: episode_rewards = 200.0, policy_loss = 3158.08349609375, value_loss = 265184.6875\n",
      "1737: episode_rewards = 200.0, policy_loss = 3058.68115234375, value_loss = 269930.90625\n",
      "1738: episode_rewards = 200.0, policy_loss = 3175.600830078125, value_loss = 270405.5\n",
      "1739: episode_rewards = 200.0, policy_loss = 3119.789306640625, value_loss = 280258.46875\n",
      "1740: episode_rewards = 173.0, policy_loss = 2521.22705078125, value_loss = 197064.90625\n",
      "1741: episode_rewards = 200.0, policy_loss = 3506.2568359375, value_loss = 282997.15625\n",
      "1742: episode_rewards = 200.0, policy_loss = 2953.897216796875, value_loss = 258310.90625\n",
      "1743: episode_rewards = 200.0, policy_loss = 3492.4765625, value_loss = 275102.25\n",
      "1744: episode_rewards = 200.0, policy_loss = 3413.537109375, value_loss = 276159.65625\n",
      "1745: episode_rewards = 200.0, policy_loss = 3329.565185546875, value_loss = 260806.84375\n",
      "1746: episode_rewards = 78.0, policy_loss = -28.079111099243164, value_loss = 29576.728515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747: episode_rewards = 200.0, policy_loss = 3057.15087890625, value_loss = 267577.71875\n",
      "1748: episode_rewards = 131.0, policy_loss = 957.1151123046875, value_loss = 84220.3203125\n",
      "1749: episode_rewards = 170.0, policy_loss = 2406.108642578125, value_loss = 184939.359375\n",
      "1750: episode_rewards = 200.0, policy_loss = 2918.9091796875, value_loss = 269667.34375\n",
      "1751: episode_rewards = 66.0, policy_loss = -252.48184204101562, value_loss = 24140.52734375\n",
      "1752: episode_rewards = 200.0, policy_loss = 3193.734375, value_loss = 281418.0625\n",
      "1753: episode_rewards = 174.0, policy_loss = 2507.9892578125, value_loss = 199258.109375\n",
      "1754: episode_rewards = 200.0, policy_loss = 2877.37548828125, value_loss = 257013.875\n",
      "1755: episode_rewards = 200.0, policy_loss = 2658.893310546875, value_loss = 273701.59375\n",
      "1756: episode_rewards = 200.0, policy_loss = 3463.37939453125, value_loss = 272518.1875\n",
      "1757: episode_rewards = 200.0, policy_loss = 3121.762451171875, value_loss = 264457.375\n",
      "1758: episode_rewards = 141.0, policy_loss = 995.8447875976562, value_loss = 95512.3046875\n",
      "1759: episode_rewards = 200.0, policy_loss = 3332.340576171875, value_loss = 270623.6875\n",
      "1760: episode_rewards = 23.0, policy_loss = -310.9488525390625, value_loss = 9472.369140625\n",
      "1761: episode_rewards = 200.0, policy_loss = 2616.024169921875, value_loss = 262755.15625\n",
      "1762: episode_rewards = 200.0, policy_loss = 3510.3359375, value_loss = 267555.875\n",
      "1763: episode_rewards = 200.0, policy_loss = 2829.693603515625, value_loss = 278885.4375\n",
      "1764: episode_rewards = 131.0, policy_loss = 1276.14208984375, value_loss = 84351.25\n",
      "1765: episode_rewards = 134.0, policy_loss = 773.2155151367188, value_loss = 95273.5859375\n",
      "1766: episode_rewards = 170.0, policy_loss = 1733.1787109375, value_loss = 156108.90625\n",
      "1767: episode_rewards = 200.0, policy_loss = 3080.5986328125, value_loss = 251830.078125\n",
      "1768: episode_rewards = 182.0, policy_loss = 2117.99462890625, value_loss = 195522.34375\n",
      "1769: episode_rewards = 149.0, policy_loss = 1227.75830078125, value_loss = 121939.3203125\n",
      "1770: episode_rewards = 122.0, policy_loss = 868.5115966796875, value_loss = 66552.09375\n",
      "1771: episode_rewards = 200.0, policy_loss = 2836.035888671875, value_loss = 247624.9375\n",
      "1772: episode_rewards = 200.0, policy_loss = 2703.259033203125, value_loss = 256722.875\n",
      "1773: episode_rewards = 173.0, policy_loss = 2529.371826171875, value_loss = 184095.328125\n",
      "1774: episode_rewards = 200.0, policy_loss = 3000.670166015625, value_loss = 248024.71875\n",
      "1775: episode_rewards = 200.0, policy_loss = 3395.303955078125, value_loss = 265448.5\n",
      "1776: episode_rewards = 200.0, policy_loss = 2834.943359375, value_loss = 258436.265625\n",
      "1777: episode_rewards = 200.0, policy_loss = 3161.307861328125, value_loss = 261041.359375\n",
      "1778: episode_rewards = 147.0, policy_loss = 1644.1910400390625, value_loss = 114063.671875\n",
      "1779: episode_rewards = 200.0, policy_loss = 3369.173583984375, value_loss = 267681.96875\n",
      "1780: episode_rewards = 200.0, policy_loss = 2871.248046875, value_loss = 232696.625\n",
      "1781: episode_rewards = 200.0, policy_loss = 3310.517333984375, value_loss = 260363.78125\n",
      "1782: episode_rewards = 200.0, policy_loss = 2896.44580078125, value_loss = 248551.4375\n",
      "1783: episode_rewards = 200.0, policy_loss = 3200.174072265625, value_loss = 260758.078125\n",
      "1784: episode_rewards = 200.0, policy_loss = 2932.699462890625, value_loss = 249007.5625\n",
      "1785: episode_rewards = 200.0, policy_loss = 3263.97119140625, value_loss = 248899.625\n",
      "1786: episode_rewards = 200.0, policy_loss = 3066.40625, value_loss = 241961.21875\n",
      "1787: episode_rewards = 135.0, policy_loss = 1138.4508056640625, value_loss = 92503.8828125\n",
      "1788: episode_rewards = 78.0, policy_loss = -143.83839416503906, value_loss = 22656.39453125\n",
      "1789: episode_rewards = 200.0, policy_loss = 2842.92041015625, value_loss = 238419.828125\n",
      "1790: episode_rewards = 200.0, policy_loss = 2946.955078125, value_loss = 255471.53125\n",
      "1791: episode_rewards = 200.0, policy_loss = 3005.877685546875, value_loss = 247421.140625\n",
      "1792: episode_rewards = 187.0, policy_loss = 2338.36083984375, value_loss = 218914.515625\n",
      "1793: episode_rewards = 157.0, policy_loss = 1761.3509521484375, value_loss = 136181.0625\n",
      "1794: episode_rewards = 200.0, policy_loss = 2945.270263671875, value_loss = 252059.546875\n",
      "1795: episode_rewards = 200.0, policy_loss = 2978.20068359375, value_loss = 243180.859375\n",
      "1796: episode_rewards = 200.0, policy_loss = 3059.99365234375, value_loss = 241799.359375\n",
      "1797: episode_rewards = 200.0, policy_loss = 2834.464111328125, value_loss = 241870.6875\n",
      "1798: episode_rewards = 200.0, policy_loss = 2993.72021484375, value_loss = 238815.96875\n",
      "1799: episode_rewards = 200.0, policy_loss = 3091.009033203125, value_loss = 250876.21875\n",
      "1800: episode_rewards = 21.0, policy_loss = -329.264404296875, value_loss = 9845.7724609375\n",
      "1801: episode_rewards = 200.0, policy_loss = 2981.4501953125, value_loss = 259502.5625\n",
      "1802: episode_rewards = 200.0, policy_loss = 2942.77685546875, value_loss = 234504.59375\n",
      "1803: episode_rewards = 200.0, policy_loss = 2595.796875, value_loss = 217886.3125\n",
      "1804: episode_rewards = 200.0, policy_loss = 3060.566162109375, value_loss = 242280.984375\n",
      "1805: episode_rewards = 120.0, policy_loss = 640.75439453125, value_loss = 67540.875\n",
      "1806: episode_rewards = 200.0, policy_loss = 2704.5283203125, value_loss = 255611.234375\n",
      "1807: episode_rewards = 140.0, policy_loss = 1271.464599609375, value_loss = 92685.7109375\n",
      "1808: episode_rewards = 117.0, policy_loss = 647.5889892578125, value_loss = 60787.6796875\n",
      "1809: episode_rewards = 200.0, policy_loss = 2794.075927734375, value_loss = 219540.625\n",
      "1810: episode_rewards = 143.0, policy_loss = 1331.5042724609375, value_loss = 101482.125\n",
      "1811: episode_rewards = 200.0, policy_loss = 2730.916015625, value_loss = 241398.625\n",
      "1812: episode_rewards = 171.0, policy_loss = 1665.7166748046875, value_loss = 167181.609375\n",
      "1813: episode_rewards = 132.0, policy_loss = 1176.2142333984375, value_loss = 71896.5703125\n",
      "1814: episode_rewards = 168.0, policy_loss = 2125.095703125, value_loss = 157060.765625\n",
      "1815: episode_rewards = 200.0, policy_loss = 2783.489013671875, value_loss = 245694.78125\n",
      "1816: episode_rewards = 200.0, policy_loss = 2794.34912109375, value_loss = 236012.921875\n",
      "1817: episode_rewards = 136.0, policy_loss = 1176.79931640625, value_loss = 84327.109375\n",
      "1818: episode_rewards = 200.0, policy_loss = 2643.537353515625, value_loss = 232659.515625\n",
      "1819: episode_rewards = 182.0, policy_loss = 2328.311767578125, value_loss = 201020.53125\n",
      "1820: episode_rewards = 200.0, policy_loss = 2550.56298828125, value_loss = 231215.5625\n",
      "1821: episode_rewards = 200.0, policy_loss = 2836.692138671875, value_loss = 236788.859375\n",
      "1822: episode_rewards = 200.0, policy_loss = 2972.396484375, value_loss = 234240.8125\n",
      "1823: episode_rewards = 194.0, policy_loss = 2371.67626953125, value_loss = 205618.625\n",
      "1824: episode_rewards = 200.0, policy_loss = 2952.100830078125, value_loss = 223574.359375\n",
      "1825: episode_rewards = 200.0, policy_loss = 2397.221923828125, value_loss = 220270.5\n",
      "1826: episode_rewards = 119.0, policy_loss = 700.1520385742188, value_loss = 60981.92578125\n",
      "1827: episode_rewards = 200.0, policy_loss = 2923.28955078125, value_loss = 248922.1875\n",
      "1828: episode_rewards = 200.0, policy_loss = 2897.89208984375, value_loss = 247938.8125\n",
      "1829: episode_rewards = 171.0, policy_loss = 1534.108154296875, value_loss = 150195.03125\n",
      "1830: episode_rewards = 171.0, policy_loss = 2121.58740234375, value_loss = 163948.578125\n",
      "1831: episode_rewards = 200.0, policy_loss = 2810.531005859375, value_loss = 233051.625\n",
      "1832: episode_rewards = 200.0, policy_loss = 2570.94384765625, value_loss = 225113.203125\n",
      "1833: episode_rewards = 191.0, policy_loss = 2702.374267578125, value_loss = 211593.78125\n",
      "1834: episode_rewards = 200.0, policy_loss = 2473.685791015625, value_loss = 235280.90625\n",
      "1835: episode_rewards = 200.0, policy_loss = 2855.66943359375, value_loss = 249255.40625\n",
      "1836: episode_rewards = 172.0, policy_loss = 1778.1322021484375, value_loss = 168017.90625\n",
      "1837: episode_rewards = 200.0, policy_loss = 2953.6474609375, value_loss = 245969.375\n",
      "1838: episode_rewards = 136.0, policy_loss = 1081.895751953125, value_loss = 81025.75\n",
      "1839: episode_rewards = 200.0, policy_loss = 2910.894287109375, value_loss = 231046.40625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1840: episode_rewards = 200.0, policy_loss = 2930.0869140625, value_loss = 231313.75\n",
      "1841: episode_rewards = 161.0, policy_loss = 1870.2764892578125, value_loss = 130757.875\n",
      "1842: episode_rewards = 200.0, policy_loss = 2503.6259765625, value_loss = 209938.421875\n",
      "1843: episode_rewards = 146.0, policy_loss = 1299.4935302734375, value_loss = 105215.8828125\n",
      "1844: episode_rewards = 200.0, policy_loss = 2846.998779296875, value_loss = 224342.828125\n",
      "1845: episode_rewards = 200.0, policy_loss = 2796.6220703125, value_loss = 238889.265625\n",
      "1846: episode_rewards = 200.0, policy_loss = 2540.490478515625, value_loss = 225995.390625\n",
      "1847: episode_rewards = 200.0, policy_loss = 2463.93359375, value_loss = 218327.390625\n",
      "1848: episode_rewards = 164.0, policy_loss = 1830.203125, value_loss = 142117.171875\n",
      "1849: episode_rewards = 164.0, policy_loss = 1832.0919189453125, value_loss = 140025.125\n",
      "1850: episode_rewards = 200.0, policy_loss = 2622.5205078125, value_loss = 214697.234375\n",
      "1851: episode_rewards = 200.0, policy_loss = 2802.853759765625, value_loss = 235397.5625\n",
      "1852: episode_rewards = 200.0, policy_loss = 2619.869873046875, value_loss = 227141.890625\n",
      "1853: episode_rewards = 200.0, policy_loss = 2400.23046875, value_loss = 212566.75\n",
      "1854: episode_rewards = 174.0, policy_loss = 2064.55859375, value_loss = 160299.53125\n",
      "1855: episode_rewards = 195.0, policy_loss = 2094.373046875, value_loss = 214791.984375\n",
      "1856: episode_rewards = 200.0, policy_loss = 2902.9482421875, value_loss = 227618.046875\n",
      "1857: episode_rewards = 200.0, policy_loss = 2442.638916015625, value_loss = 208124.859375\n",
      "1858: episode_rewards = 200.0, policy_loss = 2685.233154296875, value_loss = 227030.40625\n",
      "1859: episode_rewards = 174.0, policy_loss = 2132.930419921875, value_loss = 150068.890625\n",
      "1860: episode_rewards = 200.0, policy_loss = 2405.97119140625, value_loss = 213136.0\n",
      "1861: episode_rewards = 171.0, policy_loss = 1492.0345458984375, value_loss = 162259.4375\n",
      "1862: episode_rewards = 200.0, policy_loss = 2541.447021484375, value_loss = 201765.6875\n",
      "1863: episode_rewards = 183.0, policy_loss = 1712.4476318359375, value_loss = 176974.0625\n",
      "1864: episode_rewards = 174.0, policy_loss = 2058.56201171875, value_loss = 155631.75\n",
      "1865: episode_rewards = 200.0, policy_loss = 2810.096435546875, value_loss = 221250.421875\n",
      "1866: episode_rewards = 198.0, policy_loss = 2728.80908203125, value_loss = 213271.5\n",
      "1867: episode_rewards = 172.0, policy_loss = 1372.6541748046875, value_loss = 143010.921875\n",
      "1868: episode_rewards = 120.0, policy_loss = 480.1521301269531, value_loss = 53424.24609375\n",
      "1869: episode_rewards = 200.0, policy_loss = 2704.4140625, value_loss = 208887.140625\n",
      "1870: episode_rewards = 200.0, policy_loss = 2226.51708984375, value_loss = 203191.375\n",
      "1871: episode_rewards = 198.0, policy_loss = 2234.69775390625, value_loss = 223524.859375\n",
      "1872: episode_rewards = 32.0, policy_loss = -621.1757202148438, value_loss = 18015.041015625\n",
      "1873: episode_rewards = 200.0, policy_loss = 2680.24951171875, value_loss = 214364.09375\n",
      "1874: episode_rewards = 148.0, policy_loss = 1316.518310546875, value_loss = 96850.3984375\n",
      "1875: episode_rewards = 188.0, policy_loss = 1818.0887451171875, value_loss = 172703.890625\n",
      "1876: episode_rewards = 200.0, policy_loss = 2734.742431640625, value_loss = 206465.859375\n",
      "1877: episode_rewards = 200.0, policy_loss = 2246.300048828125, value_loss = 214682.796875\n",
      "1878: episode_rewards = 200.0, policy_loss = 2418.602294921875, value_loss = 216139.8125\n",
      "1879: episode_rewards = 166.0, policy_loss = 1181.0050048828125, value_loss = 139215.703125\n",
      "1880: episode_rewards = 162.0, policy_loss = 1587.3414306640625, value_loss = 129863.7578125\n",
      "1881: episode_rewards = 200.0, policy_loss = 2463.564453125, value_loss = 205289.328125\n",
      "1882: episode_rewards = 200.0, policy_loss = 2742.39501953125, value_loss = 220353.6875\n",
      "1883: episode_rewards = 200.0, policy_loss = 2580.850341796875, value_loss = 225019.734375\n",
      "1884: episode_rewards = 200.0, policy_loss = 2410.876220703125, value_loss = 208946.15625\n",
      "1885: episode_rewards = 110.0, policy_loss = 324.2872619628906, value_loss = 47380.71875\n",
      "1886: episode_rewards = 200.0, policy_loss = 2255.48681640625, value_loss = 202537.171875\n",
      "1887: episode_rewards = 200.0, policy_loss = 1937.550048828125, value_loss = 210552.40625\n",
      "1888: episode_rewards = 200.0, policy_loss = 2120.806640625, value_loss = 206761.953125\n",
      "1889: episode_rewards = 146.0, policy_loss = 1224.019287109375, value_loss = 91626.8671875\n",
      "1890: episode_rewards = 200.0, policy_loss = 2141.789794921875, value_loss = 219500.125\n",
      "1891: episode_rewards = 142.0, policy_loss = 1195.811279296875, value_loss = 82182.546875\n",
      "1892: episode_rewards = 200.0, policy_loss = 2159.668701171875, value_loss = 204018.046875\n",
      "1893: episode_rewards = 95.0, policy_loss = -180.18019104003906, value_loss = 29824.978515625\n",
      "1894: episode_rewards = 200.0, policy_loss = 2742.273193359375, value_loss = 202430.765625\n",
      "1895: episode_rewards = 200.0, policy_loss = 2388.50244140625, value_loss = 207585.328125\n",
      "1896: episode_rewards = 200.0, policy_loss = 2609.305419921875, value_loss = 213929.234375\n",
      "1897: episode_rewards = 150.0, policy_loss = 1196.0133056640625, value_loss = 95781.5078125\n",
      "1898: episode_rewards = 200.0, policy_loss = 2305.890869140625, value_loss = 202936.5\n",
      "1899: episode_rewards = 191.0, policy_loss = 1859.96484375, value_loss = 192897.84375\n",
      "1900: episode_rewards = 200.0, policy_loss = 2285.720947265625, value_loss = 202308.296875\n",
      "1901: episode_rewards = 138.0, policy_loss = 892.836669921875, value_loss = 78239.78125\n",
      "1902: episode_rewards = 157.0, policy_loss = 1381.4034423828125, value_loss = 114896.7890625\n",
      "1903: episode_rewards = 200.0, policy_loss = 2124.8388671875, value_loss = 193504.40625\n",
      "1904: episode_rewards = 131.0, policy_loss = 647.2598266601562, value_loss = 72666.3359375\n",
      "1905: episode_rewards = 144.0, policy_loss = 1058.9703369140625, value_loss = 90015.5703125\n",
      "1906: episode_rewards = 140.0, policy_loss = 948.1536865234375, value_loss = 78269.921875\n",
      "1907: episode_rewards = 200.0, policy_loss = 2428.435546875, value_loss = 219140.296875\n",
      "1908: episode_rewards = 200.0, policy_loss = 2267.77197265625, value_loss = 206316.390625\n",
      "1909: episode_rewards = 126.0, policy_loss = 680.0392456054688, value_loss = 55290.9296875\n",
      "1910: episode_rewards = 200.0, policy_loss = 2215.462646484375, value_loss = 217803.515625\n",
      "1911: episode_rewards = 200.0, policy_loss = 2424.533203125, value_loss = 223439.28125\n",
      "1912: episode_rewards = 158.0, policy_loss = 926.2086181640625, value_loss = 120683.1484375\n",
      "1913: episode_rewards = 200.0, policy_loss = 2280.88525390625, value_loss = 202420.4375\n",
      "1914: episode_rewards = 200.0, policy_loss = 2543.984375, value_loss = 193344.28125\n",
      "1915: episode_rewards = 152.0, policy_loss = 1198.2919921875, value_loss = 101535.203125\n",
      "1916: episode_rewards = 183.0, policy_loss = 1538.259033203125, value_loss = 150001.171875\n",
      "1917: episode_rewards = 197.0, policy_loss = 1834.677490234375, value_loss = 194933.359375\n",
      "1918: episode_rewards = 167.0, policy_loss = 1586.8026123046875, value_loss = 128617.296875\n",
      "1919: episode_rewards = 176.0, policy_loss = 1813.51708984375, value_loss = 146216.09375\n",
      "1920: episode_rewards = 200.0, policy_loss = 2435.05224609375, value_loss = 206506.65625\n",
      "1921: episode_rewards = 198.0, policy_loss = 1872.3690185546875, value_loss = 210102.984375\n",
      "1922: episode_rewards = 194.0, policy_loss = 2370.357666015625, value_loss = 186162.546875\n",
      "1923: episode_rewards = 180.0, policy_loss = 1958.0704345703125, value_loss = 141541.84375\n",
      "1924: episode_rewards = 122.0, policy_loss = 367.6954345703125, value_loss = 54105.00390625\n",
      "1925: episode_rewards = 200.0, policy_loss = 2629.799072265625, value_loss = 202755.53125\n",
      "1926: episode_rewards = 200.0, policy_loss = 2456.006591796875, value_loss = 210793.796875\n",
      "1927: episode_rewards = 200.0, policy_loss = 2436.924072265625, value_loss = 197457.515625\n",
      "1928: episode_rewards = 177.0, policy_loss = 1827.8912353515625, value_loss = 145086.75\n",
      "1929: episode_rewards = 200.0, policy_loss = 2218.5849609375, value_loss = 196091.265625\n",
      "1930: episode_rewards = 200.0, policy_loss = 2245.13037109375, value_loss = 200118.875\n",
      "1931: episode_rewards = 179.0, policy_loss = 1857.2076416015625, value_loss = 152247.328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1932: episode_rewards = 174.0, policy_loss = 1710.78173828125, value_loss = 142564.578125\n",
      "1933: episode_rewards = 200.0, policy_loss = 2364.378662109375, value_loss = 200869.53125\n",
      "1934: episode_rewards = 184.0, policy_loss = 1411.1220703125, value_loss = 166932.46875\n",
      "1935: episode_rewards = 200.0, policy_loss = 2254.45166015625, value_loss = 196470.703125\n",
      "1936: episode_rewards = 128.0, policy_loss = 526.2305908203125, value_loss = 60828.68359375\n",
      "1937: episode_rewards = 196.0, policy_loss = 1792.469970703125, value_loss = 189780.1875\n",
      "1938: episode_rewards = 195.0, policy_loss = 2387.105712890625, value_loss = 187296.4375\n",
      "1939: episode_rewards = 200.0, policy_loss = 2091.43701171875, value_loss = 183030.921875\n",
      "1940: episode_rewards = 46.0, policy_loss = -583.773193359375, value_loss = 19446.439453125\n",
      "1941: episode_rewards = 200.0, policy_loss = 2370.7001953125, value_loss = 180984.84375\n",
      "1942: episode_rewards = 200.0, policy_loss = 2176.4560546875, value_loss = 186872.015625\n",
      "1943: episode_rewards = 176.0, policy_loss = 1817.7388916015625, value_loss = 139577.90625\n",
      "1944: episode_rewards = 200.0, policy_loss = 2466.8818359375, value_loss = 192641.84375\n",
      "1945: episode_rewards = 110.0, policy_loss = 127.24726867675781, value_loss = 40294.1484375\n",
      "1946: episode_rewards = 200.0, policy_loss = 2339.771484375, value_loss = 196699.90625\n",
      "1947: episode_rewards = 200.0, policy_loss = 2365.91796875, value_loss = 187631.796875\n",
      "1948: episode_rewards = 200.0, policy_loss = 2043.7412109375, value_loss = 191130.140625\n",
      "1949: episode_rewards = 200.0, policy_loss = 2194.903076171875, value_loss = 179866.796875\n",
      "1950: episode_rewards = 192.0, policy_loss = 1571.4754638671875, value_loss = 172514.84375\n",
      "1951: episode_rewards = 165.0, policy_loss = 1417.265869140625, value_loss = 112783.625\n",
      "1952: episode_rewards = 196.0, policy_loss = 2345.136474609375, value_loss = 174628.5625\n",
      "1953: episode_rewards = 200.0, policy_loss = 2276.4052734375, value_loss = 194260.296875\n",
      "1954: episode_rewards = 200.0, policy_loss = 2379.29931640625, value_loss = 189092.6875\n",
      "1955: episode_rewards = 200.0, policy_loss = 2284.63720703125, value_loss = 185465.71875\n",
      "1956: episode_rewards = 200.0, policy_loss = 2111.37451171875, value_loss = 179901.296875\n",
      "1957: episode_rewards = 169.0, policy_loss = 1469.675048828125, value_loss = 119582.3515625\n",
      "1958: episode_rewards = 200.0, policy_loss = 2099.6142578125, value_loss = 184990.28125\n",
      "1959: episode_rewards = 200.0, policy_loss = 2198.4677734375, value_loss = 187714.515625\n",
      "1960: episode_rewards = 178.0, policy_loss = 1674.7418212890625, value_loss = 146574.765625\n",
      "1961: episode_rewards = 200.0, policy_loss = 2457.03759765625, value_loss = 186639.0625\n",
      "1962: episode_rewards = 200.0, policy_loss = 2214.58154296875, value_loss = 169134.6875\n",
      "1963: episode_rewards = 200.0, policy_loss = 1851.9124755859375, value_loss = 177088.078125\n",
      "1964: episode_rewards = 200.0, policy_loss = 2165.322265625, value_loss = 183655.453125\n",
      "1965: episode_rewards = 200.0, policy_loss = 2147.54931640625, value_loss = 178799.53125\n",
      "1966: episode_rewards = 200.0, policy_loss = 2046.5513916015625, value_loss = 186740.75\n",
      "1967: episode_rewards = 200.0, policy_loss = 2097.266845703125, value_loss = 176899.265625\n",
      "1968: episode_rewards = 83.0, policy_loss = -360.9827880859375, value_loss = 26571.63671875\n",
      "1969: episode_rewards = 200.0, policy_loss = 1901.648193359375, value_loss = 180991.96875\n",
      "1970: episode_rewards = 200.0, policy_loss = 1983.4317626953125, value_loss = 193454.03125\n",
      "1971: episode_rewards = 200.0, policy_loss = 1998.601806640625, value_loss = 186669.0\n",
      "1972: episode_rewards = 200.0, policy_loss = 2118.604736328125, value_loss = 180209.78125\n",
      "1973: episode_rewards = 200.0, policy_loss = 2445.804443359375, value_loss = 175723.890625\n",
      "1974: episode_rewards = 200.0, policy_loss = 2035.089599609375, value_loss = 189351.375\n",
      "1975: episode_rewards = 130.0, policy_loss = 495.25384521484375, value_loss = 57568.9296875\n",
      "1976: episode_rewards = 200.0, policy_loss = 1888.1705322265625, value_loss = 182868.234375\n",
      "1977: episode_rewards = 200.0, policy_loss = 1691.2880859375, value_loss = 182669.84375\n",
      "1978: episode_rewards = 200.0, policy_loss = 2008.4508056640625, value_loss = 177873.59375\n",
      "1979: episode_rewards = 57.0, policy_loss = -688.9761962890625, value_loss = 25697.638671875\n",
      "1980: episode_rewards = 156.0, policy_loss = 1013.0472412109375, value_loss = 100689.125\n",
      "1981: episode_rewards = 200.0, policy_loss = 2321.8798828125, value_loss = 186949.5\n",
      "1982: episode_rewards = 200.0, policy_loss = 2106.697509765625, value_loss = 177439.515625\n",
      "1983: episode_rewards = 200.0, policy_loss = 2032.58984375, value_loss = 190528.015625\n",
      "1984: episode_rewards = 200.0, policy_loss = 1912.8966064453125, value_loss = 183148.59375\n",
      "1985: episode_rewards = 200.0, policy_loss = 2017.7452392578125, value_loss = 182407.640625\n",
      "1986: episode_rewards = 200.0, policy_loss = 2241.58447265625, value_loss = 179707.609375\n",
      "1987: episode_rewards = 200.0, policy_loss = 1810.6785888671875, value_loss = 179490.9375\n",
      "1988: episode_rewards = 200.0, policy_loss = 1942.736328125, value_loss = 183860.0625\n",
      "1989: episode_rewards = 200.0, policy_loss = 1727.0439453125, value_loss = 166532.609375\n",
      "1990: episode_rewards = 124.0, policy_loss = 281.345947265625, value_loss = 56035.09375\n",
      "1991: episode_rewards = 200.0, policy_loss = 1802.5960693359375, value_loss = 167330.609375\n",
      "1992: episode_rewards = 200.0, policy_loss = 2167.07568359375, value_loss = 180031.9375\n",
      "1993: episode_rewards = 200.0, policy_loss = 1674.057373046875, value_loss = 174417.015625\n",
      "1994: episode_rewards = 200.0, policy_loss = 1987.893798828125, value_loss = 173314.90625\n",
      "1995: episode_rewards = 160.0, policy_loss = 942.0225830078125, value_loss = 101061.046875\n",
      "1996: episode_rewards = 200.0, policy_loss = 1947.76708984375, value_loss = 179721.828125\n",
      "1997: episode_rewards = 200.0, policy_loss = 1893.8846435546875, value_loss = 167397.5\n",
      "1998: episode_rewards = 194.0, policy_loss = 1639.130615234375, value_loss = 167376.8125\n",
      "1999: episode_rewards = 200.0, policy_loss = 1925.4747314453125, value_loss = 177429.28125\n"
     ]
    }
   ],
   "source": [
    "# vanilla policy gradient\n",
    "for i in range(2000):\n",
    "  current_state = env.reset() # an array of 4 values\n",
    "  done = False\n",
    "  episode_reward = 0\n",
    "  \n",
    "  values = [] \n",
    "  logprobs = []\n",
    "  rewards = []\n",
    "\n",
    "  while not done:\n",
    "     # forward propagation on policy using current_state\n",
    "    value, action_real = model(Variable(torch.from_numpy(current_state).float().unsqueeze(0))) \n",
    "    # value and action_real are variables\n",
    "    action_logprob = F.log_softmax(action_real) # returns a variable\n",
    "    \n",
    "    action_prob = F.softmax(action_real) # returns a variable\n",
    "    action = action_prob.multinomial().data # returns a torch tensor\n",
    "    \n",
    "    logprob = action_logprob.gather(1, Variable(action))\n",
    "    current_state, reward, done, _ = env.step(action.numpy()[0,0])\n",
    "    \n",
    "    values.append(value) # variable\n",
    "    logprobs.append(logprob) # variable\n",
    "    rewards.append(reward) # numpy\n",
    "    \n",
    "    episode_reward += reward\n",
    "  \n",
    "  R = 0\n",
    "  value_loss = 0\n",
    "  policy_loss = 0\n",
    "  for j in reversed(range(len(rewards))):\n",
    "    R = rewards[j] + gamma * R # numpy\n",
    "    advantage = R - values[j]\n",
    "    value_loss += advantage.pow(2)\n",
    "    policy_loss -= logprobs[j] * advantage\n",
    "  \n",
    "  optimizer.zero_grad()\n",
    "  value_loss.backward(retain_variables=True)\n",
    "  policy_loss.backward()\n",
    "  optimizer.step()\n",
    "  \n",
    "  print('{0}: episode_rewards = {1}, policy_loss = {2}, value_loss = {3}'.format(\n",
    "    i, episode_reward, policy_loss.data[0,0], value_loss.data[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.render(close=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.shape[0]\n",
    "print('input_size = {0}, output_size = {1}'.format(input_size, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ActorCritic(input_size, output_size)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vanilla policy gradient\n",
    "for i in range(2000):\n",
    "  current_state = env.reset() # an array of 4 values\n",
    "  done = False\n",
    "  episode_reward = 0\n",
    "  \n",
    "  values = []\n",
    "  logprobs = []\n",
    "  rewards = []\n",
    "\n",
    "  while not done:\n",
    "     # forward propagation on policy using current_state\n",
    "    value, action_real = model(Variable(torch.from_numpy(current_state).float().unsqueeze(0)))\n",
    "    break\n",
    "    # value and action_real are variables\n",
    "#     action_logprob = F.log_softmax(action_real) # returns a variable\n",
    "    \n",
    "#     action_prob = F.softmax(action_real) # returns a variable\n",
    "#     action = action_prob.multinomial().data # returns a torch tensor\n",
    "    \n",
    "#     logprob = action_logprob.gather(1, Variable(action))\n",
    "#     current_state, reward, done, _ = env.step(action.numpy()[0,0])\n",
    "    \n",
    "#     values.append(value) # variable\n",
    "#     logprobs.append(logprob) # variable\n",
    "#     rewards.append(reward) # numpy\n",
    "    \n",
    "#     episode_reward += reward\n",
    "  \n",
    "#   R = 0\n",
    "#   value_loss = 0\n",
    "#   policy_loss = 0\n",
    "#   for j in reversed(range(len(rewards))):\n",
    "#     R = rewards[j] + gamma * R # numpy\n",
    "#     advantage = R - values[j]\n",
    "#     value_loss += advantage.pow(2)\n",
    "#     policy_loss -= logprobs[j] * advantage\n",
    "  \n",
    "#   optimizer.zero_grad()\n",
    "#   value_loss.backward(retain_variables=True)\n",
    "#   policy_loss.backward()\n",
    "#   optimizer.step()\n",
    "  \n",
    "#   print('{0}: episode_rewards = {1}, policy_loss = {2}, value_loss = {3}'.format(\n",
    "#     i, episode_reward, policy_loss.data[0,0], value_loss.data[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F.tanh(action_real)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
